// Package client provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/deepmap/oapi-codegen version v1.12.4 DO NOT EDIT.
package client

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/deepmap/oapi-codegen/pkg/runtime"
	"github.com/getkin/kin-openapi/openapi3"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeGcs   BackupStorageType = "gcs"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeGcs   CreateBackupStorageParamsType = "gcs"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for DatabaseClusterRestoreStatusConditionsStatus.
const (
	False   DatabaseClusterRestoreStatusConditionsStatus = "False"
	True    DatabaseClusterRestoreStatusConditionsStatus = "True"
	Unknown DatabaseClusterRestoreStatusConditionsStatus = "Unknown"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	BucketName string            `json:"bucketName"`
	Id         string            `json:"id"`
	Name       string            `json:"name"`
	Region     string            `json:"region"`
	Type       BackupStorageType `json:"type"`
	Url        *string           `json:"url,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// BucketName The cloud storage bucket/container name
	BucketName string `json:"bucketName"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                        `json:"name"`
	Region    string                        `json:"region"`
	SecretKey string                        `json:"secretKey"`
	Type      CreateBackupStorageParamsType `json:"type"`
	Url       *string                       `json:"url,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// CreateKubernetesClusterParams kubernetes object
type CreateKubernetesClusterParams struct {
	Kubeconfig string  `json:"kubeconfig"`
	Name       string  `json:"name"`
	Namespace  *string `json:"namespace,omitempty"`
}

// DatabaseCluster DatabaseCluster is the Schema for the databases API.
type DatabaseCluster struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseSpec defines the desired state of Database.
	Spec *struct {
		// Backup Backup contains backup settings.
		Backup *struct {
			Annotations *map[string]string `json:"annotations,omitempty"`

			// ContainerSecurityContext SecurityContext holds security configuration that will be applied to a container. Some fields are present in both SecurityContext and PodSecurityContext.  When both are set, the values in SecurityContext take precedence.
			ContainerSecurityContext *struct {
				// AllowPrivilegeEscalation AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN Note that this field cannot be set when spec.os.name is windows.
				AllowPrivilegeEscalation *bool `json:"allowPrivilegeEscalation,omitempty"`

				// Capabilities The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime. Note that this field cannot be set when spec.os.name is windows.
				Capabilities *struct {
					// Add Added capabilities
					Add *[]string `json:"add,omitempty"`

					// Drop Removed capabilities
					Drop *[]string `json:"drop,omitempty"`
				} `json:"capabilities,omitempty"`

				// Privileged Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false. Note that this field cannot be set when spec.os.name is windows.
				Privileged *bool `json:"privileged,omitempty"`

				// ProcMount procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled. Note that this field cannot be set when spec.os.name is windows.
				ProcMount *string `json:"procMount,omitempty"`

				// ReadOnlyRootFilesystem Whether this container has a read-only root filesystem. Default is false. Note that this field cannot be set when spec.os.name is windows.
				ReadOnlyRootFilesystem *bool `json:"readOnlyRootFilesystem,omitempty"`

				// RunAsGroup The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				RunAsGroup *int64 `json:"runAsGroup,omitempty"`

				// RunAsNonRoot Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
				RunAsNonRoot *bool `json:"runAsNonRoot,omitempty"`

				// RunAsUser The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				RunAsUser *int64 `json:"runAsUser,omitempty"`

				// SeLinuxOptions The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				SeLinuxOptions *struct {
					// Level Level is SELinux level label that applies to the container.
					Level *string `json:"level,omitempty"`

					// Role Role is a SELinux role label that applies to the container.
					Role *string `json:"role,omitempty"`

					// Type Type is a SELinux type label that applies to the container.
					Type *string `json:"type,omitempty"`

					// User User is a SELinux user label that applies to the container.
					User *string `json:"user,omitempty"`
				} `json:"seLinuxOptions,omitempty"`

				// SeccompProfile The seccomp options to use by this container. If seccomp options are provided at both the pod & container level, the container options override the pod options. Note that this field cannot be set when spec.os.name is windows.
				SeccompProfile *struct {
					// LocalhostProfile localhostProfile indicates a profile defined in a file on the node should be used. The profile must be preconfigured on the node to work. Must be a descending path, relative to the kubelet's configured seccomp profile location. Must only be set if type is "Localhost".
					LocalhostProfile *string `json:"localhostProfile,omitempty"`

					// Type type indicates which kind of seccomp profile will be applied. Valid options are:
					//  Localhost - a profile defined in a file on the node should be used. RuntimeDefault - the container runtime default profile should be used. Unconfined - no profile should be applied.
					Type string `json:"type"`
				} `json:"seccompProfile,omitempty"`

				// WindowsOptions The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is linux.
				WindowsOptions *struct {
					// GmsaCredentialSpec GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
					GmsaCredentialSpec *string `json:"gmsaCredentialSpec,omitempty"`

					// GmsaCredentialSpecName GMSACredentialSpecName is the name of the GMSA credential spec to use.
					GmsaCredentialSpecName *string `json:"gmsaCredentialSpecName,omitempty"`

					// HostProcess HostProcess determines if a container should be run as a 'Host Process' container. This field is alpha-level and will only be honored by components that enable the WindowsHostProcessContainers feature flag. Setting this field without the feature flag will result in errors when validating the Pod. All of a Pod's containers must have the same effective HostProcess value (it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).  In addition, if HostProcess is true then HostNetwork must also be set to true.
					HostProcess *bool `json:"hostProcess,omitempty"`

					// RunAsUserName The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
					RunAsUserName *string `json:"runAsUserName,omitempty"`
				} `json:"windowsOptions,omitempty"`
			} `json:"containerSecurityContext,omitempty"`
			Enabled *bool   `json:"enabled,omitempty"`
			Image   *string `json:"image,omitempty"`

			// ImagePullPolicy PullPolicy describes a policy for if/when to pull a container image
			ImagePullPolicy  *string `json:"imagePullPolicy,omitempty"`
			ImagePullSecrets *[]struct {
				// Name Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
				Name *string `json:"name,omitempty"`
			} `json:"imagePullSecrets,omitempty"`
			InitImage *string            `json:"initImage,omitempty"`
			Labels    *map[string]string `json:"labels,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]interface{} `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]interface{} `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
			Schedule *[]struct {
				CompressionLevel *int    `json:"compressionLevel,omitempty"`
				CompressionType  *string `json:"compressionType,omitempty"`
				Enabled          *bool   `json:"enabled,omitempty"`
				Keep             *int    `json:"keep,omitempty"`
				Name             *string `json:"name,omitempty"`
				Schedule         *string `json:"schedule,omitempty"`
				StorageName      *string `json:"storageName,omitempty"`
			} `json:"schedule,omitempty"`
			ServiceAccountName *string `json:"serviceAccountName,omitempty"`
			Storages           *map[string]struct {
				// Affinity Affinity is a group of affinity scheduling rules.
				Affinity *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"affinity,omitempty"`
				Annotations *map[string]string `json:"annotations,omitempty"`

				// ContainerSecurityContext SecurityContext holds security configuration that will be applied to a container. Some fields are present in both SecurityContext and PodSecurityContext.  When both are set, the values in SecurityContext take precedence.
				ContainerSecurityContext *struct {
					// AllowPrivilegeEscalation AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN Note that this field cannot be set when spec.os.name is windows.
					AllowPrivilegeEscalation *bool `json:"allowPrivilegeEscalation,omitempty"`

					// Capabilities The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime. Note that this field cannot be set when spec.os.name is windows.
					Capabilities *struct {
						// Add Added capabilities
						Add *[]string `json:"add,omitempty"`

						// Drop Removed capabilities
						Drop *[]string `json:"drop,omitempty"`
					} `json:"capabilities,omitempty"`

					// Privileged Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false. Note that this field cannot be set when spec.os.name is windows.
					Privileged *bool `json:"privileged,omitempty"`

					// ProcMount procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled. Note that this field cannot be set when spec.os.name is windows.
					ProcMount *string `json:"procMount,omitempty"`

					// ReadOnlyRootFilesystem Whether this container has a read-only root filesystem. Default is false. Note that this field cannot be set when spec.os.name is windows.
					ReadOnlyRootFilesystem *bool `json:"readOnlyRootFilesystem,omitempty"`

					// RunAsGroup The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
					RunAsGroup *int64 `json:"runAsGroup,omitempty"`

					// RunAsNonRoot Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
					RunAsNonRoot *bool `json:"runAsNonRoot,omitempty"`

					// RunAsUser The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
					RunAsUser *int64 `json:"runAsUser,omitempty"`

					// SeLinuxOptions The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
					SeLinuxOptions *struct {
						// Level Level is SELinux level label that applies to the container.
						Level *string `json:"level,omitempty"`

						// Role Role is a SELinux role label that applies to the container.
						Role *string `json:"role,omitempty"`

						// Type Type is a SELinux type label that applies to the container.
						Type *string `json:"type,omitempty"`

						// User User is a SELinux user label that applies to the container.
						User *string `json:"user,omitempty"`
					} `json:"seLinuxOptions,omitempty"`

					// SeccompProfile The seccomp options to use by this container. If seccomp options are provided at both the pod & container level, the container options override the pod options. Note that this field cannot be set when spec.os.name is windows.
					SeccompProfile *struct {
						// LocalhostProfile localhostProfile indicates a profile defined in a file on the node should be used. The profile must be preconfigured on the node to work. Must be a descending path, relative to the kubelet's configured seccomp profile location. Must only be set if type is "Localhost".
						LocalhostProfile *string `json:"localhostProfile,omitempty"`

						// Type type indicates which kind of seccomp profile will be applied. Valid options are:
						//  Localhost - a profile defined in a file on the node should be used. RuntimeDefault - the container runtime default profile should be used. Unconfined - no profile should be applied.
						Type string `json:"type"`
					} `json:"seccompProfile,omitempty"`

					// WindowsOptions The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is linux.
					WindowsOptions *struct {
						// GmsaCredentialSpec GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
						GmsaCredentialSpec *string `json:"gmsaCredentialSpec,omitempty"`

						// GmsaCredentialSpecName GMSACredentialSpecName is the name of the GMSA credential spec to use.
						GmsaCredentialSpecName *string `json:"gmsaCredentialSpecName,omitempty"`

						// HostProcess HostProcess determines if a container should be run as a 'Host Process' container. This field is alpha-level and will only be honored by components that enable the WindowsHostProcessContainers feature flag. Setting this field without the feature flag will result in errors when validating the Pod. All of a Pod's containers must have the same effective HostProcess value (it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).  In addition, if HostProcess is true then HostNetwork must also be set to true.
						HostProcess *bool `json:"hostProcess,omitempty"`

						// RunAsUserName The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
						RunAsUserName *string `json:"runAsUserName,omitempty"`
					} `json:"windowsOptions,omitempty"`
				} `json:"containerSecurityContext,omitempty"`
				Labels       *map[string]string `json:"labels,omitempty"`
				NodeSelector *map[string]string `json:"nodeSelector,omitempty"`

				// PodSecurityContext PodSecurityContext holds pod-level security attributes and common container settings. Some fields are also present in container.securityContext.  Field values of container.securityContext take precedence over field values of PodSecurityContext.
				PodSecurityContext *struct {
					// FsGroup A special supplemental group that applies to all containers in a pod. Some volume types allow the Kubelet to change the ownership of that volume to be owned by the pod:
					//  1. The owning GID will be the FSGroup 2. The setgid bit is set (new files created in the volume will be owned by FSGroup) 3. The permission bits are OR'd with rw-rw----
					//  If unset, the Kubelet will not modify the ownership and permissions of any volume. Note that this field cannot be set when spec.os.name is windows.
					FsGroup *int64 `json:"fsGroup,omitempty"`

					// FsGroupChangePolicy fsGroupChangePolicy defines behavior of changing ownership and permission of the volume before being exposed inside Pod. This field will only apply to volume types which support fsGroup based ownership(and permissions). It will have no effect on ephemeral volume types such as: secret, configmaps and emptydir. Valid values are "OnRootMismatch" and "Always". If not specified, "Always" is used. Note that this field cannot be set when spec.os.name is windows.
					FsGroupChangePolicy *string `json:"fsGroupChangePolicy,omitempty"`

					// RunAsGroup The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows.
					RunAsGroup *int64 `json:"runAsGroup,omitempty"`

					// RunAsNonRoot Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
					RunAsNonRoot *bool `json:"runAsNonRoot,omitempty"`

					// RunAsUser The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows.
					RunAsUser *int64 `json:"runAsUser,omitempty"`

					// SeLinuxOptions The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows.
					SeLinuxOptions *struct {
						// Level Level is SELinux level label that applies to the container.
						Level *string `json:"level,omitempty"`

						// Role Role is a SELinux role label that applies to the container.
						Role *string `json:"role,omitempty"`

						// Type Type is a SELinux type label that applies to the container.
						Type *string `json:"type,omitempty"`

						// User User is a SELinux user label that applies to the container.
						User *string `json:"user,omitempty"`
					} `json:"seLinuxOptions,omitempty"`

					// SeccompProfile The seccomp options to use by the containers in this pod. Note that this field cannot be set when spec.os.name is windows.
					SeccompProfile *struct {
						// LocalhostProfile localhostProfile indicates a profile defined in a file on the node should be used. The profile must be preconfigured on the node to work. Must be a descending path, relative to the kubelet's configured seccomp profile location. Must only be set if type is "Localhost".
						LocalhostProfile *string `json:"localhostProfile,omitempty"`

						// Type type indicates which kind of seccomp profile will be applied. Valid options are:
						//  Localhost - a profile defined in a file on the node should be used. RuntimeDefault - the container runtime default profile should be used. Unconfined - no profile should be applied.
						Type string `json:"type"`
					} `json:"seccompProfile,omitempty"`

					// SupplementalGroups A list of groups applied to the first process run in each container, in addition to the container's primary GID, the fsGroup (if specified), and group memberships defined in the container image for the uid of the container process. If unspecified, no additional groups are added to any container. Note that group memberships defined in the container image for the uid of the container process are still effective, even if they are not included in this list. Note that this field cannot be set when spec.os.name is windows.
					SupplementalGroups *[]int64 `json:"supplementalGroups,omitempty"`

					// Sysctls Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch. Note that this field cannot be set when spec.os.name is windows.
					Sysctls *[]struct {
						// Name Name of a property to set
						Name string `json:"name"`

						// Value Value of a property to set
						Value string `json:"value"`
					} `json:"sysctls,omitempty"`

					// WindowsOptions The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is linux.
					WindowsOptions *struct {
						// GmsaCredentialSpec GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
						GmsaCredentialSpec *string `json:"gmsaCredentialSpec,omitempty"`

						// GmsaCredentialSpecName GMSACredentialSpecName is the name of the GMSA credential spec to use.
						GmsaCredentialSpecName *string `json:"gmsaCredentialSpecName,omitempty"`

						// HostProcess HostProcess determines if a container should be run as a 'Host Process' container. This field is alpha-level and will only be honored by components that enable the WindowsHostProcessContainers feature flag. Setting this field without the feature flag will result in errors when validating the Pod. All of a Pod's containers must have the same effective HostProcess value (it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).  In addition, if HostProcess is true then HostNetwork must also be set to true.
						HostProcess *bool `json:"hostProcess,omitempty"`

						// RunAsUserName The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
						RunAsUserName *string `json:"runAsUserName,omitempty"`
					} `json:"windowsOptions,omitempty"`
				} `json:"podSecurityContext,omitempty"`
				PriorityClassName *string `json:"priorityClassName,omitempty"`

				// Resources ResourceRequirements describes the compute resource requirements.
				Resources *struct {
					// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
					//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
					//  This field is immutable. It can only be set for containers.
					Claims *[]struct {
						// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
						Name string `json:"name"`
					} `json:"claims,omitempty"`

					// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
					Limits *map[string]interface{} `json:"limits,omitempty"`

					// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
					Requests *map[string]interface{} `json:"requests,omitempty"`
				} `json:"resources,omitempty"`
				RuntimeClassName *string `json:"runtimeClassName,omitempty"`
				SchedulerName    *string `json:"schedulerName,omitempty"`

				// StorageProvider BackupStorageProviderSpec represents set of settings to configure cloud provider.
				StorageProvider *struct {
					Bucket *string `json:"bucket,omitempty"`

					// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
					ContainerName     *string `json:"containerName,omitempty"`
					CredentialsSecret string  `json:"credentialsSecret"`
					EndpointUrl       *string `json:"endpointUrl,omitempty"`
					Prefix            *string `json:"prefix,omitempty"`
					Region            *string `json:"region,omitempty"`

					// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
					StorageClass *string `json:"storageClass,omitempty"`
				} `json:"storageProvider,omitempty"`
				Tolerations *[]struct {
					// Effect Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
					Effect *string `json:"effect,omitempty"`

					// Key Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
					Key *string `json:"key,omitempty"`

					// Operator Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
					Operator *string `json:"operator,omitempty"`

					// TolerationSeconds TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
					TolerationSeconds *int64 `json:"tolerationSeconds,omitempty"`

					// Value Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
					Value *string `json:"value,omitempty"`
				} `json:"tolerations,omitempty"`

				// Type BackupStorageType represents backup storage type.
				Type      string `json:"type"`
				VerifyTLS *bool  `json:"verifyTLS,omitempty"`

				// VolumeSpec VolumeSpec represents a specification to configure volume for underlying database.
				VolumeSpec *struct {
					// EmptyDir EmptyDir to use as data volume for mysql. EmptyDir represents a temporary directory that shares a pod's lifetime.
					EmptyDir *map[string]interface{} `json:"emptyDir,omitempty"`

					// HostPath HostPath to use as data volume for mysql. HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container.
					HostPath *struct {
						// Path path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
						Path string `json:"path"`

						// Type type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
						Type *string `json:"type,omitempty"`
					} `json:"hostPath,omitempty"`

					// PersistentVolumeClaim PersistentVolumeClaim to specify PVC spec for the volume for mysql data. It has the highest level of precedence, followed by HostPath and EmptyDir. And represents the PVC specification.
					PersistentVolumeClaim *struct {
						// AccessModes accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
						AccessModes *[]string `json:"accessModes,omitempty"`

						// DataSource dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef, and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified. If the namespace is specified, then dataSourceRef will not be copied to dataSource.
						DataSource *struct {
							// ApiGroup APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
							ApiGroup *string `json:"apiGroup,omitempty"`

							// Kind Kind is the type of resource being referenced
							Kind string `json:"kind"`

							// Name Name is the name of resource being referenced
							Name string `json:"name"`
						} `json:"dataSource,omitempty"`

						// DataSourceRef dataSourceRef specifies the object from which to populate the volume with data, if a non-empty volume is desired. This may be any object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the dataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, when namespace isn't specified in dataSourceRef, both fields (dataSource and dataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. When namespace is specified in dataSourceRef, dataSource isn't set to the same value and must be empty. There are three important differences between dataSource and dataSourceRef: * While dataSource only allows two specific types of objects, dataSourceRef allows any non-core object, as well as PersistentVolumeClaim objects. * While dataSource ignores disallowed values (dropping them), dataSourceRef preserves all values, and generates an error if a disallowed value is specified. * While dataSource only allows local objects, dataSourceRef allows objects in any namespaces. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled. (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
						DataSourceRef *struct {
							// ApiGroup APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
							ApiGroup *string `json:"apiGroup,omitempty"`

							// Kind Kind is the type of resource being referenced
							Kind string `json:"kind"`

							// Name Name is the name of resource being referenced
							Name string `json:"name"`

							// Namespace Namespace is the namespace of resource being referenced Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details. (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
							Namespace *string `json:"namespace,omitempty"`
						} `json:"dataSourceRef,omitempty"`

						// Resources resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
						Resources *struct {
							// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
							//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
							//  This field is immutable. It can only be set for containers.
							Claims *[]struct {
								// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
								Name string `json:"name"`
							} `json:"claims,omitempty"`

							// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
							Limits *map[string]interface{} `json:"limits,omitempty"`

							// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
							Requests *map[string]interface{} `json:"requests,omitempty"`
						} `json:"resources,omitempty"`

						// Selector selector is a label query over volumes to consider for binding.
						Selector *struct {
							// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
							MatchExpressions *[]struct {
								// Key key is the label key that the selector applies to.
								Key string `json:"key"`

								// Operator operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
								Operator string `json:"operator"`

								// Values values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
								Values *[]string `json:"values,omitempty"`
							} `json:"matchExpressions,omitempty"`

							// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
							MatchLabels *map[string]string `json:"matchLabels,omitempty"`
						} `json:"selector,omitempty"`

						// StorageClassName storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
						StorageClassName *string `json:"storageClassName,omitempty"`

						// VolumeMode volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
						VolumeMode *string `json:"volumeMode,omitempty"`

						// VolumeName volumeName is the binding reference to the PersistentVolume backing this claim.
						VolumeName *string `json:"volumeName,omitempty"`
					} `json:"persistentVolumeClaim,omitempty"`
				} `json:"volumeSpec,omitempty"`
			} `json:"storages,omitempty"`
		} `json:"backup,omitempty"`

		// ClusterSize ClusterSize is amount of nodes that required for the cluster. A database starts in cluster mode if clusterSize >= 3.
		ClusterSize int32 `json:"clusterSize"`

		// DatabaseConfig DatabaseConfig contains a config settings for the specified database.
		DatabaseConfig string `json:"databaseConfig"`

		// DatabaseImage DatabaseVersion sets from version service and uses the recommended version by default.
		DatabaseImage string `json:"databaseImage"`

		// DatabaseType Database type stands for supported databases by the PMM API Now it's pxc or psmdb types but we can extend it.
		DatabaseType string `json:"databaseType"`

		// DbInstance DBInstance represents resource requests for a database cluster.
		DbInstance struct {
			Cpu              *DatabaseCluster_Spec_DbInstance_Cpu      `json:"cpu,omitempty"`
			DiskSize         *DatabaseCluster_Spec_DbInstance_DiskSize `json:"diskSize,omitempty"`
			Memory           *DatabaseCluster_Spec_DbInstance_Memory   `json:"memory,omitempty"`
			StorageClassName *string                                   `json:"storageClassName,omitempty"`
		} `json:"dbInstance"`

		// LoadBalancer LoadBalancer contains a load balancer settings. For PXC it's haproxy or proxysql. For PSMDB it's mongos.
		LoadBalancer *struct {
			Annotations   *map[string]string `json:"annotations,omitempty"`
			Configuration *string            `json:"configuration,omitempty"`

			// ExposeType Service Type string describes ingress methods for a service
			ExposeType               *string   `json:"exposeType,omitempty"`
			Image                    *string   `json:"image,omitempty"`
			LoadBalancerSourceRanges *[]string `json:"loadBalancerSourceRanges,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
			Size *int32 `json:"size,omitempty"`

			// TrafficPolicy ServiceExternalTrafficPolicyType describes how nodes distribute service traffic they receive on one of the Service's "externally-facing" addresses (NodePorts, ExternalIPs, and LoadBalancer IPs).
			TrafficPolicy *string `json:"trafficPolicy,omitempty"`

			// Type LoadBalancerType contains supported loadbalancers. It can be proxysql or haproxy for PXC clusters, mongos for PSMDB clusters or pgbouncer for Postgresql clusters.
			Type *string `json:"type,omitempty"`
		} `json:"loadBalancer,omitempty"`

		// Monitoring Monitoring contains a monitoring settings.
		Monitoring *struct {
			// ContainerSecurityContext SecurityContext holds security configuration that will be applied to a container. Some fields are present in both SecurityContext and PodSecurityContext.  When both are set, the values in SecurityContext take precedence.
			ContainerSecurityContext *struct {
				// AllowPrivilegeEscalation AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN Note that this field cannot be set when spec.os.name is windows.
				AllowPrivilegeEscalation *bool `json:"allowPrivilegeEscalation,omitempty"`

				// Capabilities The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime. Note that this field cannot be set when spec.os.name is windows.
				Capabilities *struct {
					// Add Added capabilities
					Add *[]string `json:"add,omitempty"`

					// Drop Removed capabilities
					Drop *[]string `json:"drop,omitempty"`
				} `json:"capabilities,omitempty"`

				// Privileged Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false. Note that this field cannot be set when spec.os.name is windows.
				Privileged *bool `json:"privileged,omitempty"`

				// ProcMount procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled. Note that this field cannot be set when spec.os.name is windows.
				ProcMount *string `json:"procMount,omitempty"`

				// ReadOnlyRootFilesystem Whether this container has a read-only root filesystem. Default is false. Note that this field cannot be set when spec.os.name is windows.
				ReadOnlyRootFilesystem *bool `json:"readOnlyRootFilesystem,omitempty"`

				// RunAsGroup The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				RunAsGroup *int64 `json:"runAsGroup,omitempty"`

				// RunAsNonRoot Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
				RunAsNonRoot *bool `json:"runAsNonRoot,omitempty"`

				// RunAsUser The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				RunAsUser *int64 `json:"runAsUser,omitempty"`

				// SeLinuxOptions The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is windows.
				SeLinuxOptions *struct {
					// Level Level is SELinux level label that applies to the container.
					Level *string `json:"level,omitempty"`

					// Role Role is a SELinux role label that applies to the container.
					Role *string `json:"role,omitempty"`

					// Type Type is a SELinux type label that applies to the container.
					Type *string `json:"type,omitempty"`

					// User User is a SELinux user label that applies to the container.
					User *string `json:"user,omitempty"`
				} `json:"seLinuxOptions,omitempty"`

				// SeccompProfile The seccomp options to use by this container. If seccomp options are provided at both the pod & container level, the container options override the pod options. Note that this field cannot be set when spec.os.name is windows.
				SeccompProfile *struct {
					// LocalhostProfile localhostProfile indicates a profile defined in a file on the node should be used. The profile must be preconfigured on the node to work. Must be a descending path, relative to the kubelet's configured seccomp profile location. Must only be set if type is "Localhost".
					LocalhostProfile *string `json:"localhostProfile,omitempty"`

					// Type type indicates which kind of seccomp profile will be applied. Valid options are:
					//  Localhost - a profile defined in a file on the node should be used. RuntimeDefault - the container runtime default profile should be used. Unconfined - no profile should be applied.
					Type string `json:"type"`
				} `json:"seccompProfile,omitempty"`

				// WindowsOptions The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is linux.
				WindowsOptions *struct {
					// GmsaCredentialSpec GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
					GmsaCredentialSpec *string `json:"gmsaCredentialSpec,omitempty"`

					// GmsaCredentialSpecName GMSACredentialSpecName is the name of the GMSA credential spec to use.
					GmsaCredentialSpecName *string `json:"gmsaCredentialSpecName,omitempty"`

					// HostProcess HostProcess determines if a container should be run as a 'Host Process' container. This field is alpha-level and will only be honored by components that enable the WindowsHostProcessContainers feature flag. Setting this field without the feature flag will result in errors when validating the Pod. All of a Pod's containers must have the same effective HostProcess value (it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).  In addition, if HostProcess is true then HostNetwork must also be set to true.
					HostProcess *bool `json:"hostProcess,omitempty"`

					// RunAsUserName The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
					RunAsUserName *string `json:"runAsUserName,omitempty"`
				} `json:"windowsOptions,omitempty"`
			} `json:"containerSecurityContext,omitempty"`

			// ImagePullPolicy PullPolicy describes a policy for if/when to pull a container image
			ImagePullPolicy *string `json:"imagePullPolicy,omitempty"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
			RuntimeClassName *string `json:"runtimeClassName,omitempty"`
		} `json:"monitoring,omitempty"`

		// Pause Pause represents is a cluster paused or not.
		Pause *bool `json:"pause,omitempty"`

		// SecretsName SecretsName contains name of a secrets file for a database cluster.
		SecretsName *string `json:"secretsName,omitempty"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterStatus defines the observed state of Database.
	Status *struct {
		Host    *string `json:"host,omitempty"`
		Message *string `json:"message,omitempty"`
		Ready   *int32  `json:"ready,omitempty"`
		Size    *int32  `json:"size,omitempty"`

		// Status AppState is used to represent cluster's state.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecDbInstanceCpu0 defines model for .
type DatabaseClusterSpecDbInstanceCpu0 = int

// DatabaseClusterSpecDbInstanceCpu1 defines model for .
type DatabaseClusterSpecDbInstanceCpu1 = string

// DatabaseCluster_Spec_DbInstance_Cpu defines model for DatabaseCluster.Spec.DbInstance.Cpu.
type DatabaseCluster_Spec_DbInstance_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecDbInstanceDiskSize0 defines model for .
type DatabaseClusterSpecDbInstanceDiskSize0 = int

// DatabaseClusterSpecDbInstanceDiskSize1 defines model for .
type DatabaseClusterSpecDbInstanceDiskSize1 = string

// DatabaseCluster_Spec_DbInstance_DiskSize defines model for DatabaseCluster.Spec.DbInstance.DiskSize.
type DatabaseCluster_Spec_DbInstance_DiskSize struct {
	union json.RawMessage
}

// DatabaseClusterSpecDbInstanceMemory0 defines model for .
type DatabaseClusterSpecDbInstanceMemory0 = int

// DatabaseClusterSpecDbInstanceMemory1 defines model for .
type DatabaseClusterSpecDbInstanceMemory1 = string

// DatabaseCluster_Spec_DbInstance_Memory defines model for DatabaseCluster.Spec.DbInstance.Memory.
type DatabaseCluster_Spec_DbInstance_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecLoadBalancerResourcesLimits0 defines model for .
type DatabaseClusterSpecLoadBalancerResourcesLimits0 = int

// DatabaseClusterSpecLoadBalancerResourcesLimits1 defines model for .
type DatabaseClusterSpecLoadBalancerResourcesLimits1 = string

// DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.LoadBalancer.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecLoadBalancerResourcesRequests0 defines model for .
type DatabaseClusterSpecLoadBalancerResourcesRequests0 = int

// DatabaseClusterSpecLoadBalancerResourcesRequests1 defines model for .
type DatabaseClusterSpecLoadBalancerResourcesRequests1 = string

// DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.LoadBalancer.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Items DatabaseCluster is the Schema for the databases API.
	Items *DatabaseCluster `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		BackupName *string `json:"backupName,omitempty"`

		// BackupSource BackupSource represents settings of a source where to get a backup to run restoration.
		BackupSource *struct {
			// Azure BackupStorageProviderSpec represents set of settings to configure cloud provider.
			Azure *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"azure,omitempty"`
			Destination *string `json:"destination,omitempty"`
			Image       *string `json:"image,omitempty"`

			// S3 BackupStorageProviderSpec represents set of settings to configure cloud provider.
			S3 *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"s3,omitempty"`
			SslInternalSecretName *string `json:"sslInternalSecretName,omitempty"`
			SslSecretName         *string `json:"sslSecretName,omitempty"`
			StorageName           *string `json:"storageName,omitempty"`

			// StorageType BackupStorageType represents backup storage type.
			StorageType     string  `json:"storage_type"`
			VaultSecretName *string `json:"vaultSecretName,omitempty"`
		} `json:"backupSource,omitempty"`
		DatabaseCluster string `json:"databaseCluster"`

		// DatabaseType EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		DatabaseType string `json:"databaseType"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed  *time.Time `json:"completed,omitempty"`
		Conditions *[]struct {
			// LastTransitionTime lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
			LastTransitionTime time.Time `json:"lastTransitionTime"`

			// Message message is a human readable message indicating details about the transition. This may be an empty string.
			Message string `json:"message"`

			// ObservedGeneration observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
			ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

			// Reason reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
			Reason string `json:"reason"`

			// Status status of the condition, one of True, False, Unknown.
			Status DatabaseClusterRestoreStatusConditionsStatus `json:"status"`

			// Type type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
			Type string `json:"type"`
		} `json:"conditions,omitempty"`
		Destination   *string    `json:"destination,omitempty"`
		Lastscheduled *time.Time `json:"lastscheduled,omitempty"`
		Message       *string    `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State       *string `json:"state,omitempty"`
		StorageName *string `json:"storageName,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreStatusConditionsStatus status of the condition, one of True, False, Unknown.
type DatabaseClusterRestoreStatusConditionsStatus string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Items DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
	Items *DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		// Type EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// Status EngineState represents state of engine in a k8s cluster.
		Status  *string `json:"status,omitempty"`
		Version *string `json:"version,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Items DatabaseEngine is the Schema for the databaseengines API.
	Items *DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesCluster kubernetes object
type KubernetesCluster struct {
	Id   string `json:"id"`
	Name string `json:"name"`
}

// KubernetesClusterList defines model for KubernetesClusterList.
type KubernetesClusterList = []KubernetesCluster

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName *string `json:"bucketName,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      *string `json:"name,omitempty"`
	Region    *string `json:"region,omitempty"`
	SecretKey *string `json:"secretKey,omitempty"`
	Url       *string `json:"url,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// RegisterKubernetesClusterJSONRequestBody defines body for RegisterKubernetesCluster for application/json ContentType.
type RegisterKubernetesClusterJSONRequestBody = CreateKubernetesClusterParams

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = DatabaseCluster

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// AsDatabaseClusterSpecDbInstanceCpu0 returns the union data inside the DatabaseCluster_Spec_DbInstance_Cpu as a DatabaseClusterSpecDbInstanceCpu0
func (t DatabaseCluster_Spec_DbInstance_Cpu) AsDatabaseClusterSpecDbInstanceCpu0() (DatabaseClusterSpecDbInstanceCpu0, error) {
	var body DatabaseClusterSpecDbInstanceCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceCpu0 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_Cpu as the provided DatabaseClusterSpecDbInstanceCpu0
func (t *DatabaseCluster_Spec_DbInstance_Cpu) FromDatabaseClusterSpecDbInstanceCpu0(v DatabaseClusterSpecDbInstanceCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_Cpu, using the provided DatabaseClusterSpecDbInstanceCpu0
func (t *DatabaseCluster_Spec_DbInstance_Cpu) MergeDatabaseClusterSpecDbInstanceCpu0(v DatabaseClusterSpecDbInstanceCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecDbInstanceCpu1 returns the union data inside the DatabaseCluster_Spec_DbInstance_Cpu as a DatabaseClusterSpecDbInstanceCpu1
func (t DatabaseCluster_Spec_DbInstance_Cpu) AsDatabaseClusterSpecDbInstanceCpu1() (DatabaseClusterSpecDbInstanceCpu1, error) {
	var body DatabaseClusterSpecDbInstanceCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceCpu1 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_Cpu as the provided DatabaseClusterSpecDbInstanceCpu1
func (t *DatabaseCluster_Spec_DbInstance_Cpu) FromDatabaseClusterSpecDbInstanceCpu1(v DatabaseClusterSpecDbInstanceCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_Cpu, using the provided DatabaseClusterSpecDbInstanceCpu1
func (t *DatabaseCluster_Spec_DbInstance_Cpu) MergeDatabaseClusterSpecDbInstanceCpu1(v DatabaseClusterSpecDbInstanceCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_DbInstance_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_DbInstance_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecDbInstanceDiskSize0 returns the union data inside the DatabaseCluster_Spec_DbInstance_DiskSize as a DatabaseClusterSpecDbInstanceDiskSize0
func (t DatabaseCluster_Spec_DbInstance_DiskSize) AsDatabaseClusterSpecDbInstanceDiskSize0() (DatabaseClusterSpecDbInstanceDiskSize0, error) {
	var body DatabaseClusterSpecDbInstanceDiskSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceDiskSize0 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_DiskSize as the provided DatabaseClusterSpecDbInstanceDiskSize0
func (t *DatabaseCluster_Spec_DbInstance_DiskSize) FromDatabaseClusterSpecDbInstanceDiskSize0(v DatabaseClusterSpecDbInstanceDiskSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceDiskSize0 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_DiskSize, using the provided DatabaseClusterSpecDbInstanceDiskSize0
func (t *DatabaseCluster_Spec_DbInstance_DiskSize) MergeDatabaseClusterSpecDbInstanceDiskSize0(v DatabaseClusterSpecDbInstanceDiskSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecDbInstanceDiskSize1 returns the union data inside the DatabaseCluster_Spec_DbInstance_DiskSize as a DatabaseClusterSpecDbInstanceDiskSize1
func (t DatabaseCluster_Spec_DbInstance_DiskSize) AsDatabaseClusterSpecDbInstanceDiskSize1() (DatabaseClusterSpecDbInstanceDiskSize1, error) {
	var body DatabaseClusterSpecDbInstanceDiskSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceDiskSize1 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_DiskSize as the provided DatabaseClusterSpecDbInstanceDiskSize1
func (t *DatabaseCluster_Spec_DbInstance_DiskSize) FromDatabaseClusterSpecDbInstanceDiskSize1(v DatabaseClusterSpecDbInstanceDiskSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceDiskSize1 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_DiskSize, using the provided DatabaseClusterSpecDbInstanceDiskSize1
func (t *DatabaseCluster_Spec_DbInstance_DiskSize) MergeDatabaseClusterSpecDbInstanceDiskSize1(v DatabaseClusterSpecDbInstanceDiskSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_DbInstance_DiskSize) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_DbInstance_DiskSize) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecDbInstanceMemory0 returns the union data inside the DatabaseCluster_Spec_DbInstance_Memory as a DatabaseClusterSpecDbInstanceMemory0
func (t DatabaseCluster_Spec_DbInstance_Memory) AsDatabaseClusterSpecDbInstanceMemory0() (DatabaseClusterSpecDbInstanceMemory0, error) {
	var body DatabaseClusterSpecDbInstanceMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceMemory0 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_Memory as the provided DatabaseClusterSpecDbInstanceMemory0
func (t *DatabaseCluster_Spec_DbInstance_Memory) FromDatabaseClusterSpecDbInstanceMemory0(v DatabaseClusterSpecDbInstanceMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_Memory, using the provided DatabaseClusterSpecDbInstanceMemory0
func (t *DatabaseCluster_Spec_DbInstance_Memory) MergeDatabaseClusterSpecDbInstanceMemory0(v DatabaseClusterSpecDbInstanceMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecDbInstanceMemory1 returns the union data inside the DatabaseCluster_Spec_DbInstance_Memory as a DatabaseClusterSpecDbInstanceMemory1
func (t DatabaseCluster_Spec_DbInstance_Memory) AsDatabaseClusterSpecDbInstanceMemory1() (DatabaseClusterSpecDbInstanceMemory1, error) {
	var body DatabaseClusterSpecDbInstanceMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecDbInstanceMemory1 overwrites any union data inside the DatabaseCluster_Spec_DbInstance_Memory as the provided DatabaseClusterSpecDbInstanceMemory1
func (t *DatabaseCluster_Spec_DbInstance_Memory) FromDatabaseClusterSpecDbInstanceMemory1(v DatabaseClusterSpecDbInstanceMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecDbInstanceMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_DbInstance_Memory, using the provided DatabaseClusterSpecDbInstanceMemory1
func (t *DatabaseCluster_Spec_DbInstance_Memory) MergeDatabaseClusterSpecDbInstanceMemory1(v DatabaseClusterSpecDbInstanceMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_DbInstance_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_DbInstance_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecLoadBalancerResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecLoadBalancerResourcesLimits0
func (t DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecLoadBalancerResourcesLimits0() (DatabaseClusterSpecLoadBalancerResourcesLimits0, error) {
	var body DatabaseClusterSpecLoadBalancerResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecLoadBalancerResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecLoadBalancerResourcesLimits0
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecLoadBalancerResourcesLimits0(v DatabaseClusterSpecLoadBalancerResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecLoadBalancerResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecLoadBalancerResourcesLimits0
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecLoadBalancerResourcesLimits0(v DatabaseClusterSpecLoadBalancerResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecLoadBalancerResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecLoadBalancerResourcesLimits1
func (t DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecLoadBalancerResourcesLimits1() (DatabaseClusterSpecLoadBalancerResourcesLimits1, error) {
	var body DatabaseClusterSpecLoadBalancerResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecLoadBalancerResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecLoadBalancerResourcesLimits1
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecLoadBalancerResourcesLimits1(v DatabaseClusterSpecLoadBalancerResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecLoadBalancerResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecLoadBalancerResourcesLimits1
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecLoadBalancerResourcesLimits1(v DatabaseClusterSpecLoadBalancerResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecLoadBalancerResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecLoadBalancerResourcesRequests0
func (t DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecLoadBalancerResourcesRequests0() (DatabaseClusterSpecLoadBalancerResourcesRequests0, error) {
	var body DatabaseClusterSpecLoadBalancerResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecLoadBalancerResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecLoadBalancerResourcesRequests0
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecLoadBalancerResourcesRequests0(v DatabaseClusterSpecLoadBalancerResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecLoadBalancerResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecLoadBalancerResourcesRequests0
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecLoadBalancerResourcesRequests0(v DatabaseClusterSpecLoadBalancerResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecLoadBalancerResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecLoadBalancerResourcesRequests1
func (t DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecLoadBalancerResourcesRequests1() (DatabaseClusterSpecLoadBalancerResourcesRequests1, error) {
	var body DatabaseClusterSpecLoadBalancerResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecLoadBalancerResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecLoadBalancerResourcesRequests1
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecLoadBalancerResourcesRequests1(v DatabaseClusterSpecLoadBalancerResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecLoadBalancerResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecLoadBalancerResourcesRequests1
func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecLoadBalancerResourcesRequests1(v DatabaseClusterSpecLoadBalancerResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_LoadBalancer_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(b, t.union)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// ListBackupStorages request
	ListBackupStorages(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateBackupStorage request with any body
	CreateBackupStorageWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateBackupStorage(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteBackupStorage request
	DeleteBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetBackupStorage request
	GetBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateBackupStorage request with any body
	UpdateBackupStorageWithBody(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateBackupStorage(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListKubernetesClusters request
	ListKubernetesClusters(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RegisterKubernetesCluster request with any body
	RegisterKubernetesClusterWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RegisterKubernetesCluster(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetKubernetesCluster request
	GetKubernetesCluster(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusterRestores request
	ListDatabaseClusterRestores(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterRestore request with any body
	CreateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseClusterRestore(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseClusterRestore request
	DeleteDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterRestore request
	GetDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseClusterRestore request with any body
	UpdateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusters request
	ListDatabaseClusters(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseCluster request with any body
	CreateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseCluster(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseCluster request
	DeleteDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseCluster request
	GetDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseCluster request with any body
	UpdateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseCluster(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseEngines request
	ListDatabaseEngines(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseEngine request
	GetDatabaseEngine(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) ListBackupStorages(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupStoragesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorageWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorage(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteBackupStorageRequest(c.Server, backupStorageId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetBackupStorageRequest(c.Server, backupStorageId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorageWithBody(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequestWithBody(c.Server, backupStorageId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorage(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequest(c.Server, backupStorageId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListKubernetesClusters(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListKubernetesClustersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RegisterKubernetesClusterWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRegisterKubernetesClusterRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RegisterKubernetesCluster(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRegisterKubernetesClusterRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetKubernetesCluster(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetKubernetesClusterRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusterRestores(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClusterRestoresRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequestWithBody(c.Server, kubernetesId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestore(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequest(c.Server, kubernetesId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRestoreRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRestoreRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequestWithBody(c.Server, kubernetesId, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequest(c.Server, kubernetesId, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusters(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClustersRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequestWithBody(c.Server, kubernetesId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseCluster(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequest(c.Server, kubernetesId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequestWithBody(c.Server, kubernetesId, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseCluster(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequest(c.Server, kubernetesId, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseEngines(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseEnginesRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseEngine(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseEngineRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewListBackupStoragesRequest generates requests for ListBackupStorages
func NewListBackupStoragesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateBackupStorageRequest calls the generic CreateBackupStorage builder with application/json body
func NewCreateBackupStorageRequest(server string, body CreateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateBackupStorageRequestWithBody(server, "application/json", bodyReader)
}

// NewCreateBackupStorageRequestWithBody generates requests for CreateBackupStorage with any type of body
func NewCreateBackupStorageRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteBackupStorageRequest generates requests for DeleteBackupStorage
func NewDeleteBackupStorageRequest(server string, backupStorageId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetBackupStorageRequest generates requests for GetBackupStorage
func NewGetBackupStorageRequest(server string, backupStorageId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateBackupStorageRequest calls the generic UpdateBackupStorage builder with application/json body
func NewUpdateBackupStorageRequest(server string, backupStorageId string, body UpdateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateBackupStorageRequestWithBody(server, backupStorageId, "application/json", bodyReader)
}

// NewUpdateBackupStorageRequestWithBody generates requests for UpdateBackupStorage with any type of body
func NewUpdateBackupStorageRequestWithBody(server string, backupStorageId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListKubernetesClustersRequest generates requests for ListKubernetesClusters
func NewListKubernetesClustersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewRegisterKubernetesClusterRequest calls the generic RegisterKubernetesCluster builder with application/json body
func NewRegisterKubernetesClusterRequest(server string, body RegisterKubernetesClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRegisterKubernetesClusterRequestWithBody(server, "application/json", bodyReader)
}

// NewRegisterKubernetesClusterRequestWithBody generates requests for RegisterKubernetesCluster with any type of body
func NewRegisterKubernetesClusterRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetKubernetesClusterRequest generates requests for GetKubernetesCluster
func NewGetKubernetesClusterRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDatabaseClusterRestoresRequest generates requests for ListDatabaseClusterRestores
func NewListDatabaseClusterRestoresRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRestoreRequest calls the generic CreateDatabaseClusterRestore builder with application/json body
func NewCreateDatabaseClusterRestoreRequest(server string, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRestoreRequestWithBody(server, kubernetesId, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRestoreRequestWithBody generates requests for CreateDatabaseClusterRestore with any type of body
func NewCreateDatabaseClusterRestoreRequestWithBody(server string, kubernetesId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRestoreRequest generates requests for DeleteDatabaseClusterRestore
func NewDeleteDatabaseClusterRestoreRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRestoreRequest generates requests for GetDatabaseClusterRestore
func NewGetDatabaseClusterRestoreRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRestoreRequest calls the generic UpdateDatabaseClusterRestore builder with application/json body
func NewUpdateDatabaseClusterRestoreRequest(server string, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRestoreRequestWithBody(server, kubernetesId, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRestoreRequestWithBody generates requests for UpdateDatabaseClusterRestore with any type of body
func NewUpdateDatabaseClusterRestoreRequestWithBody(server string, kubernetesId string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseClustersRequest generates requests for ListDatabaseClusters
func NewListDatabaseClustersRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRequest calls the generic CreateDatabaseCluster builder with application/json body
func NewCreateDatabaseClusterRequest(server string, kubernetesId string, body CreateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRequestWithBody(server, kubernetesId, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRequestWithBody generates requests for CreateDatabaseCluster with any type of body
func NewCreateDatabaseClusterRequestWithBody(server string, kubernetesId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRequest generates requests for DeleteDatabaseCluster
func NewDeleteDatabaseClusterRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRequest generates requests for GetDatabaseCluster
func NewGetDatabaseClusterRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRequest calls the generic UpdateDatabaseCluster builder with application/json body
func NewUpdateDatabaseClusterRequest(server string, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRequestWithBody(server, kubernetesId, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRequestWithBody generates requests for UpdateDatabaseCluster with any type of body
func NewUpdateDatabaseClusterRequestWithBody(server string, kubernetesId string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseEnginesRequest generates requests for ListDatabaseEngines
func NewListDatabaseEnginesRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-engines", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseEngineRequest generates requests for GetDatabaseEngine
func NewGetDatabaseEngineRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-engines/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// ListBackupStorages request
	ListBackupStoragesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error)

	// CreateBackupStorage request with any body
	CreateBackupStorageWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	CreateBackupStorageWithResponse(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	// DeleteBackupStorage request
	DeleteBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error)

	// GetBackupStorage request
	GetBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error)

	// UpdateBackupStorage request with any body
	UpdateBackupStorageWithBodyWithResponse(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	UpdateBackupStorageWithResponse(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	// ListKubernetesClusters request
	ListKubernetesClustersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListKubernetesClustersResponse, error)

	// RegisterKubernetesCluster request with any body
	RegisterKubernetesClusterWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error)

	RegisterKubernetesClusterWithResponse(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error)

	// GetKubernetesCluster request
	GetKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResponse, error)

	// ListDatabaseClusterRestores request
	ListDatabaseClusterRestoresWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error)

	// CreateDatabaseClusterRestore request with any body
	CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	CreateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	// DeleteDatabaseClusterRestore request
	DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error)

	// GetDatabaseClusterRestore request
	GetDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error)

	// UpdateDatabaseClusterRestore request with any body
	UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	// ListDatabaseClusters request
	ListDatabaseClustersWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error)

	// CreateDatabaseCluster request with any body
	CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	CreateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	// DeleteDatabaseCluster request
	DeleteDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error)

	// GetDatabaseCluster request
	GetDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error)

	// UpdateDatabaseCluster request with any body
	UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	UpdateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	// ListDatabaseEngines request
	ListDatabaseEnginesWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error)

	// GetDatabaseEngine request
	GetDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error)
}

type ListBackupStoragesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStoragesList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListBackupStoragesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupStoragesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListKubernetesClustersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesClusterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListKubernetesClustersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListKubernetesClustersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RegisterKubernetesClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *KubernetesCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RegisterKubernetesClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RegisterKubernetesClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetKubernetesClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetKubernetesClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetKubernetesClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClusterRestoresResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestoreList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClusterRestoresResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClusterRestoresResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON202      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClustersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClustersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClustersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON201      *DatabaseCluster
	JSON202      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseEnginesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngineList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseEnginesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseEnginesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseEngineResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngineList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseEngineResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseEngineResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// ListBackupStoragesWithResponse request returning *ListBackupStoragesResponse
func (c *ClientWithResponses) ListBackupStoragesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error) {
	rsp, err := c.ListBackupStorages(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupStoragesResponse(rsp)
}

// CreateBackupStorageWithBodyWithResponse request with arbitrary body returning *CreateBackupStorageResponse
func (c *ClientWithResponses) CreateBackupStorageWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorageWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) CreateBackupStorageWithResponse(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorage(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

// DeleteBackupStorageWithResponse request returning *DeleteBackupStorageResponse
func (c *ClientWithResponses) DeleteBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error) {
	rsp, err := c.DeleteBackupStorage(ctx, backupStorageId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteBackupStorageResponse(rsp)
}

// GetBackupStorageWithResponse request returning *GetBackupStorageResponse
func (c *ClientWithResponses) GetBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error) {
	rsp, err := c.GetBackupStorage(ctx, backupStorageId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetBackupStorageResponse(rsp)
}

// UpdateBackupStorageWithBodyWithResponse request with arbitrary body returning *UpdateBackupStorageResponse
func (c *ClientWithResponses) UpdateBackupStorageWithBodyWithResponse(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorageWithBody(ctx, backupStorageId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) UpdateBackupStorageWithResponse(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorage(ctx, backupStorageId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

// ListKubernetesClustersWithResponse request returning *ListKubernetesClustersResponse
func (c *ClientWithResponses) ListKubernetesClustersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListKubernetesClustersResponse, error) {
	rsp, err := c.ListKubernetesClusters(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListKubernetesClustersResponse(rsp)
}

// RegisterKubernetesClusterWithBodyWithResponse request with arbitrary body returning *RegisterKubernetesClusterResponse
func (c *ClientWithResponses) RegisterKubernetesClusterWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error) {
	rsp, err := c.RegisterKubernetesClusterWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRegisterKubernetesClusterResponse(rsp)
}

func (c *ClientWithResponses) RegisterKubernetesClusterWithResponse(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error) {
	rsp, err := c.RegisterKubernetesCluster(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRegisterKubernetesClusterResponse(rsp)
}

// GetKubernetesClusterWithResponse request returning *GetKubernetesClusterResponse
func (c *ClientWithResponses) GetKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResponse, error) {
	rsp, err := c.GetKubernetesCluster(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetKubernetesClusterResponse(rsp)
}

// ListDatabaseClusterRestoresWithResponse request returning *ListDatabaseClusterRestoresResponse
func (c *ClientWithResponses) ListDatabaseClusterRestoresWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error) {
	rsp, err := c.ListDatabaseClusterRestores(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClusterRestoresResponse(rsp)
}

// CreateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestoreWithBody(ctx, kubernetesId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestore(ctx, kubernetesId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

// DeleteDatabaseClusterRestoreWithResponse request returning *DeleteDatabaseClusterRestoreResponse
func (c *ClientWithResponses) DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error) {
	rsp, err := c.DeleteDatabaseClusterRestore(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterRestoreResponse(rsp)
}

// GetDatabaseClusterRestoreWithResponse request returning *GetDatabaseClusterRestoreResponse
func (c *ClientWithResponses) GetDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error) {
	rsp, err := c.GetDatabaseClusterRestore(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterRestoreResponse(rsp)
}

// UpdateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestoreWithBody(ctx, kubernetesId, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestore(ctx, kubernetesId, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

// ListDatabaseClustersWithResponse request returning *ListDatabaseClustersResponse
func (c *ClientWithResponses) ListDatabaseClustersWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error) {
	rsp, err := c.ListDatabaseClusters(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClustersResponse(rsp)
}

// CreateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterResponse
func (c *ClientWithResponses) CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseClusterWithBody(ctx, kubernetesId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseCluster(ctx, kubernetesId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

// DeleteDatabaseClusterWithResponse request returning *DeleteDatabaseClusterResponse
func (c *ClientWithResponses) DeleteDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error) {
	rsp, err := c.DeleteDatabaseCluster(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterResponse(rsp)
}

// GetDatabaseClusterWithResponse request returning *GetDatabaseClusterResponse
func (c *ClientWithResponses) GetDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error) {
	rsp, err := c.GetDatabaseCluster(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterResponse(rsp)
}

// UpdateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterResponse
func (c *ClientWithResponses) UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseClusterWithBody(ctx, kubernetesId, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseCluster(ctx, kubernetesId, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

// ListDatabaseEnginesWithResponse request returning *ListDatabaseEnginesResponse
func (c *ClientWithResponses) ListDatabaseEnginesWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error) {
	rsp, err := c.ListDatabaseEngines(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseEnginesResponse(rsp)
}

// GetDatabaseEngineWithResponse request returning *GetDatabaseEngineResponse
func (c *ClientWithResponses) GetDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error) {
	rsp, err := c.GetDatabaseEngine(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseEngineResponse(rsp)
}

// ParseListBackupStoragesResponse parses an HTTP response from a ListBackupStoragesWithResponse call
func ParseListBackupStoragesResponse(rsp *http.Response) (*ListBackupStoragesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupStoragesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStoragesList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateBackupStorageResponse parses an HTTP response from a CreateBackupStorageWithResponse call
func ParseCreateBackupStorageResponse(rsp *http.Response) (*CreateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteBackupStorageResponse parses an HTTP response from a DeleteBackupStorageWithResponse call
func ParseDeleteBackupStorageResponse(rsp *http.Response) (*DeleteBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetBackupStorageResponse parses an HTTP response from a GetBackupStorageWithResponse call
func ParseGetBackupStorageResponse(rsp *http.Response) (*GetBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateBackupStorageResponse parses an HTTP response from a UpdateBackupStorageWithResponse call
func ParseUpdateBackupStorageResponse(rsp *http.Response) (*UpdateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListKubernetesClustersResponse parses an HTTP response from a ListKubernetesClustersWithResponse call
func ParseListKubernetesClustersResponse(rsp *http.Response) (*ListKubernetesClustersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListKubernetesClustersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesClusterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRegisterKubernetesClusterResponse parses an HTTP response from a RegisterKubernetesClusterWithResponse call
func ParseRegisterKubernetesClusterResponse(rsp *http.Response) (*RegisterKubernetesClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RegisterKubernetesClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest KubernetesCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetKubernetesClusterResponse parses an HTTP response from a GetKubernetesClusterWithResponse call
func ParseGetKubernetesClusterResponse(rsp *http.Response) (*GetKubernetesClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetKubernetesClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClusterRestoresResponse parses an HTTP response from a ListDatabaseClusterRestoresWithResponse call
func ParseListDatabaseClusterRestoresResponse(rsp *http.Response) (*ListDatabaseClusterRestoresResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClusterRestoresResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestoreList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterRestoreResponse parses an HTTP response from a CreateDatabaseClusterRestoreWithResponse call
func ParseCreateDatabaseClusterRestoreResponse(rsp *http.Response) (*CreateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterRestoreResponse parses an HTTP response from a DeleteDatabaseClusterRestoreWithResponse call
func ParseDeleteDatabaseClusterRestoreResponse(rsp *http.Response) (*DeleteDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterRestoreResponse parses an HTTP response from a GetDatabaseClusterRestoreWithResponse call
func ParseGetDatabaseClusterRestoreResponse(rsp *http.Response) (*GetDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterRestoreResponse parses an HTTP response from a UpdateDatabaseClusterRestoreWithResponse call
func ParseUpdateDatabaseClusterRestoreResponse(rsp *http.Response) (*UpdateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClustersResponse parses an HTTP response from a ListDatabaseClustersWithResponse call
func ParseListDatabaseClustersResponse(rsp *http.Response) (*ListDatabaseClustersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClustersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterResponse parses an HTTP response from a CreateDatabaseClusterWithResponse call
func ParseCreateDatabaseClusterResponse(rsp *http.Response) (*CreateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterResponse parses an HTTP response from a DeleteDatabaseClusterWithResponse call
func ParseDeleteDatabaseClusterResponse(rsp *http.Response) (*DeleteDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterResponse parses an HTTP response from a GetDatabaseClusterWithResponse call
func ParseGetDatabaseClusterResponse(rsp *http.Response) (*GetDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterResponse parses an HTTP response from a UpdateDatabaseClusterWithResponse call
func ParseUpdateDatabaseClusterResponse(rsp *http.Response) (*UpdateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseEnginesResponse parses an HTTP response from a ListDatabaseEnginesWithResponse call
func ParseListDatabaseEnginesResponse(rsp *http.Response) (*ListDatabaseEnginesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseEnginesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngineList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseEngineResponse parses an HTTP response from a GetDatabaseEngineWithResponse call
func ParseGetDatabaseEngineResponse(rsp *http.Response) (*GetDatabaseEngineResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseEngineResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngineList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{
	"H4sIAAAAAAAC/+y9f3PcNpIA+lVQs1tlKTszspO9fXu62tpSJMerF8tWSXL27iy/HIbEzGBFAgwASppk",
	"891foRsAQQ44GllSYif8y9YQBMBG/+5G90+jTJaVFEwYPdr/aaSzJSsp/Pdrml3V1bmRii6Y/SFnOlO8",
	"MlyK0b57TDQ+J1zMpSopPByPKiUrpgxnMNOszq6YeUNLmMasKjbaH2mjuFiMfh6PeJ78WfSNV2wBW0g8",
	"wh9+GjFRl6P99yP91Wg8oj/Wio3Go0WmRx/G6y/VqkhMBgv9UHPFcjsTz0duS+P4e8Ju3LzN/HL2L5YZ",
	"O38LkPo118Yuxw0rATp/VGw+2h/9Ya85iT13DHvtMwgfOKJK0ZX9+1Axalhr2ClVFGfeeGCVHcYMU3rt",
	"vGiWMa2/ZaskjNun2V7jYslIVsg6D8vg6L1MCkO5YIo4GPYed3vCA1JrpkjO5lwwO6sdDnMQOSdmySIE",
	"hD+P3pzjY0RHsjSm0vt7e1f1jCnBDNNTLvdymWm7p4xVRu/Ja6auObvZu5HqiovF5Iab5QQPUO/Z2fTe",
	"H3KhJwWdsWICP4zGI3ZLy6qA47jRk5xdpz5rA7Jqlilm+sD8dKicwuLmyON9bYPdiIHfBvAeFrU2TPVh",
	"YXMOxM3RxT47IpNizhcb2UID/ZILbl/qwypd0cyh1pzWhRntjyqmMinohF0zxbRZfzMNsmhrKVAcUUNn",
	"VDMHgvWP7wwgXAPOngO1W4yFP3M3SpOD0+PpOnVW/DumtMOqDrmcHrtnjmRwgWv8zRIQLgW0wzVRrFJM",
	"M2GAcdufqXDnMiXnTNkXiV7KushJJsU1U4YolsmF4D+G2TQxEpYpqGHaEC4MU4IW5JoWNRsTKnJS0hVR",
	"zM5LahHNAEP0lJxIhTJkP1Dsgpvp1V+BXDNZlrXgZgV8RPFZbaTSezm7ZsWe5osJVdmSG5aZWrE9WvEJ",
	"bFbYj9LTMv+DYlrWKgOyXcORKy7ydVB+y0VuD4h6pgNbbSBmf7Ifffby/IL4+RGqCMBmqG5gaeHAxZwp",
	"HDlXsoRZmMgryYWBP7KCM2GIrmclN/aQfqiZNhbMU3JIhZCGzBipq5walk/JsSCHtGTFIdXsySFpoacn",
	"FmRJWJbMUIu/Eek29KErlvUTxXnFshbW5kxb+iPaUAPs3o9cp4kZyLZemeekjyYzJwOZseenE8RloQvE",
	"gH/mObd/0OK0NayHW0ffGgTeOctqxc3qUArDbs36HjsDyFIWuSba/UqQ39QKKdQsqSE3vCgsBtCqKjjL",
	"LflREhacknNp5R9ndh6qGHFoaEXkTJol6a5oCfRU5p2fp4T8c8ncK3YazcwY2QkQrZ2uO5OhV7BcxnIm",
	"ssRB0aKQN6eKX/OCLdhLndECdcZ1VtYzEj5UyUKTmyUzS6YIJZWSVnyRjAqyoFyQUsJnu5ctOlFBLC1V",
	"VFlIuBem5MJS4UzKguRcscwUq2Z+jgqGkN8LdvO9nU2TeUEXAf6aGSJR7Wj0mzB17wdYrq9qRmhxQ1fw",
	"Gd05uN4nL3aJqgWhmoQ5cvLlLllSTQ4PTr8//5/z7w+OTo7fkDfSMEQM5Cn24C0oHJ+wu4Q1LPlNpZ6C",
	"esQ1ueEilzdABA59LSAYFYC/tKIzXnB/cAk9LxoBKJjne7mSFS6maiEsiwwfpafkCOVvkBdOHiMc5+0J",
	"F4oKw3IyW3Vgo2pheMmmj/HZHdzME2LgIM9Z3traaNzo7u2xh37UquH95PTt+fF/d4BloT3uZSJBubfQ",
	"XF/ljJXy+lfaU4rTBTJLQO+sFjFai4Ymc1LKnE3JKZILspPoaYM3wHvsEGE4LYoVsXrZNS3shxhJlJSB",
	"CpdSmzaazWmhHwdX1knEUvqJrEWCp4dHJGdCGifQ7BQW0e1TUsJjI62BE1S/mFouIgrh2n/VaZj5Zsmz",
	"pX1bpynEv6xhdsVoLkWxIhU1S+10Mn3FcvzBcUKn8+KMYakLu+85o1YnQA5opAUbE3RWWA3k8cAbG040",
	"fyuK1ZmU5hteML3ShpXroP6nkwKwcgMEyyYpfPUEPhvQZB7mCVhit/GUSKJqcaBfKZnSTuwJvzo+Aiyu",
	"hdMDjVqhJujs24RkeWfPvHPKVlrVQjMzJSd0RWihpd80F2npfjz3j++hFUQaAACCz60G0qMK6FgXeAz4",
	"olE/2h9xYf7y5wbg1uRYMBUA/kYKizfrID8WOc8oEiQ1HQCXtTZe6FIipJgA1tTaKlXHc5Da+P3W3C2Y",
	"08SuacGtKg5PeEkXjFATzsdIwoS2lAMrckNyyTSxH+2Wend8RJ6THbvWLkB9Tnlh39OGqu4e+dxPAVuC",
	"IydSIQ6PiZBE19nS78mqG15bqZiy4LP0+oliSD8BvdMpc9rSz7uPoJ9YQIB7qbVNPEFvyDi68gN+79Sl",
	"2Wsu6tu3VTCR1o/k/CWMAcjDXmXHWGkdi0dj/7XjHmkGaGzNB0u+lrVTkctybTEr6xjNlvECv+Uza6uw",
	"hbXj10/ltf3ZvuihBeMIuDNxfTwdvX46SdEsi4Sr9kwWDB0mfhU77qMX8f7PDn5ZVaS1CChVH7tIneQr",
	"ltu0FwEu8XGLpFRmzbJMltWpklYjSVORG0MkkprXFMEeijWdKWJtezBa/fKaW+OFGkRnu9NK5uSyfv78",
	"y79EJAbY0KU7P5W8ZkrxnIXX3YOnwF6Z0cLq8L2A6Y4gPMhz8ALAbz5YwAWhoPJ580DInHlv5oxZcOao",
	"Zvs3QQGYoQfDuV1Y3nrbSHIj1dWUnLihlNgdMpFbY9eq0mOimDX0r5nHjitUFp5pEk3qT8wvDXyNS+Fm",
	"Bp3Vc6s5IjnX5HL02kPgcnQPssH3A6zQdLjiIrdSsruVjntpSr6zykSMW/vkUpCwEzL5aOCfIXP3uvhk",
	"syUTFulO804AZO26E6sCrY/z33Knp783zuGwdqPk+yeO8WIgC47GlquuKFp2Xkr8eVgH//C62AnHhCD4",
	"XERXYfnpOukvSk0PlZ3cGvnnSUfxq5Pzg/YY4CZLppA52eeE5iXXEAC5YbOllFdkJ3KDL+vZNJNlFA2c",
	"aL7Qe+5wJ3Ybu4SLIjihQa8QRnt1EhbJwi7g+yDgGFxV69t8Q70/Nkmy69+eDq72TOyCSHFMNLlJFCDJ",
	"HTiOarXj9WX/0TwkOTNMlQAcPo+dzhGpBQPqmX3TO3iexRLrokEZK2aLakknqJJYPAXE9gxwKYVUCNwm",
	"Po6Ih+4H+GBHeNFWDxv/Uey5mJJzJMkYbW+4WcoaLa2WmwN2opgG+1oQppRUzmHrDSwXBTqVOXh8IYRm",
	"/3qmYxcWCJYlvcbdantUbD5nGYiJGMBIizsc/BKWlsBhjowD3qek5Ld2lfit2FkmcrBc0493rZIriA9r",
	"jO0pxiO9a9rYT7QP3jBj5R1+QKxCW9mm6rtstv4sAf/UwtWzzYfYcXbIU9lyv5oZ3K9DprRK546L4lPR",
	"kQAk0uk39slpXRSnsuDZav24mmcEH8xQ3cKfrMHF53sYxZCkqq2ZFjssYOHxhnXPId9At5JiOvaLVTXe",
	"woeesTlTFkxNUI8JWS+WcQaS3UjBDFnJmjiD0R6G8u/mPkTLhfaqLRBlSBdYl1Dp/JQ3Edd105tkDPbB",
	"+SfwD7l4e/R2nxzkOZHg9aw1m9eFC/ZNSZMbMAb1bkxqnv99C4Qaj24nkVAsaTXxnn8jS56lwhNccHPc",
	"i1ZgLT0wiNqE7RNREHx0hrpbCWKhQU/kGGVVG9YE51U0dv2As4LyZAQFficFhxC8k7SgD4TtjWO1FzQe",
	"/whfHjurUaG2ljLiLgVKRSsPBYpEJ50sewl+eaBxL3SOVoKWPPOgOCi8ERGk2IIa1swdJC4vy9pYZjEl",
	"xwaiprG9YSk6UlD7Y0tn8Uc21KWJFI6De45qQdIare9FYCB9SmqyZUvVaS1TyXyaAL0nzlOZB1UxBoXT",
	"nu30V94rHBCGXlNegJLhGAW9y9RfSxpKmRItQupQnkUzIL8rttLxLOuj3DQlrYDeeMnNBnpDB3GXscJL",
	"Hbop6S0v65JQDFHJ+Rolaa+W3JvVtbIZ9koq6IJNwrSTBu32Rkl+gJkw9/zKM59A0/lOLu78Tn+eoASE",
	"ebgmsuTGsByIJcKKMXjnI73EQRhyCShodey2KnjGTbEikdUH7PyGa/AaUKu5VAVwKoDUxPMX0Cd+Uagn",
	"/VfZkuU1Omh6eINLSXUDo1woH+0PprGRjV8kJOi49xJcWpZ2JiviXntn57qbOhp14Rwia9Jmo7p0xViV",
	"nro3LTkGyvpDzFLtyYH++S4mAT5Ddc0zdpBlFlt7k6ndQhsFb/Kk8D2wqu97WPhqIqFiPrc6QkKlPHBP",
	"0Mu6ULKuwHLyPztYWkGn6oKlpIXM2UHv/EeB0MHt1DtvCLxb6bG2RgUiTbH8qLbgPQ8vHy/AKMWfX96y",
	"rE7nMIEf16GFQmsS54TonqeNSuYAWLtVJ4E0NVzP0Z8QNs9uPU7ryKLwugRItDGZ1RBjLOmKZEspNYNI",
	"Zu58NddcQpImiE6pME/KSchoevSKNq9xTUpryweAeKeDncYqq/DHAjKBtSG6Lu2kN4wvlkaPCZ+yaROY",
	"aaYtGTMgSkIud3Q8sV6301LhmDbjwJi7R5ME15gwk013x4HBU9jjbEW4Ycpb8QrMCABF4Rb2ebKNJmZp",
	"SizI5Qi/7nLkjU87YcgYyxmqK0ETVYrpSqKXGJ68bHb3X+GlHb3bgHPJF0sPTepcXO1T2KCaHQjCysqs",
	"oiOLgGuYKsMGAf5oa+DiVvRYAeUOkDwnO3CC3DzDuPhEVrtTckBEHRB60wJChvndRBqt7jBXD+VZZTJ1",
	"JQBdyaxgmbHky1Q5JlRrmXFqRXKAYBvs+DXra3WPI7Wi1bcsMrRXbuHobAVPn2mME23Smw/653EZx+Hb",
	"LJkEQxfzLseEkiu2wrxqq7pXFoX9YAg+OLS7YisY5JKs1zPt2SrNszDSZV8PWRJhS03oK+lK9LtJWQtB",
	"qsAHPNMuUiKFXvIKs1idvPFp4T7ygHNiXOtYjMkbaew/L2+tUTYmR5LpN9LAn1PyyiBsXpvkDnHuJMmA",
	"sAV5F6V8o4sevfIO0lyTY2H5p9tHlBSLU/hAkpBiAnSYnAO3b+eJP2DDdP1TvYIkkNe9LzvfoeZiUQT+",
	"NnaBIB9JgMT9SjFLRBTsUKf3OI8tzofXBgqasZzkwH0xR54atuAZKZmC20UmW7ZI4O7Mwth2uoLbJwGZ",
	"PmyhIAEdfwOOkAeTsPOnDCQ8kPBAwr8UCX+UUxKleiItFHWXrloATML7z9r6gSXoc0ciF6BTuCuFiooF",
	"Iy8mL54/72ZJffVlIkuqA4dIlwnb3Yaf9Wm42xofDsWCPtxidT32A1CnkFY1N8TaIZFKx0uX/FhJF6Pz",
	"sV5nyORECqcMC8jt/qgdZIyiE2TGwi5kaVflwnhstVtg/tPJDpsupiSvve8Eb0bt4m4x3xcMImvw0BVs",
	"26gVZGZeM2FqzCq/5pkJ3weBd27QfkxbnzGuJJ2j3nPUJ3us4upMLfgvAP/t2Wa9HpVua0uBer8+Y0Lt",
	"xjVa0EeDCw2LgzdHPhHmQlaykItV/G0u+cT7o0C41TPH5S283nSAMajYg3we5POgYg8q9kDCAwl//ir2",
	"xi2sa0If7r9G8lqhzLfx71tlrd+9j5phJichC4TjK061x6QPmbMx+VEKhn5ie6qgcmKKRSXzHb27O4QH",
	"hvDAI4YHllTjySJz6Y8WRHRg6espggX2NN1pQBSugThuKydoTbP8tL2ZuMgAhYvSFVMTnyg/5yJPbMRv",
	"fp2e2pNvNqladP/QEABIcs/FkpoNiPofaqZWcCGikcFRDhDwFK5JZg1Ye7YfYwh1R6Cq4zUr3EdStUoY",
	"eY1xt0nL6p/z11ez7EuOlzyJthW2q55K7YJvbmle99G2fKUNTAr7PPSuz8WOeX3/BMUEqeIsSCklhSyG",
	"nyxBAIR+JhXlSlt+5XTK+JnTQeJp7AxcdyocUOEljp29yyCsemrluKWMkNV2aaFyORqvHerl6FjY36lj",
	"za2DDLQN2YCXiH2Xo7s4y10JQ9vomCHx9l5cGJkA2px+guhmN7jDIt4QXG1wXO37qLVwBbBChidOhjxm",
	"3U/q4CcFw9RQFnTK6GW884Euu4ZZibzrxGveAEZfMirsUXlt9ZluhtjjCMH9MOfOTz/vtgL6zZSDEBqE",
	"0CCEBiE0CKHthVCCCGKR4IxrrA1IDc8az6cf5S4JPKooisVMWhDFwmpNok7vkDpBLq29eZdAugfZjEfG",
	"hZi+TbtVnX+muU4YnDc52fEG3679CiFN+6EwfNKMCCYgWNmtuG/L3AuuoOAyaQAzdlcGomW4Dnc9qA5V",
	"zqTwfhSkA7z25Y4QhQbsByRHA4DI7KcGq2+6kJ4UzjFgf/HuD3+68EU8rD4lL+FA44nbtwe3uPYcnUry",
	"9nNPmP3m3mH2jpX/aFH2jvNgCLX/AqF2eIjo/egxdyw+aYD+LKjKujC8atzyGpfCa1ku6KQ7uGZXo9my",
	"i3MwH7jxNRCUc0FavRkD8V6ZQD8r36i7HrmKpUEzA+rcsUyksNC27GAD9+kWi1jwayYaFrSjd3eja/aP",
	"xxqfhLVd1s+ff5VFvAR+YNuwOSwtMo9Nug6bG7x2g8E0GEyDwTQYTIPXbvDaDUJoEEKDEBqE0CCEBq/d",
	"4LUbvHYfk/znsuyE4Vtn2sWn1ZduR68lz0lVR3XWfmMpdy0oDHl3W+Xd9cFsSL4bku8GN95gQQ0W1GBB",
	"DRbU4MYb3HiDEBqE0CCEBiE0uPEGN97gxhvceEPy3VbJdy0H06+XgXf/bQxpeEMa3pCGN/jvBtNpMJ0G",
	"02kwnQb/3eC/G4TQIIQGITQIocF/N/jvBv/dbzwNL5WYB510aeg1/PE99EJzp07fyXX86TamXMoit2SB",
	"v5JWEykEeqdTNMrYqKndufSNb31LcpDQ9+ykOSXohIJX7DSatYVYT1PNTk/NTm8ie7inil/zgi3YS51R",
	"1BUS+lXPSPhQJQtoCAtpi9S3JoWWegvKBWbyVf5lwFUBzrWKKguJ0MsUiHcmZUFyrlhmilUzf0hd+16w",
	"m+/tbDrqT+u69rk224k2qb0f4Lu90uKGrlxf2/YcXO+TF7u+pW+YIydf7kIS3eHB6ffn/3P+/cHRyfGb",
	"x2gIv96JK6MVnfGCp5tXWUkQjwAUzPO9XMkKF/NcJm653W0c6/uLO/WwNeFCUWGa7s5rzcmfoA8+zfME",
	"GkKKXwsavSbBoR+1atRicvr2/Pi/O8Cy0B7fLXYsNFMZgaW8/pX2lMxlDuiZ2GstYrQWDU3mpAQ/t2uB",
	"jOwkehr3VlaM2CHQVLtYdZQ8JWWgwqXUpo1m0Jhw+jQkYin9RNYiwdPDI5IzIb0lBxXd5RxYBMHuh9gd",
	"PPRDi6nlIqIQrv1XnYaZUdbWOuqYnmzfj93WFKM5aKcVNUs0rkqqr6xktj84ThgankLvTr/Uhd13q0M3",
	"Rk1cK7/HBG+DeHbDb0WxOpPSfMMLhlGVRMcJJwXanV2BTVL46gl8NqDJPMwTsMRu4ymRBHpyv1KyrtJc",
	"9NXx0b0bcL+zZ945Zddkm5mt22v/0v21HwO+cYT0L39OREgdwN9IYfEmEbUUOc+ca8WZOQ2AwR4PffSt",
	"kQ9YU2urVFlDX9UuPPltPWMFc5qY60mPCejY+pyacD5GEiZ0rfzlAUNyyVDTdUu9Oz4iz8mOXWsXoD6n",
	"vICLEYaq7h753E8BW4Ijt5YFdmAlQhJdZ8vQJ9/q5E5bqZiy4LtHA/ZfrwN7qql9T0P7j6CfWEA8VfP6",
	"3yh1afaai/r2bWXSXlh7JOcvYQxAHvYqO8ZK61g8Gjc9edPSDNCYFq6iOCWKilyWa4uFizXRAr/lM+sE",
	"hX1v3k6/afuzfdFDC8Y5Ix97pAc3T+d0kqJZFokGkWeyYOjO86vYcR+9iHENhDv4BU1x4kVAqfrYReok",
	"X7Hcpr0IcImPWyTZyJllmSyrUyWtRtJzXQ7HEImk5jXFRA97wNr2YLT65TW3xgs1iM4+0+Syfv78y79E",
	"JAbY0KU7P5W8ZkrxnIXX3YOnwF6Z0cLq8L2A6Y4gPMhz8ALAb97XxQWhoPJ58wAbmwQvHfagt7D2b3qH",
	"vKVR3245b71tJLmR6mpKTtxQCt3NmcvzomY5XktquUJl4Zkm0aT+xPzSwNe4FG5m0Fk9t5q7XlCaXI5e",
	"ewigD3NLssH3A6zQdLjiIscu0+2tdNxLTbwm4NY+uRQk7IRMPhr4Z8jcvS4+2WzJhEW607wTAFm77sSq",
	"QOvj/Lfc7VS0T5PZgIi1GyXfP3GMFwNZ08A7dtUVRcvOS4k/D2tICgNbbE3shGNCEHwuoquw/HSd9Bel",
	"pofKTm6N/POKZesQfnVyftAeA9wEvN32O+xzQvOSQ3yH3LDZUsorsuNb9S+4WdazaSbLqGv/RPOF3nOH",
	"O7Hb2CVcFJDU5pExat2Gi2RhF/B94H0Prqr1bb6h3h+bJNn1b/dt5u/6/jcOqD7osnGTKECSO3Ac1WrH",
	"68v+o3lIcmaYKgE4fB47nSNSCwbUM/umd/A8iyXWRYMy0JS6WtIJqiQWTwGxPQNcSkhHtcC1TEoKOAxA",
	"PHQ/wAc7wou2etj4j2LPxZScs+iCPO7hhpulrNHSark5YCeKabCvBWFKSeUctt7AcuGZU5mDxxcCIvav",
	"Zzp2YTVtjsJdfDafswzERAxgpMUdbjrREHt6rk1SyW/tKvFbsbNM5GC5ph/vWiVXEB/WGNtTjEd617Sx",
	"n2gfvGHGyjv8gFiFtrJN1XfZbGlEBrvNPbVw9WzzIXYcBCGfyJb71czgfh0ypVUW94/Lr80R95V62EzV",
	"GkTWESEh1TD6VcncMYQQB6PGKD6rQdUTuWUGpYydy17Uroe/4ISjGFjDiPSaBQhd9nyAS877x3ZDXZjc",
	"Ne+8nsCmNdE373MPHiDeWP5dV64NKC3Iwo5eM0PaWgWqX5VlSgCNa1nUJTqgNbKUlhvLSJIt4S4CKB83",
	"doolr5D0qAmvA6HYx0HYVTIHZfAFKtLyBoI+r46PgnpiR31zDp9IvsRRmpkFz8kMuZwlrR3BbtA7a8UW",
	"jTLT3NJ+trC4m3KXfOVUeCuXUPDPuPFNXZ+5uxnqZqJuJpPJxO7Vu80Srjy4liBz7iqONJCwKNcsoX3c",
	"G3f3SzlfHKYcwlGdyoJniXSExCCnlGsyY0t6zaUCzLYDIA+g5yM943UnMGNzqew/9h12W0kNh6StaQjS",
	"7yIWqF6CWwyFew8tDET7w2K1VIa4HZMZtVOG7ex0YL47JcfumEASCulkqLUwWLVkJVO0aC8EvlCq9y0b",
	"UfbE0QIraYVcBLJKcq68jROyehi5HL0FH/IJ15DxcDmCNy5HBxC2vRyBXLAHHOnuzVN7uqiZP0lw5JOI",
	"KvzaDjQXNmuSK61uOUQZPuEowxBi+Ei19HdMao8SctjG6fLkMYff6iEOMYjfYQyCdcwNn2c7xAWGuMDv",
	"KS4Q2+agkW/s0Q/G+1r2/JwrHZJSQdHgoiNR4Kqu98as0fwzy+Z5SdXKqv4oILxZtcPnjZjYxRsM6EMo",
	"WTlDW0vH59NRBUFX8QlqNc83aD1dqSokaRxI4dtD4US4orFKC6Mn2SGmMRuLx8H9OoYr+S7ZdxWKE3CR",
	"FXUeXV0ooH3/I/C2kKi5he7TzQjVK52ZIoFh5/gA3GfRtbdwLSAn7lWgjAAs4NenUJKTm6U9PLTJo/E7",
	"fRm4u6SEOhjejihoLbLl44Io9ZHBm0HJFVOCFaSiipbMYDVZXGJNhoikJ/qNC5oAn7KjwVeB76fvmq3P",
	"8Z2/N7HFJN0u/nZTfuJt7l/9KkFIixrAtmN2M0Qjh2jkEI0copFDNHKIRvZdC5EwcUG19pBPZPm7UjSp",
	"ey746Cy+P5uHuvh4Cli7vFUQPdzrX2PrWUF58o4M/O6KKYULrJ1KOZH6CVLEP8KXx84mVygBU2l6lwI5",
	"jbuTbtlMdB823LwAPuIJ+WglaMkzD4qDwpuDgTMsqGHN3IGL8bKsjWVIEDTJqGhZjlb9i6R/v8Z1Fn8k",
	"gWrmFimwYj5QhcdSC5LW6AT8N+hgQNEQZ2mJj9YyVllNgN6T5KnMg/iNQeE0Ejv9lffIB4Sh15QXwLhd",
	"KIve5UhZ09/u1Ns617gtmsFd7iu20vEs66PcNCWtIL7PS242xPfROd91u8FLHbop6S0v65JQvIQEce42",
	"JelwDZecSKgXNpf7xOsuzT6nXO7lMtN7mRQZqwz8p7mvuldSQRdsEqadNGi3N0oAznU0uO9XnrnXut/J",
	"xZ3fqUKB/eM5CfNwTWTJjXG2Em0Z4qa5WmUkcRDm89Adgt1WBc+4KVZxbBB6bNxwrDlHrTTwfgP7ERPP",
	"X4BH/6JQT3FvZ+NtZt6ho0f/CCMVXbBTTEVOuDm/ptlVXZ23h4EyHRUWcfdDgx1jZOMxI1kh69wnO6t1",
	"pjOrsytmkrsLUEkrBgeRlPcGA0VVixy9OcffvDvdGvNB9B/8aHdmWbfv0ZJUdBudWJ9DfDq5SyZyUD3e",
	"qSL5vFJszm97pOvC3a3uOxk44ISlfXHw5ujg7GhM3rw8OHt9/OblmBy+fX2E/zs4O/zH8XcvgTJeHZ6S",
	"f0hDdr4B0hUW6WkGVzpz7KmSo65hVZ7dMTmUsiA7x2K+3fADlS2tVrpzRhXbOBZ2A4C/m2+vAz7JxGXB",
	"VFMLYEMjkUrmKHQuwiuALMZQaCVi0QKfQPbSilisMq7tS9QFxSio8YiFBEPBkzEq566aYK29chDqQ4Q6",
	"Jfii/xNfWKcInG79S15iNgWPgtfM7dQlWhiJi/rqDVhjA8U21I+MBmtXwzLigN56iLIs3khXeZSNySno",
	"F80voBe9kViDNG0qJmsffdvUPsINtWofNafaqm2y6YOsoA6VflxlJcgcGTeg9yECLP7zX177K2dc4GI4",
	"tYcgzO7hIHL4E5a5Xxmmt/cowxQMgHQBpqjq0ssfalq0DRr3kxu0Vmnnhhd5RhUKS0RaoqXTiYE8rArq",
	"aaABrXZ+M6oMz+qCKmIxbyHVKh3ECGd3zjIp8hQ5dofEoDGYKMZdsU1InGijxI5rTeROU8496gc8bAny",
	"ts6NlXN3I1oPODglX6+81gAahDOoIQ3NrekQxMGoQd+5VOyaKbKTS3gH6sbuTsn/MiXRwmYLDCw5hAqp",
	"dy6VjmrynOxguVlelizn1LBitet9RO5K9Hbh+I1e0BbZobXZAXBgd3JD7ayWtRpcOZ7kAvj/BW4AotgC",
	"UAfxZMvw51qJn2R8rKWeQNw3wqYZPCROkkIsLl2jjCk+X128Po8EceSewIS1tJPxu/CsTeHet0t9NKjR",
	"h1z+myXEWuRMFSsrIqyInFGdkgYWqkc8wVxeuic+7Es1TBOvUK70D4VjnnZka5OGlZVUVK1cbRWpHBvW",
	"S6owMgueqYLPGZT0SBkE4AykZtnjCaRmeff2wsjW9irFJsyim4UPRiRVtNOopAQpqRW0Tfu3UCvG50Gm",
	"YvCdRl/Jb7C/evs1uXQgEhiJZQVXZcHFFXARoPS5DAm99oHfjGK0gNfubUw4jN5DSOo/2I3A/u8XV7Yn",
	"EECPmNySKZejy9HTba1bK90OSml5FVOaa8OEwS2CUyGRqp4aBnEeIMUVOf3uED3bPrbWxUPATnBELKlu",
	"NbBDZzMUBvFut7E7VXQlBSiCdHbENiUH4DdqSTe/i8AcEmVuQIU+kXnK6RY9bKraYa0ebUHpFHAo3qLj",
	"z3Rsekmv2UfjW3MUE3++uNwElpu8uFfRNgvuc7B/1z+zedbEinz0Kj5Uxq2w2SdfQP1SzywcVxa00ktp",
	"COIS2dHuh6n7nunVX+Fj28N3O5PZE9tJYtduoH1r3Gou4VqugrKGt4YpQQtfrKpgCj7Bp1S3i8MBW0RX",
	"QMM1MM+eUCLYTcjxxgxskYw1JedrCtWTA7HCzR9FwI28lKA1YsWYMYkOIKzj1ZZMVi5K2Yw6Y3PMXGj9",
	"tN27GCJpvThtih56Razxwx93qhjCJYVWaLQzW6tTQWoHCSKseN+tj9NjzNtwuhQmQnimEhyXmIcfPLK4",
	"7fjdTmZ6+wS/5SIPSm5IqFDMzoArTsk3gGor1xvWLLnKJ1ZRX2Fu/bi1WvCiJa00LhK1oWAPvF0Zqffz",
	"UtNucCd3opD3mLZbI9Vufdzj6N2mPmcLUTYxIotHTZVO0IuRr8AdYDQRjCSVrOrC2wfhcoxZAraNMQ4a",
	"ytP6AVAAUqOXE+IEJYVYABxvtEr8asAEsiPgopXyO4JKlpSkJSIOCWwhto8ibPT8hrsepSHGqussYyz3",
	"tfc8XrSx123ZmxLQtYMLbWhRsNzP7QAlgWXmGEeJOen6hRVXcRcDr7XI0PfMTShmuSY1wHJ3t0z4HONx",
	"0cWzAMwx5hYl4q7OILe0Zs2JG6pycBtU1HAs2zZG9hVzI/HMtIN4HT4Z72Mn2vQa/9xtlTL0XXvDvgit",
	"jSyp4RnUXeMYj0FglMEJ0pRzBUYBrCeUR/5nd+8bNx7t1X1lelsR8wq1k32nFLNUjBFuTQ9DhSE5n4eo",
	"1YyZG9bi3uswscL+n0tIWWxG4V0mq5BpYm5kk1uD14zk3OGkHnckg3sHa6SKSURFY4s5N6wooMTjBlrS",
	"09SO0NlgTRHdcavt5EpWlXMSlrvdHYG6qK5dzfVQjFzkZMFEcFFidgGyk+4SrVOc3gUuSM29AzzuKaQ4",
	"irjK75TsfM0M3SXvdCdLolWp7k7Vo1OvbuegqJbRrLGwx+nlvLPT1nqHSmJYBF65z9KDIvC5KAJRae30",
	"3IGjtfFn0ypRnhowddqrZFJAnhu6mgrMeeFi4e2JMz/fK2UZnJOGEexDezEcaKJVMPUPvAU0+v2ZxnuX",
	"8DyzVlk8gVXzzxlKrc7iuczqEMME5MyZobzQDZFd9BDtg4joAVrb5qyTODDcsqx9LLkZ0Gf9Qhw5k9dM",
	"4Ue9vK2osErHN5QXkM3lPq0xiCBZyN9WDylW3gpNprc0CSd2vMISx5Vi11zWPnNrVhskbsx5njmXgxuc",
	"0YpmWBg2kypv8EYbamrdcEJgClYiPaZl35zBkKYzpOkMaTpDms6QpnPvNB3d23kqtPjBNkjdLlSOC7vQ",
	"kSUpBRB0FvnQgGlowDQ0YBoaMA0NmO508MaJdOk8wu6I1B2Z82hMY8f5q3ePrXtndhkIp63TMww5kXni",
	"Q5pn4Q7eDXA0Z7Q33uaeLwhX5ZqC/qgF4700dHR2Ll/Cq6jL9+83DfjmmQe5dzgHFdl7F7sOOPDGBpcT",
	"bv/jbkJse494C2mfFbU2TJ3zH1nKOgoPgaaDLiVcqBakmjuW0G8CX7Jk7jNEsB6MRtDDUwj2WsUpWh9T",
	"DdnfyFdbNS7HOIid/hA0oEQj6dbzhqCpS21psn/93tvxSJ/css753MPjki5Y/7rfWQSQwi7jyq5eh1/U",
	"NXee4tBtw5rMZcmERVI/cBYyvDZu5CKZMeH3gcSkDRU5fmpzI9dPoD1VnZ6cgJ/ujbwh3DzTpLrNrNSr",
	"dJnPnGt6Vhtyw8C0ZLeGiZzwnu3NjoVdNuXuOvraP4vVjZZbAtRx1MEDJnnsWrfwqxqkl1i9nY/23/+0",
	"ji9rIuzDeFRRY5iy+/n/di4v//Tvye7fd3beP5/854c/7VxeTuF/X+z+ffff4a8/7e7u7Lz/9uTVxenL",
	"D3z33+9FXV7hX//eec9efth+nt3dv/+xKw+4MBOpJm6L+0bVzAKS6ytPor/NLyxZKdXqt/t9KZG+RUph",
	"IWn+NS0smSQU9tfR05i92bfIzD9oqlh+IxU5/e9DJOwlrZS8XQFx2/9AWhuMOD85+hrHlFIsZKqt1SO2",
	"tGuM1/RVBUiHSzO4c8dGL5C/gUrduAG4WCjIK2JmKXPPSRzrTbEr7tn52pP4GFz8hooFa+fw35k9NFxM",
	"HDyeg8fzcTyev1lJ/9t24f4+jm3wST+2T9rpvlsYhUbR+ZxnfaWMncrw0iW7XsSjQY1ojmwpb5yhm3Pt",
	"CoUHy80tg0lYimWMX0P5sSabibilnmlyOfLJtcVqMqcZF4vLEaF5rrBN5c4bmbNTqYweE7+z41OXQtNS",
	"8o5P9e49arHF78LXBSWxMQGtbuN1RR0kKFSmQ63QaoheWZw7DdKZYXrsVER8AIqjfwSK5WIma9g4PJfa",
	"WJXshyIM2vJmTSkFNxIprvuNJ+FZrAI3bzT677qONDRUHhoqDw2Vh4bKQ0PloaHy0FB5aKg8NFQeWh0M",
	"DZWHhspDQ+WhofLQUHloZjA0VB4aJwyNE4aGykND5aGE+VDCfChhPpQwH0qYP6yEOXzsaV0UfQHK5lkU",
	"iqSkwp/mcIF+D8MRklS1tbe6fWtS3KMqUwWoTk6AQ4e42enJyYZw2ab8qAVPp29VVOsbqfL0w3pW8OwA",
	"46DpkrJMXTNlkXzDY+942EKpH1KwhhSsIQVrSMEaUrCGFKwhBeuRq/cnA8+01gkmfGp/ji9+gCfPXw6C",
	"l6Aeu5Amrb1i8/We23HnzcNGtxGhL5t7Fz0f/fdL7qj3Hl2cWruK1L0i1Lmp07oZk2wACdUyNtxocotj",
	"UQ1/cQ4LvIFOlEPBDfjeo94yvcs+tapkWvepeorRfLVlLt490vb6vvigqs6Nq/ToK2k2ORLuEJ5p/NyP",
	"1so7cH3NtbkT+HaQU65cuZz2lXCsnauDbRSqc3ZxTScrOLnLY8kaTv5iWXzw7saYPflsyUqKy/Ko5gwq",
	"cpYCRCipdw4KtPaegUyKa6YMXEVbCP5jmC2Yb3CF3ZpZrlioK8yOqQorohhAohbRDP5mdoKBLbjxFYgy",
	"WZa14Ga1B7ldfFYbqfRezq5Zsaf5YkJVtuSGZVYN3aMVn8BmBfq5y7xV/GX9aofXN/+o2Hy0P/rDXuOo",
	"2HOfuNc54LurS9HW5fMG0l6dPnt5ftHofnAaDlUaztecgYUfF3OfJhHcir5Zh7tdyS3i63oGMiZckzNy",
	"Sg6DZ6+ucmpAgglySEtWHFoG8NQnALcDJxZkyTPwFn7EVu5Bk2dMG6nYnWTpxnmP2zkSg8/d8bTnSE/h",
	"YE0OTo8HKnxyKhyo6RehpvFIJ33zaUoBD1CMw74s95oG0X4v0RYJmhf0Nm7Cx33ls7+OnnYaNWF0BlW3",
	"UH1Zgda8YIZQ3zXBuSaRqPsqlf9YKzb0jBp6Rn0+PaNyZvXG/huy/W5Z/dWA6QOmfz6YrnVx7FQaHNXf",
	"BFDfOQLBfdfz75+ySQ+tC7Nxmx0otfaUZAUdCyVZlmljTZCXYsEFu+gUBIGA51pREMJgsJ6SM+jKL3xN",
	"EMxRv81A4YTKIFPyD3nDrp0zzF8g02NSLVwxNF/rV4fuBZth0f3Uzoc9wGvi9Z77OE/uUn2sNVkwg9cr",
	"grvDqo0Tw8tkRC6TAt2zmzoBHvpBjV/BFcOFc5OCEWqVvSYCWyu4PBW+ALTfg9Nj4qMlUzKZTDB8o42q",
	"scyvtSSg8Mw8NCzyDZBCrTWXio2BDugdNEWIT5tPmRIoIcFuqYXHmFwKTIv6RkoHb1zzJ7K3R87a1XAR",
	"+tRltFltby7lM93+pKl98Vshb0RqdVgLc59GBz7Ucjkak8vRqZJQDgLuXqKpdDk6YgtFc5Zfjuy0f4Li",
	"aydMLdi3bPU3mCz8fI6F2lZ/wzpt9veCa7h28beSVuGHE1qFl8PpafL+g1XYr19MmxP9v39pKfYvI0QY",
	"y9LiQWVWlyPSWnX/cgTr+t/9JvcvAbHsz0oaOavn+5ej2cowPX4xVqwaW5H5t2aFy9H/2TPZ23PU6C4g",
	"/rye5ke1uVBUaHjvgqfE9fqYpjyhNk0vvLA8MWG0RTVrklkMdrWBwQkO23LJJ026Srh+F7Ufa2bNllQs",
	"rH2GhftoyMu4snjiuqs0PS4xUzm0mDk99olROA0oHVCvGuKZccr1RnqOnKadynj4AJWZZV1SAVdeIAoY",
	"nmHaHxYwQfqmM5/u0kCt22rDdUtoutSV9PY1EwuzHO1/9eX/85e/puo/Oib3CkvzJ70b62O6paun3v6c",
	"Lpox8XUNdzY3FLVJbANUV/YbLIfgzv0N2S3JyXig/GJFXnw5hrJTsPQa3b+//TBNbJlr8p/jzn64Jhas",
	"WIvftTlRDFmoTxReZ6Es7DeZgu+iSqP958nLLozqFJDx9/jScmV5FC2hPQbhoDDNOdzJC9jhurBpVxm9",
	"9XHPtCO8CF9OlczrDK5jz5uUx4gioaKXRSgUhITdWlhEHVVFDm0kozppPtqNXPQm3O1icRdWXwKW5YSS",
	"RU3hqijLwdMG+bzdVoy08a14hI6TDOwWnT8GS2u2sf3F8y//DAcRfmgFLt8fTP6XTn78sOP+83zyn9+P",
	"9z98Ef35ASONCUUxrVU4rtVkPvl0LVcC4AIuIn2DV37eCeBFdtNMWEx5P7LPR+MRDBiNR25EpNhslS8M",
	"EcyA3JF/igCRWRE6ddIYkioj/5VVA06sYtZQEgrQ7ilCDUNCMyW1juKkBb9iJEhZpM8ZyyCyR9WMG+jT",
	"2FBp1BBtXhdkRzNGpkLmbJ2gd5Fs/aVYI0kOyd4Fd+qKb8Xiq3Eu2K1VPH37Hq7JTi70ixdffnVez3JZ",
	"Ui6+Kc3e7t93fqhpAUaMVcm/Kc1uh2u++Es74v0e0ePDzvuJ+98X/qfdv0OketOA3S/2IMod0OzD+0mD",
	"ctMPX+z+PXq2+8c71eKEXG5ET+A1AWvHdxaHbC4y3+FmsCv77uz3UHM3xRKBwyazgLyC3nYFeobc8fDd",
	"0/b7qJCg29NWkcFo7KMECIkPUwwhik8yUOhDU0OE41OIF6KHo59I8fkd8UHn+RjigkNc8PcTF0TK8Hd2",
	"aNN6mHZdgus0YT5vb6P5WJ+ig9l9fIkve0DYt1SzRFobYo6hCULJ1V/1hhQ26Buv0wre/bQi3NNmbagZ",
	"8zAtyOPFwIc/KeXHydmBff+aSs9LpVKdXOBn8GtJAd6FTuOdXpsstca3Ics4Cjt1OtOEISS0uejcHUrf",
	"APJXNJyLYrQPvjQ73Z0sm29sx7e2ac+rtsLx9U9OGMzvAH/a8XSqaCqM83U7YljZYcwwpXs66X+L7X/W",
	"U2ggtN5/YQ9D834ZHL3Xjqlv3+zyAO/q+TR0R8XxFVa/kOvdEkL06BnYKk1dXjN1zdnNnmtIObnhZjlx",
	"zVv34GLU3h9yoSdQ2GECP4zGEb7QGz3J2XW6OlV/MB6isn1grpOB/+R1PgmMgVa8pNnSAnk1ra4W9gcN",
	"Xu3p9YupRb0ThjTdvVyCT6JbCuEeJIhJvRJmyQzPIr9buKc6dk1N7LEUob3SNVXQrtH7J33D34OGyVom",
	"ChdVQbVy/sqf3sJIu50x8Rv7OV00k4s6gTD+iY9P+LoI4dYnJGvBtaJQcKAuZ0zZ5YEuiWKmVoI51zJf",
	"LwSFN/6gchjUjwRQhVtVsWfZypGK/uB7O+OWfAo51xoeoJboBISX3pEssUeAahyIG1BUIAPdKM7cTWHB",
	"bkN5xOZ+V4D7IUIF2z1F/lSYK/JqV1JrDjfD5vGXtkuL2u/2cSpIyMCSVVDHgd2QkovaggsOt6I6FM/w",
	"R+91It87FaGN0bC66YccThJB6asYYEgio4WHlIO0cIFhpU0QOmNSi4JpTVayxv24KrkOlEZeMeFaxPvW",
	"0E4u9ZSaKykXXCyODSsP0xX91seEi/cBz3Q905gI41DO7R6OA2tuYJ/1dsug5vj9B4Y2Ye5XRCHPbHNX",
	"iUa6GGtoz6ZdPLK9q7BzvylNagwIhOZUUVf5GSMFmxtXWMwO8FeTXF8xzRSnBf/RVSuJN8qxF3zBDCM7",
	"jAP+e699c6M9W9YCehXJ5qlxt0lDgBcG7Tbf47qlC4l42f0m/JB2f/z7folXA2WR+5az1y+mL/6D5BKb",
	"UrO41gXifshtsB/hJFcaU75g2vASAm1fIA3yH92doUwW9vxgE4egXgZzAKrEMWCkfXObcHtdKl+X8ZZm",
	"ZttyeW3qTWSPoWzG2LePG+qIjTzTkTHieIA3fVpmWQjRYDUH96UQgHFVJZBZ+PbqQNkhAI/NuHyFHqOY",
	"VbAJDZw4mhKMeeBQpBYhsWxGs6vQnR92PiWnsqoLGtWZ9dUhz3zhyCdX2q26AlHhbDVxpYcnVOSTwM6z",
	"VTIOwYr5ay6ukq004QkaSO/OXnftonAuW33/pbgURy9Pz14eHly8PCKN+opUpo2EykEVXdBuXQ0uyIvp",
	"l88tBjNrbbfZDdekKqgQKDVngNxQ2BZfe+Ff27Km1lbqEjpTDtMXB6OHPgXVaQJcICVZ1MbcCSsWK+7m",
	"g4KNtWopTRl0vgJ8LuvC8Kpgvn4I1LMVmaVeplJN9gE+aS281eQ6smytSmzlN95uhDOA1caWQkJ5Gmux",
	"/r/nb990Wd8JWL4gkUgukVlWUps5vyW+Gw+41wTTQHXG1ay3up+1WfCjfmRKTrjI2S1kzHyDCUBWD6FV",
	"xWisU1gdHdxKUbdN2LwmeQ3p9y59aEmvLTg7MJwSrMNEC8DPl6iy6/1LQcgl2ByXI1dNCiEWfvT1ul0i",
	"hgchvgjC5P3zD9MtZkCVBDcf7vW7KS5H98riOcDUnUlI3YkehyQAGokYAMKUdHMYZqHUO3DGCcfEJ0gJ",
	"6ivl15NAckAcFd17U8eO9QdNGfOIUIaDCtAmp6BfPzqZH2G20/fXX/bRuhvh2++imh1utpOGKpHCTg7+",
	"x8tazy5RkTbSM4z49QTXiDQ8S81nLtvGEzUl57Fl1W5b2RBdXIC+URlANPKFsDTmiAd27dSXpiKFt7p9",
	"kgeUywyzo3nk9A+qde3z4qlYNaM8vsHhWr4HmfRjq4NAHp1fJGHjAZWnudshcgDX0xYZkjfGfOqa1jLj",
	"ILIgwQq7kVqgeWAiL4YKZVBrLX6K3MifFc4JpdTtuq3iIZtcOPcWNQkPz6K/JDQ8ikDd5fYpEDiLPP7W",
	"6fbhMLsqVAN8+KLkrSBalr4ZLvcwz/l8zlTjVHVGDcubJb7lIv+1faSi1/8F3qcHw4fs3DQWDbId7FcM",
	"06ON6BRl77fJd3s4t1Grg7mBDiPSfs56ses56dQVhPxULojGV8iMzaWrnhfOKy7lBr6I3HUUceoLusnR",
	"exK7xIH/QAMQqAkEFoFhhIJlQyYuPCd1mMi0pVeYcylvSCEFVJm/odyEXdIr79jvTr9lV9eaJ5D/3fFR",
	"9zSnvccUzrvvqLr4m/ZR1pqpyaLmOdtrcjH1H2qewsoHisEN8g8/DV01TmBDPSVaFEF4iGfGj0CPlvc+",
	"DTGzp46ZZcm21uf1YoGc8x8XF6f+bOzYJocWOc+YPCd87p0X23Y+RkH7iDIw0sOGiN4jR/QeYFHEScbg",
	"0GYb0h7j2OGD0SIELR5kgNwsV52d420j+LjL0TeoB16O3Ic+wDIhB15Tzwqq0P9FBZKfgyKQ36yOmjuE",
	"utk9Daz7UjLOW7nfzamQtxBL2SeXo/MaInnWFlXxlz45OlptApxT7RTgjZkeVliJuYSgFzcQVztlKpOC",
	"kpfXTFm+jMgzilJIRi+mz6fP4UpJxQSt+Gh/9NX0+dSyLOhXY6fbw8uSExcqxDrCzKRDYcFkdY7D9kVL",
	"+ykB1Me5e6cVf9WQAo3WGyz15fPnPmbFMGIARZ6xqOHevxxWu2+7g2zaK0E8GSDX5fxw7vO6aPDCwujP",
	"j7gTjPonFn8ndM/y//FLLO8v73qTm7mB45Guy5Kq1dbnbOgCahXOYpiPPvw8HlUylXN0CDMRSgS76d7P",
	"DRkJbeTBV1qHOgr1876WWOTqUeCVWMklCiRgaM2Y5Ac4B6yD2ShOhnAV8H4ZzB+Q/v5IvxV69uH8z+M1",
	"Lrr3U/uHCc9/RqIoWOpGxRH8jhpFKHPc3scafeA7XfqIUlf236/ZssHrvTY3h45r1Cx90s7+aO0T1nB6",
	"HJ1NV4h9WMP3P6fU8AEvN+HldnjRz4yTkvwVM/fDtFfMfEZoNrDVTwZ9t8C0DYoENdkyVZlUQTsGtCWD",
	"HdazwpRgFqDLUm8PRQf/dA3fE4mDnxzKP74W1J8uuZ0WBPDR1sTqAXTTbMW5AQYd6XMi5vsR3h36UuPO",
	"3crgVGzBNQT6SZTK7OuzJu3OtRThJ7U90+nMA5Y9yPy889Q9hl39VW+wPc/cNIlJCBfegbKGRP619Vzz",
	"p7RC11bbzIMTn/SR1uiLp6OFgQ7uTwdbI22bBtq8de+nuCo/mqBbmgTry6bMghRtbKknJRdI6EqtL/hk",
	"TIMBx5/EPEgixX0wfM/fSpy49ye+NsO9HNu9FR584tq9CMWukC5JoH8v9LKhWsdAOI/io38oynoqy9O1",
	"M7Zw7fft4KNoBmftKeTxqRHN4yuDfRVM0lpgP+R/7cjE9t/RR/OPqZluv5tDR1WOFeBGvvwVNnIAlQ5Z",
	"PrC/RLTmgRznTpb3sbrG3k+Wr9w/4vMYjBMn/vQZ5zjZ988t33ewkExkedlc1iJ3WdInLq3mvb9d8MFP",
	"09N6xKXApb/I3cH+NNSme2YoDqrU40TYnoid9MTjziD5UD8BL3jFzMAIfhOM4OF61EDw3rH2eNS2jc1U",
	"Jym+Kmj2FNIfg3gD0f+yRP952H8u7DrYf/e3/+Z1MfDQmIc+Hv96bCPsYY7eR3Pw/l49u4NL9+lcug90",
	"5X6UD/fRfLe/P6ft1tL6U/PSfiLieTu5XKye2Dk7eGUf6pV9KNe6rwbwse7XR2F+Sf/rZ2t6PczkGjyt",
	"A3/Y7Gl9dF6x9Z2HRyH2dQfrQOmfmSt1IOXHSNx6Ajq+h+f0UWg56TodyPnzcZJ+nL31CXhFBxb0WC7I",
	"X830cD0w7vQ9NvWnu+0zHux4fOm28DvzO0adTgYyepDb8cG42SUj14Hk3lQU2e/3VeZdr50H6vJu45+d",
	"7Gd+35+LDj4Q7xOp4feig366hRrZUAYM8B/6boz2rl+MLHa419Z621wztTJLLhZEMayL7SrIRWWvoyiZ",
	"p42/6tE6mvdP5lEoMVVXjH/UtI047cwa+ip9/F5JdP0jveemZeX2q3zdvYDbum0ebj5/+Pn/DwAA//+R",
	"tlwdisYBAA==",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %s", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
