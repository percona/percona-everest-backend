// Package client provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/deepmap/oapi-codegen version v1.13.0 DO NOT EDIT.
package client

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/deepmap/oapi-codegen/pkg/runtime"
	"github.com/getkin/kin-openapi/openapi3"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeGcs   BackupStorageType = "gcs"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeGcs   CreateBackupStorageParamsType = "gcs"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for CreateDatabaseClusterSpecProxyExposeType.
const (
	CreateDatabaseClusterSpecProxyExposeTypeExternal CreateDatabaseClusterSpecProxyExposeType = "external"
	CreateDatabaseClusterSpecProxyExposeTypeInternal CreateDatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for CreateDatabaseClusterSpecProxyType.
const (
	CreateDatabaseClusterSpecProxyTypeHaproxy   CreateDatabaseClusterSpecProxyType = "haproxy"
	CreateDatabaseClusterSpecProxyTypeMongos    CreateDatabaseClusterSpecProxyType = "mongos"
	CreateDatabaseClusterSpecProxyTypePgbouncer CreateDatabaseClusterSpecProxyType = "pgbouncer"
	CreateDatabaseClusterSpecProxyTypeProxysql  CreateDatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DBClusterSpecProxyExposeType.
const (
	DBClusterSpecProxyExposeTypeExternal DBClusterSpecProxyExposeType = "external"
	DBClusterSpecProxyExposeTypeInternal DBClusterSpecProxyExposeType = "internal"
)

// Defines values for DBClusterSpecProxyType.
const (
	DBClusterSpecProxyTypeHaproxy   DBClusterSpecProxyType = "haproxy"
	DBClusterSpecProxyTypeMongos    DBClusterSpecProxyType = "mongos"
	DBClusterSpecProxyTypePgbouncer DBClusterSpecProxyType = "pgbouncer"
	DBClusterSpecProxyTypeProxysql  DBClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterSpecProxyExposeType.
const (
	External DatabaseClusterSpecProxyExposeType = "external"
	Internal DatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterSpecProxyType.
const (
	Haproxy   DatabaseClusterSpecProxyType = "haproxy"
	Mongos    DatabaseClusterSpecProxyType = "mongos"
	Pgbouncer DatabaseClusterSpecProxyType = "pgbouncer"
	Proxysql  DatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterRestoreStatusConditionsStatus.
const (
	False   DatabaseClusterRestoreStatusConditionsStatus = "False"
	True    DatabaseClusterRestoreStatusConditionsStatus = "True"
	Unknown DatabaseClusterRestoreStatusConditionsStatus = "Unknown"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	BucketName string            `json:"bucketName"`
	Id         string            `json:"id"`
	Name       string            `json:"name"`
	Region     string            `json:"region"`
	Type       BackupStorageType `json:"type"`
	Url        *string           `json:"url,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// BucketName The cloud storage bucket/container name
	BucketName string `json:"bucketName"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                        `json:"name"`
	Region    string                        `json:"region"`
	SecretKey string                        `json:"secretKey"`
	Type      CreateBackupStorageParamsType `json:"type"`
	Url       *string                       `json:"url,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// CreateDatabaseCluster DatabaseCluster is the Schema for the database clusters API.
type CreateDatabaseCluster struct {
	Name string `json:"name"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *CreateDatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *CreateDatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size CreateDatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *CreateDatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *CreateDatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *CreateDatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`
}

// CreateDatabaseClusterSpecEngineResourcesCpu0 defines model for .
type CreateDatabaseClusterSpecEngineResourcesCpu0 = int

// CreateDatabaseClusterSpecEngineResourcesCpu1 defines model for .
type CreateDatabaseClusterSpecEngineResourcesCpu1 = string

// CreateDatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type CreateDatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecEngineResourcesMemory0 defines model for .
type CreateDatabaseClusterSpecEngineResourcesMemory0 = int

// CreateDatabaseClusterSpecEngineResourcesMemory1 defines model for .
type CreateDatabaseClusterSpecEngineResourcesMemory1 = string

// CreateDatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type CreateDatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecEngineStorageSize0 defines model for .
type CreateDatabaseClusterSpecEngineStorageSize0 = int

// CreateDatabaseClusterSpecEngineStorageSize1 defines model for .
type CreateDatabaseClusterSpecEngineStorageSize1 = string

// CreateDatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type CreateDatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesLimits0 = int

// CreateDatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesLimits1 = string

// CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for CreateDatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesRequests0 = int

// CreateDatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesRequests1 = string

// CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for CreateDatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type CreateDatabaseClusterSpecProxyExposeType string

// CreateDatabaseClusterSpecProxyResourcesCpu0 defines model for .
type CreateDatabaseClusterSpecProxyResourcesCpu0 = int

// CreateDatabaseClusterSpecProxyResourcesCpu1 defines model for .
type CreateDatabaseClusterSpecProxyResourcesCpu1 = string

// CreateDatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type CreateDatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyResourcesMemory0 defines model for .
type CreateDatabaseClusterSpecProxyResourcesMemory0 = int

// CreateDatabaseClusterSpecProxyResourcesMemory1 defines model for .
type CreateDatabaseClusterSpecProxyResourcesMemory1 = string

// CreateDatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type CreateDatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyType Type is the proxy type
type CreateDatabaseClusterSpecProxyType string

// CreateKubernetesClusterParams kubernetes object
type CreateKubernetesClusterParams struct {
	Kubeconfig string  `json:"kubeconfig"`
	Name       string  `json:"name"`
	Namespace  *string `json:"namespace,omitempty"`
}

// DBCluster DatabaseCluster is the Schema for the databaseclusters API.
type DBCluster struct {
	Name string `json:"name"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DBCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DBCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DBCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DBClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DBCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DBCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DBClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status"`
}

// DBClusterSpecEngineResourcesCpu0 defines model for .
type DBClusterSpecEngineResourcesCpu0 = int

// DBClusterSpecEngineResourcesCpu1 defines model for .
type DBClusterSpecEngineResourcesCpu1 = string

// DBCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DBCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DBClusterSpecEngineResourcesMemory0 defines model for .
type DBClusterSpecEngineResourcesMemory0 = int

// DBClusterSpecEngineResourcesMemory1 defines model for .
type DBClusterSpecEngineResourcesMemory1 = string

// DBCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DBCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DBClusterSpecEngineStorageSize0 defines model for .
type DBClusterSpecEngineStorageSize0 = int

// DBClusterSpecEngineStorageSize1 defines model for .
type DBClusterSpecEngineStorageSize1 = string

// DBCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DBCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DBClusterSpecMonitoringResourcesLimits0 defines model for .
type DBClusterSpecMonitoringResourcesLimits0 = int

// DBClusterSpecMonitoringResourcesLimits1 defines model for .
type DBClusterSpecMonitoringResourcesLimits1 = string

// DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DBCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DBClusterSpecMonitoringResourcesRequests0 defines model for .
type DBClusterSpecMonitoringResourcesRequests0 = int

// DBClusterSpecMonitoringResourcesRequests1 defines model for .
type DBClusterSpecMonitoringResourcesRequests1 = string

// DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DBCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DBClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DBClusterSpecProxyExposeType string

// DBClusterSpecProxyResourcesCpu0 defines model for .
type DBClusterSpecProxyResourcesCpu0 = int

// DBClusterSpecProxyResourcesCpu1 defines model for .
type DBClusterSpecProxyResourcesCpu1 = string

// DBCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DBCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DBClusterSpecProxyResourcesMemory0 defines model for .
type DBClusterSpecProxyResourcesMemory0 = int

// DBClusterSpecProxyResourcesMemory1 defines model for .
type DBClusterSpecProxyResourcesMemory1 = string

// DBCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DBCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DBClusterSpecProxyType Type is the proxy type
type DBClusterSpecProxyType string

// DatabaseCluster DatabaseCluster is the Schema for the databaseclusters API.
type DatabaseCluster struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec *struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterSpecEngineResourcesCpu0 = int

// DatabaseClusterSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterSpecEngineResourcesCpu1 = string

// DatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterSpecEngineResourcesMemory0 = int

// DatabaseClusterSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterSpecEngineResourcesMemory1 = string

// DatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineStorageSize0 defines model for .
type DatabaseClusterSpecEngineStorageSize0 = int

// DatabaseClusterSpecEngineStorageSize1 defines model for .
type DatabaseClusterSpecEngineStorageSize1 = string

// DatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterSpecProxyExposeType string

// DatabaseClusterSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterSpecProxyResourcesCpu0 = int

// DatabaseClusterSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterSpecProxyResourcesCpu1 = string

// DatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterSpecProxyResourcesMemory0 = int

// DatabaseClusterSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterSpecProxyResourcesMemory1 = string

// DatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyType Type is the proxy type
type DatabaseClusterSpecProxyType string

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	Items *[]DBCluster `json:"items,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		BackupName *string `json:"backupName,omitempty"`

		// BackupSource BackupSource represents settings of a source where to get a backup to run restoration.
		BackupSource *struct {
			// Azure BackupStorageProviderSpec represents set of settings to configure cloud provider.
			Azure *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"azure,omitempty"`
			Destination *string `json:"destination,omitempty"`
			Image       *string `json:"image,omitempty"`

			// S3 BackupStorageProviderSpec represents set of settings to configure cloud provider.
			S3 *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"s3,omitempty"`
			SslInternalSecretName *string `json:"sslInternalSecretName,omitempty"`
			SslSecretName         *string `json:"sslSecretName,omitempty"`
			StorageName           *string `json:"storageName,omitempty"`

			// StorageType BackupStorageType represents backup storage type.
			StorageType     string  `json:"storage_type"`
			VaultSecretName *string `json:"vaultSecretName,omitempty"`
		} `json:"backupSource,omitempty"`
		DatabaseCluster string `json:"databaseCluster"`

		// DatabaseType EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		DatabaseType string `json:"databaseType"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed  *time.Time `json:"completed,omitempty"`
		Conditions *[]struct {
			// LastTransitionTime lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
			LastTransitionTime time.Time `json:"lastTransitionTime"`

			// Message message is a human readable message indicating details about the transition. This may be an empty string.
			Message string `json:"message"`

			// ObservedGeneration observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
			ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

			// Reason reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
			Reason string `json:"reason"`

			// Status status of the condition, one of True, False, Unknown.
			Status DatabaseClusterRestoreStatusConditionsStatus `json:"status"`

			// Type type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
			Type string `json:"type"`
		} `json:"conditions,omitempty"`
		Destination   *string    `json:"destination,omitempty"`
		Lastscheduled *time.Time `json:"lastscheduled,omitempty"`
		Message       *string    `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State       *string `json:"state,omitempty"`
		StorageName *string `json:"storageName,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreStatusConditionsStatus status of the condition, one of True, False, Unknown.
type DatabaseClusterRestoreStatusConditionsStatus string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                   `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		AllowedVersions *[]string `json:"allowedVersions,omitempty"`

		// Type EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// AvailableVersions Versions struct represents available versions of database engine components.
		AvailableVersions *struct {
			Backup *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"backup,omitempty"`
			Engine *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"engine,omitempty"`
			Proxy *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"proxy,omitempty"`
			Tools *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"tools,omitempty"`
		} `json:"availableVersions,omitempty"`
		OperatorVersion *string `json:"operatorVersion,omitempty"`

		// Status EngineState represents state of engine in a k8s cluster.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string           `json:"apiVersion,omitempty"`
	Items      *[]DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesCluster kubernetes object
type KubernetesCluster struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Namespace string `json:"namespace"`
}

// KubernetesClusterList defines model for KubernetesClusterList.
type KubernetesClusterList = []KubernetesCluster

// PMMInstance PMM instance information
type PMMInstance struct {
	ApiKeySecretId string  `json:"apiKeySecretId"`
	Id             *string `json:"id,omitempty"`
	Url            string  `json:"url"`
}

// PMMInstanceCreateParams PMM instance create information
type PMMInstanceCreateParams struct {
	ApiKey string `json:"apiKey"`
	Url    string `json:"url"`
}

// PMMInstanceUpdateParams PMM instance update information
type PMMInstanceUpdateParams struct {
	ApiKey *string `json:"apiKey,omitempty"`
	Url    *string `json:"url,omitempty"`
}

// PMMInstancesList defines model for PMMInstancesList.
type PMMInstancesList = []PMMInstance

// UnregisterKubernetesClusterParams Options for removing a kubernetes cluster
type UnregisterKubernetesClusterParams struct {
	// Force Remove the kubernetes cluster even if there are database clusters running.
	Force *bool `json:"force,omitempty"`
}

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName *string `json:"bucketName,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      *string `json:"name,omitempty"`
	Region    *string `json:"region,omitempty"`
	SecretKey *string `json:"secretKey,omitempty"`
	Url       *string `json:"url,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// RegisterKubernetesClusterJSONRequestBody defines body for RegisterKubernetesCluster for application/json ContentType.
type RegisterKubernetesClusterJSONRequestBody = CreateKubernetesClusterParams

// UnregisterKubernetesClusterJSONRequestBody defines body for UnregisterKubernetesCluster for application/json ContentType.
type UnregisterKubernetesClusterJSONRequestBody = UnregisterKubernetesClusterParams

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = CreateDatabaseCluster

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// UpdateDatabaseEngineJSONRequestBody defines body for UpdateDatabaseEngine for application/json ContentType.
type UpdateDatabaseEngineJSONRequestBody = DatabaseEngine

// CreatePMMInstanceJSONRequestBody defines body for CreatePMMInstance for application/json ContentType.
type CreatePMMInstanceJSONRequestBody = PMMInstanceCreateParams

// UpdatePMMInstanceJSONRequestBody defines body for UpdatePMMInstance for application/json ContentType.
type UpdatePMMInstanceJSONRequestBody = PMMInstanceUpdateParams

// AsCreateDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as a CreateDatabaseClusterSpecEngineResourcesCpu0
func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) AsCreateDatabaseClusterSpecEngineResourcesCpu0() (CreateDatabaseClusterSpecEngineResourcesCpu0, error) {
	var body CreateDatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as the provided CreateDatabaseClusterSpecEngineResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) FromCreateDatabaseClusterSpecEngineResourcesCpu0(v CreateDatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu, using the provided CreateDatabaseClusterSpecEngineResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MergeCreateDatabaseClusterSpecEngineResourcesCpu0(v CreateDatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as a CreateDatabaseClusterSpecEngineResourcesCpu1
func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) AsCreateDatabaseClusterSpecEngineResourcesCpu1() (CreateDatabaseClusterSpecEngineResourcesCpu1, error) {
	var body CreateDatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as the provided CreateDatabaseClusterSpecEngineResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) FromCreateDatabaseClusterSpecEngineResourcesCpu1(v CreateDatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu, using the provided CreateDatabaseClusterSpecEngineResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MergeCreateDatabaseClusterSpecEngineResourcesCpu1(v CreateDatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as a CreateDatabaseClusterSpecEngineResourcesMemory0
func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) AsCreateDatabaseClusterSpecEngineResourcesMemory0() (CreateDatabaseClusterSpecEngineResourcesMemory0, error) {
	var body CreateDatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as the provided CreateDatabaseClusterSpecEngineResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) FromCreateDatabaseClusterSpecEngineResourcesMemory0(v CreateDatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory, using the provided CreateDatabaseClusterSpecEngineResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) MergeCreateDatabaseClusterSpecEngineResourcesMemory0(v CreateDatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as a CreateDatabaseClusterSpecEngineResourcesMemory1
func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) AsCreateDatabaseClusterSpecEngineResourcesMemory1() (CreateDatabaseClusterSpecEngineResourcesMemory1, error) {
	var body CreateDatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as the provided CreateDatabaseClusterSpecEngineResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) FromCreateDatabaseClusterSpecEngineResourcesMemory1(v CreateDatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory, using the provided CreateDatabaseClusterSpecEngineResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) MergeCreateDatabaseClusterSpecEngineResourcesMemory1(v CreateDatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecEngineStorageSize0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as a CreateDatabaseClusterSpecEngineStorageSize0
func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) AsCreateDatabaseClusterSpecEngineStorageSize0() (CreateDatabaseClusterSpecEngineStorageSize0, error) {
	var body CreateDatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as the provided CreateDatabaseClusterSpecEngineStorageSize0
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) FromCreateDatabaseClusterSpecEngineStorageSize0(v CreateDatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size, using the provided CreateDatabaseClusterSpecEngineStorageSize0
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) MergeCreateDatabaseClusterSpecEngineStorageSize0(v CreateDatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineStorageSize1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as a CreateDatabaseClusterSpecEngineStorageSize1
func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) AsCreateDatabaseClusterSpecEngineStorageSize1() (CreateDatabaseClusterSpecEngineStorageSize1, error) {
	var body CreateDatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as the provided CreateDatabaseClusterSpecEngineStorageSize1
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) FromCreateDatabaseClusterSpecEngineStorageSize1(v CreateDatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size, using the provided CreateDatabaseClusterSpecEngineStorageSize1
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) MergeCreateDatabaseClusterSpecEngineStorageSize1(v CreateDatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesLimits0() (CreateDatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesLimits0(v CreateDatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesLimits0(v CreateDatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesLimits1() (CreateDatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesLimits1(v CreateDatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesLimits1(v CreateDatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesRequests0() (CreateDatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesRequests0(v CreateDatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesRequests0(v CreateDatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesRequests1() (CreateDatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesRequests1(v CreateDatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesRequests1(v CreateDatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as a CreateDatabaseClusterSpecProxyResourcesCpu0
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) AsCreateDatabaseClusterSpecProxyResourcesCpu0() (CreateDatabaseClusterSpecProxyResourcesCpu0, error) {
	var body CreateDatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as the provided CreateDatabaseClusterSpecProxyResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) FromCreateDatabaseClusterSpecProxyResourcesCpu0(v CreateDatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided CreateDatabaseClusterSpecProxyResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MergeCreateDatabaseClusterSpecProxyResourcesCpu0(v CreateDatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as a CreateDatabaseClusterSpecProxyResourcesCpu1
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) AsCreateDatabaseClusterSpecProxyResourcesCpu1() (CreateDatabaseClusterSpecProxyResourcesCpu1, error) {
	var body CreateDatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as the provided CreateDatabaseClusterSpecProxyResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) FromCreateDatabaseClusterSpecProxyResourcesCpu1(v CreateDatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided CreateDatabaseClusterSpecProxyResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MergeCreateDatabaseClusterSpecProxyResourcesCpu1(v CreateDatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as a CreateDatabaseClusterSpecProxyResourcesMemory0
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) AsCreateDatabaseClusterSpecProxyResourcesMemory0() (CreateDatabaseClusterSpecProxyResourcesMemory0, error) {
	var body CreateDatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as the provided CreateDatabaseClusterSpecProxyResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) FromCreateDatabaseClusterSpecProxyResourcesMemory0(v CreateDatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory, using the provided CreateDatabaseClusterSpecProxyResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MergeCreateDatabaseClusterSpecProxyResourcesMemory0(v CreateDatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as a CreateDatabaseClusterSpecProxyResourcesMemory1
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) AsCreateDatabaseClusterSpecProxyResourcesMemory1() (CreateDatabaseClusterSpecProxyResourcesMemory1, error) {
	var body CreateDatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as the provided CreateDatabaseClusterSpecProxyResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) FromCreateDatabaseClusterSpecProxyResourcesMemory1(v CreateDatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory, using the provided CreateDatabaseClusterSpecProxyResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MergeCreateDatabaseClusterSpecProxyResourcesMemory1(v CreateDatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineResourcesCpu0 returns the union data inside the DBCluster_Spec_Engine_Resources_Cpu as a DBClusterSpecEngineResourcesCpu0
func (t DBCluster_Spec_Engine_Resources_Cpu) AsDBClusterSpecEngineResourcesCpu0() (DBClusterSpecEngineResourcesCpu0, error) {
	var body DBClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesCpu0 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Cpu as the provided DBClusterSpecEngineResourcesCpu0
func (t *DBCluster_Spec_Engine_Resources_Cpu) FromDBClusterSpecEngineResourcesCpu0(v DBClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Cpu, using the provided DBClusterSpecEngineResourcesCpu0
func (t *DBCluster_Spec_Engine_Resources_Cpu) MergeDBClusterSpecEngineResourcesCpu0(v DBClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineResourcesCpu1 returns the union data inside the DBCluster_Spec_Engine_Resources_Cpu as a DBClusterSpecEngineResourcesCpu1
func (t DBCluster_Spec_Engine_Resources_Cpu) AsDBClusterSpecEngineResourcesCpu1() (DBClusterSpecEngineResourcesCpu1, error) {
	var body DBClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesCpu1 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Cpu as the provided DBClusterSpecEngineResourcesCpu1
func (t *DBCluster_Spec_Engine_Resources_Cpu) FromDBClusterSpecEngineResourcesCpu1(v DBClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Cpu, using the provided DBClusterSpecEngineResourcesCpu1
func (t *DBCluster_Spec_Engine_Resources_Cpu) MergeDBClusterSpecEngineResourcesCpu1(v DBClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineResourcesMemory0 returns the union data inside the DBCluster_Spec_Engine_Resources_Memory as a DBClusterSpecEngineResourcesMemory0
func (t DBCluster_Spec_Engine_Resources_Memory) AsDBClusterSpecEngineResourcesMemory0() (DBClusterSpecEngineResourcesMemory0, error) {
	var body DBClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesMemory0 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Memory as the provided DBClusterSpecEngineResourcesMemory0
func (t *DBCluster_Spec_Engine_Resources_Memory) FromDBClusterSpecEngineResourcesMemory0(v DBClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Memory, using the provided DBClusterSpecEngineResourcesMemory0
func (t *DBCluster_Spec_Engine_Resources_Memory) MergeDBClusterSpecEngineResourcesMemory0(v DBClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineResourcesMemory1 returns the union data inside the DBCluster_Spec_Engine_Resources_Memory as a DBClusterSpecEngineResourcesMemory1
func (t DBCluster_Spec_Engine_Resources_Memory) AsDBClusterSpecEngineResourcesMemory1() (DBClusterSpecEngineResourcesMemory1, error) {
	var body DBClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesMemory1 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Memory as the provided DBClusterSpecEngineResourcesMemory1
func (t *DBCluster_Spec_Engine_Resources_Memory) FromDBClusterSpecEngineResourcesMemory1(v DBClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Memory, using the provided DBClusterSpecEngineResourcesMemory1
func (t *DBCluster_Spec_Engine_Resources_Memory) MergeDBClusterSpecEngineResourcesMemory1(v DBClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineStorageSize0 returns the union data inside the DBCluster_Spec_Engine_Storage_Size as a DBClusterSpecEngineStorageSize0
func (t DBCluster_Spec_Engine_Storage_Size) AsDBClusterSpecEngineStorageSize0() (DBClusterSpecEngineStorageSize0, error) {
	var body DBClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineStorageSize0 overwrites any union data inside the DBCluster_Spec_Engine_Storage_Size as the provided DBClusterSpecEngineStorageSize0
func (t *DBCluster_Spec_Engine_Storage_Size) FromDBClusterSpecEngineStorageSize0(v DBClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineStorageSize0 performs a merge with any union data inside the DBCluster_Spec_Engine_Storage_Size, using the provided DBClusterSpecEngineStorageSize0
func (t *DBCluster_Spec_Engine_Storage_Size) MergeDBClusterSpecEngineStorageSize0(v DBClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineStorageSize1 returns the union data inside the DBCluster_Spec_Engine_Storage_Size as a DBClusterSpecEngineStorageSize1
func (t DBCluster_Spec_Engine_Storage_Size) AsDBClusterSpecEngineStorageSize1() (DBClusterSpecEngineStorageSize1, error) {
	var body DBClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineStorageSize1 overwrites any union data inside the DBCluster_Spec_Engine_Storage_Size as the provided DBClusterSpecEngineStorageSize1
func (t *DBCluster_Spec_Engine_Storage_Size) FromDBClusterSpecEngineStorageSize1(v DBClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineStorageSize1 performs a merge with any union data inside the DBCluster_Spec_Engine_Storage_Size, using the provided DBClusterSpecEngineStorageSize1
func (t *DBCluster_Spec_Engine_Storage_Size) MergeDBClusterSpecEngineStorageSize1(v DBClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecMonitoringResourcesLimits0 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DBClusterSpecMonitoringResourcesLimits0
func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDBClusterSpecMonitoringResourcesLimits0() (DBClusterSpecMonitoringResourcesLimits0, error) {
	var body DBClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesLimits0
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDBClusterSpecMonitoringResourcesLimits0(v DBClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesLimits0
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesLimits0(v DBClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecMonitoringResourcesLimits1 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DBClusterSpecMonitoringResourcesLimits1
func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDBClusterSpecMonitoringResourcesLimits1() (DBClusterSpecMonitoringResourcesLimits1, error) {
	var body DBClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesLimits1
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDBClusterSpecMonitoringResourcesLimits1(v DBClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesLimits1
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesLimits1(v DBClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecMonitoringResourcesRequests0 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DBClusterSpecMonitoringResourcesRequests0
func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDBClusterSpecMonitoringResourcesRequests0() (DBClusterSpecMonitoringResourcesRequests0, error) {
	var body DBClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesRequests0
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDBClusterSpecMonitoringResourcesRequests0(v DBClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesRequests0
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesRequests0(v DBClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecMonitoringResourcesRequests1 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DBClusterSpecMonitoringResourcesRequests1
func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDBClusterSpecMonitoringResourcesRequests1() (DBClusterSpecMonitoringResourcesRequests1, error) {
	var body DBClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesRequests1
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDBClusterSpecMonitoringResourcesRequests1(v DBClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesRequests1
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesRequests1(v DBClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecProxyResourcesCpu0 returns the union data inside the DBCluster_Spec_Proxy_Resources_Cpu as a DBClusterSpecProxyResourcesCpu0
func (t DBCluster_Spec_Proxy_Resources_Cpu) AsDBClusterSpecProxyResourcesCpu0() (DBClusterSpecProxyResourcesCpu0, error) {
	var body DBClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesCpu0 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Cpu as the provided DBClusterSpecProxyResourcesCpu0
func (t *DBCluster_Spec_Proxy_Resources_Cpu) FromDBClusterSpecProxyResourcesCpu0(v DBClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Cpu, using the provided DBClusterSpecProxyResourcesCpu0
func (t *DBCluster_Spec_Proxy_Resources_Cpu) MergeDBClusterSpecProxyResourcesCpu0(v DBClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecProxyResourcesCpu1 returns the union data inside the DBCluster_Spec_Proxy_Resources_Cpu as a DBClusterSpecProxyResourcesCpu1
func (t DBCluster_Spec_Proxy_Resources_Cpu) AsDBClusterSpecProxyResourcesCpu1() (DBClusterSpecProxyResourcesCpu1, error) {
	var body DBClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesCpu1 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Cpu as the provided DBClusterSpecProxyResourcesCpu1
func (t *DBCluster_Spec_Proxy_Resources_Cpu) FromDBClusterSpecProxyResourcesCpu1(v DBClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Cpu, using the provided DBClusterSpecProxyResourcesCpu1
func (t *DBCluster_Spec_Proxy_Resources_Cpu) MergeDBClusterSpecProxyResourcesCpu1(v DBClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecProxyResourcesMemory0 returns the union data inside the DBCluster_Spec_Proxy_Resources_Memory as a DBClusterSpecProxyResourcesMemory0
func (t DBCluster_Spec_Proxy_Resources_Memory) AsDBClusterSpecProxyResourcesMemory0() (DBClusterSpecProxyResourcesMemory0, error) {
	var body DBClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesMemory0 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Memory as the provided DBClusterSpecProxyResourcesMemory0
func (t *DBCluster_Spec_Proxy_Resources_Memory) FromDBClusterSpecProxyResourcesMemory0(v DBClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Memory, using the provided DBClusterSpecProxyResourcesMemory0
func (t *DBCluster_Spec_Proxy_Resources_Memory) MergeDBClusterSpecProxyResourcesMemory0(v DBClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecProxyResourcesMemory1 returns the union data inside the DBCluster_Spec_Proxy_Resources_Memory as a DBClusterSpecProxyResourcesMemory1
func (t DBCluster_Spec_Proxy_Resources_Memory) AsDBClusterSpecProxyResourcesMemory1() (DBClusterSpecProxyResourcesMemory1, error) {
	var body DBClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesMemory1 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Memory as the provided DBClusterSpecProxyResourcesMemory1
func (t *DBCluster_Spec_Proxy_Resources_Memory) FromDBClusterSpecProxyResourcesMemory1(v DBClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Memory, using the provided DBClusterSpecProxyResourcesMemory1
func (t *DBCluster_Spec_Proxy_Resources_Memory) MergeDBClusterSpecProxyResourcesMemory1(v DBClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu0
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu0() (DatabaseClusterSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu1
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu1() (DatabaseClusterSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory0
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory0() (DatabaseClusterSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory1
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory1() (DatabaseClusterSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineStorageSize0 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize0
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize0() (DatabaseClusterSpecEngineStorageSize0, error) {
	var body DatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineStorageSize1 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize1
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize1() (DatabaseClusterSpecEngineStorageSize1, error) {
	var body DatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu0
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu0() (DatabaseClusterSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu1
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu1() (DatabaseClusterSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory0
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory0() (DatabaseClusterSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory1
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory1() (DatabaseClusterSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// ListBackupStorages request
	ListBackupStorages(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateBackupStorage request with any body
	CreateBackupStorageWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateBackupStorage(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteBackupStorage request
	DeleteBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetBackupStorage request
	GetBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateBackupStorage request with any body
	UpdateBackupStorageWithBody(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateBackupStorage(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListKubernetesClusters request
	ListKubernetesClusters(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// RegisterKubernetesCluster request with any body
	RegisterKubernetesClusterWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	RegisterKubernetesCluster(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UnregisterKubernetesCluster request with any body
	UnregisterKubernetesClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UnregisterKubernetesCluster(ctx context.Context, kubernetesId string, body UnregisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetKubernetesCluster request
	GetKubernetesCluster(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusterRestores request
	ListDatabaseClusterRestores(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterRestore request with any body
	CreateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseClusterRestore(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseClusterRestore request
	DeleteDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterRestore request
	GetDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseClusterRestore request with any body
	UpdateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusters request
	ListDatabaseClusters(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseCluster request with any body
	CreateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseCluster(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseCluster request
	DeleteDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseCluster request
	GetDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseCluster request with any body
	UpdateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseCluster(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseEngines request
	ListDatabaseEngines(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseEngine request
	GetDatabaseEngine(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseEngine request with any body
	UpdateDatabaseEngineWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseEngine(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListPMMInstances request
	ListPMMInstances(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreatePMMInstance request with any body
	CreatePMMInstanceWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreatePMMInstance(ctx context.Context, body CreatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeletePMMInstance request
	DeletePMMInstance(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetPMMInstance request
	GetPMMInstance(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdatePMMInstance request with any body
	UpdatePMMInstanceWithBody(ctx context.Context, pmmInstanceId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdatePMMInstance(ctx context.Context, pmmInstanceId string, body UpdatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) ListBackupStorages(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupStoragesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorageWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorage(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteBackupStorageRequest(c.Server, backupStorageId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetBackupStorage(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetBackupStorageRequest(c.Server, backupStorageId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorageWithBody(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequestWithBody(c.Server, backupStorageId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorage(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequest(c.Server, backupStorageId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListKubernetesClusters(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListKubernetesClustersRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RegisterKubernetesClusterWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRegisterKubernetesClusterRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) RegisterKubernetesCluster(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewRegisterKubernetesClusterRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UnregisterKubernetesClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUnregisterKubernetesClusterRequestWithBody(c.Server, kubernetesId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UnregisterKubernetesCluster(ctx context.Context, kubernetesId string, body UnregisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUnregisterKubernetesClusterRequest(c.Server, kubernetesId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetKubernetesCluster(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetKubernetesClusterRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusterRestores(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClusterRestoresRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequestWithBody(c.Server, kubernetesId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestore(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequest(c.Server, kubernetesId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRestoreRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRestoreRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestoreWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequestWithBody(c.Server, kubernetesId, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestore(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequest(c.Server, kubernetesId, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusters(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClustersRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequestWithBody(c.Server, kubernetesId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseCluster(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequest(c.Server, kubernetesId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseCluster(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequestWithBody(c.Server, kubernetesId, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseCluster(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequest(c.Server, kubernetesId, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseEngines(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseEnginesRequest(c.Server, kubernetesId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseEngine(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseEngineRequest(c.Server, kubernetesId, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseEngineWithBody(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseEngineRequestWithBody(c.Server, kubernetesId, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseEngine(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseEngineRequest(c.Server, kubernetesId, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListPMMInstances(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListPMMInstancesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreatePMMInstanceWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreatePMMInstanceRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreatePMMInstance(ctx context.Context, body CreatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreatePMMInstanceRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeletePMMInstance(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeletePMMInstanceRequest(c.Server, pmmInstanceId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetPMMInstance(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetPMMInstanceRequest(c.Server, pmmInstanceId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdatePMMInstanceWithBody(ctx context.Context, pmmInstanceId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdatePMMInstanceRequestWithBody(c.Server, pmmInstanceId, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdatePMMInstance(ctx context.Context, pmmInstanceId string, body UpdatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdatePMMInstanceRequest(c.Server, pmmInstanceId, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewListBackupStoragesRequest generates requests for ListBackupStorages
func NewListBackupStoragesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateBackupStorageRequest calls the generic CreateBackupStorage builder with application/json body
func NewCreateBackupStorageRequest(server string, body CreateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateBackupStorageRequestWithBody(server, "application/json", bodyReader)
}

// NewCreateBackupStorageRequestWithBody generates requests for CreateBackupStorage with any type of body
func NewCreateBackupStorageRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteBackupStorageRequest generates requests for DeleteBackupStorage
func NewDeleteBackupStorageRequest(server string, backupStorageId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetBackupStorageRequest generates requests for GetBackupStorage
func NewGetBackupStorageRequest(server string, backupStorageId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateBackupStorageRequest calls the generic UpdateBackupStorage builder with application/json body
func NewUpdateBackupStorageRequest(server string, backupStorageId string, body UpdateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateBackupStorageRequestWithBody(server, backupStorageId, "application/json", bodyReader)
}

// NewUpdateBackupStorageRequestWithBody generates requests for UpdateBackupStorage with any type of body
func NewUpdateBackupStorageRequestWithBody(server string, backupStorageId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, backupStorageId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/backup-storages/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListKubernetesClustersRequest generates requests for ListKubernetesClusters
func NewListKubernetesClustersRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewRegisterKubernetesClusterRequest calls the generic RegisterKubernetesCluster builder with application/json body
func NewRegisterKubernetesClusterRequest(server string, body RegisterKubernetesClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewRegisterKubernetesClusterRequestWithBody(server, "application/json", bodyReader)
}

// NewRegisterKubernetesClusterRequestWithBody generates requests for RegisterKubernetesCluster with any type of body
func NewRegisterKubernetesClusterRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewUnregisterKubernetesClusterRequest calls the generic UnregisterKubernetesCluster builder with application/json body
func NewUnregisterKubernetesClusterRequest(server string, kubernetesId string, body UnregisterKubernetesClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUnregisterKubernetesClusterRequestWithBody(server, kubernetesId, "application/json", bodyReader)
}

// NewUnregisterKubernetesClusterRequestWithBody generates requests for UnregisterKubernetesCluster with any type of body
func NewUnregisterKubernetesClusterRequestWithBody(server string, kubernetesId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetKubernetesClusterRequest generates requests for GetKubernetesCluster
func NewGetKubernetesClusterRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDatabaseClusterRestoresRequest generates requests for ListDatabaseClusterRestores
func NewListDatabaseClusterRestoresRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRestoreRequest calls the generic CreateDatabaseClusterRestore builder with application/json body
func NewCreateDatabaseClusterRestoreRequest(server string, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRestoreRequestWithBody(server, kubernetesId, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRestoreRequestWithBody generates requests for CreateDatabaseClusterRestore with any type of body
func NewCreateDatabaseClusterRestoreRequestWithBody(server string, kubernetesId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRestoreRequest generates requests for DeleteDatabaseClusterRestore
func NewDeleteDatabaseClusterRestoreRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRestoreRequest generates requests for GetDatabaseClusterRestore
func NewGetDatabaseClusterRestoreRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRestoreRequest calls the generic UpdateDatabaseClusterRestore builder with application/json body
func NewUpdateDatabaseClusterRestoreRequest(server string, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRestoreRequestWithBody(server, kubernetesId, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRestoreRequestWithBody generates requests for UpdateDatabaseClusterRestore with any type of body
func NewUpdateDatabaseClusterRestoreRequestWithBody(server string, kubernetesId string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseClustersRequest generates requests for ListDatabaseClusters
func NewListDatabaseClustersRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRequest calls the generic CreateDatabaseCluster builder with application/json body
func NewCreateDatabaseClusterRequest(server string, kubernetesId string, body CreateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRequestWithBody(server, kubernetesId, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRequestWithBody generates requests for CreateDatabaseCluster with any type of body
func NewCreateDatabaseClusterRequestWithBody(server string, kubernetesId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRequest generates requests for DeleteDatabaseCluster
func NewDeleteDatabaseClusterRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRequest generates requests for GetDatabaseCluster
func NewGetDatabaseClusterRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRequest calls the generic UpdateDatabaseCluster builder with application/json body
func NewUpdateDatabaseClusterRequest(server string, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRequestWithBody(server, kubernetesId, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRequestWithBody generates requests for UpdateDatabaseCluster with any type of body
func NewUpdateDatabaseClusterRequestWithBody(server string, kubernetesId string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseEnginesRequest generates requests for ListDatabaseEngines
func NewListDatabaseEnginesRequest(server string, kubernetesId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-engines", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseEngineRequest generates requests for GetDatabaseEngine
func NewGetDatabaseEngineRequest(server string, kubernetesId string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-engines/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseEngineRequest calls the generic UpdateDatabaseEngine builder with application/json body
func NewUpdateDatabaseEngineRequest(server string, kubernetesId string, name string, body UpdateDatabaseEngineJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseEngineRequestWithBody(server, kubernetesId, name, "application/json", bodyReader)
}

// NewUpdateDatabaseEngineRequestWithBody generates requests for UpdateDatabaseEngine with any type of body
func NewUpdateDatabaseEngineRequestWithBody(server string, kubernetesId string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, kubernetesId)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/kubernetes/%s/database-engines/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListPMMInstancesRequest generates requests for ListPMMInstances
func NewListPMMInstancesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pmm-instances")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreatePMMInstanceRequest calls the generic CreatePMMInstance builder with application/json body
func NewCreatePMMInstanceRequest(server string, body CreatePMMInstanceJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreatePMMInstanceRequestWithBody(server, "application/json", bodyReader)
}

// NewCreatePMMInstanceRequestWithBody generates requests for CreatePMMInstance with any type of body
func NewCreatePMMInstanceRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pmm-instances")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeletePMMInstanceRequest generates requests for DeletePMMInstance
func NewDeletePMMInstanceRequest(server string, pmmInstanceId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, pmmInstanceId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pmm-instances/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetPMMInstanceRequest generates requests for GetPMMInstance
func NewGetPMMInstanceRequest(server string, pmmInstanceId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, pmmInstanceId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pmm-instances/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdatePMMInstanceRequest calls the generic UpdatePMMInstance builder with application/json body
func NewUpdatePMMInstanceRequest(server string, pmmInstanceId string, body UpdatePMMInstanceJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdatePMMInstanceRequestWithBody(server, pmmInstanceId, "application/json", bodyReader)
}

// NewUpdatePMMInstanceRequestWithBody generates requests for UpdatePMMInstance with any type of body
func NewUpdatePMMInstanceRequestWithBody(server string, pmmInstanceId string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, pmmInstanceId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pmm-instances/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// ListBackupStorages request
	ListBackupStoragesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error)

	// CreateBackupStorage request with any body
	CreateBackupStorageWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	CreateBackupStorageWithResponse(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	// DeleteBackupStorage request
	DeleteBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error)

	// GetBackupStorage request
	GetBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error)

	// UpdateBackupStorage request with any body
	UpdateBackupStorageWithBodyWithResponse(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	UpdateBackupStorageWithResponse(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	// ListKubernetesClusters request
	ListKubernetesClustersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListKubernetesClustersResponse, error)

	// RegisterKubernetesCluster request with any body
	RegisterKubernetesClusterWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error)

	RegisterKubernetesClusterWithResponse(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error)

	// UnregisterKubernetesCluster request with any body
	UnregisterKubernetesClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UnregisterKubernetesClusterResponse, error)

	UnregisterKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, body UnregisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UnregisterKubernetesClusterResponse, error)

	// GetKubernetesCluster request
	GetKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResponse, error)

	// ListDatabaseClusterRestores request
	ListDatabaseClusterRestoresWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error)

	// CreateDatabaseClusterRestore request with any body
	CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	CreateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	// DeleteDatabaseClusterRestore request
	DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error)

	// GetDatabaseClusterRestore request
	GetDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error)

	// UpdateDatabaseClusterRestore request with any body
	UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	// ListDatabaseClusters request
	ListDatabaseClustersWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error)

	// CreateDatabaseCluster request with any body
	CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	CreateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	// DeleteDatabaseCluster request
	DeleteDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error)

	// GetDatabaseCluster request
	GetDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error)

	// UpdateDatabaseCluster request with any body
	UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	UpdateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	// ListDatabaseEngines request
	ListDatabaseEnginesWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error)

	// GetDatabaseEngine request
	GetDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error)

	// UpdateDatabaseEngine request with any body
	UpdateDatabaseEngineWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error)

	UpdateDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error)

	// ListPMMInstances request
	ListPMMInstancesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListPMMInstancesResponse, error)

	// CreatePMMInstance request with any body
	CreatePMMInstanceWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreatePMMInstanceResponse, error)

	CreatePMMInstanceWithResponse(ctx context.Context, body CreatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*CreatePMMInstanceResponse, error)

	// DeletePMMInstance request
	DeletePMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*DeletePMMInstanceResponse, error)

	// GetPMMInstance request
	GetPMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*GetPMMInstanceResponse, error)

	// UpdatePMMInstance request with any body
	UpdatePMMInstanceWithBodyWithResponse(ctx context.Context, pmmInstanceId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdatePMMInstanceResponse, error)

	UpdatePMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, body UpdatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdatePMMInstanceResponse, error)
}

type ListBackupStoragesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStoragesList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListBackupStoragesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupStoragesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListKubernetesClustersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesClusterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListKubernetesClustersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListKubernetesClustersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type RegisterKubernetesClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON201      *KubernetesCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r RegisterKubernetesClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r RegisterKubernetesClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UnregisterKubernetesClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UnregisterKubernetesClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UnregisterKubernetesClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetKubernetesClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetKubernetesClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetKubernetesClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClusterRestoresResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestoreList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClusterRestoresResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClusterRestoresResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON202      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClustersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClustersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClustersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseEnginesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngineList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseEnginesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseEnginesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseEngineResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngine
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseEngineResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseEngineResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseEngineResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngine
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseEngineResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseEngineResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListPMMInstancesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PMMInstancesList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListPMMInstancesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListPMMInstancesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreatePMMInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PMMInstance
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreatePMMInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreatePMMInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeletePMMInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeletePMMInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeletePMMInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetPMMInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PMMInstance
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetPMMInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetPMMInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdatePMMInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PMMInstance
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdatePMMInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdatePMMInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// ListBackupStoragesWithResponse request returning *ListBackupStoragesResponse
func (c *ClientWithResponses) ListBackupStoragesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error) {
	rsp, err := c.ListBackupStorages(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupStoragesResponse(rsp)
}

// CreateBackupStorageWithBodyWithResponse request with arbitrary body returning *CreateBackupStorageResponse
func (c *ClientWithResponses) CreateBackupStorageWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorageWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) CreateBackupStorageWithResponse(ctx context.Context, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorage(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

// DeleteBackupStorageWithResponse request returning *DeleteBackupStorageResponse
func (c *ClientWithResponses) DeleteBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error) {
	rsp, err := c.DeleteBackupStorage(ctx, backupStorageId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteBackupStorageResponse(rsp)
}

// GetBackupStorageWithResponse request returning *GetBackupStorageResponse
func (c *ClientWithResponses) GetBackupStorageWithResponse(ctx context.Context, backupStorageId string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error) {
	rsp, err := c.GetBackupStorage(ctx, backupStorageId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetBackupStorageResponse(rsp)
}

// UpdateBackupStorageWithBodyWithResponse request with arbitrary body returning *UpdateBackupStorageResponse
func (c *ClientWithResponses) UpdateBackupStorageWithBodyWithResponse(ctx context.Context, backupStorageId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorageWithBody(ctx, backupStorageId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) UpdateBackupStorageWithResponse(ctx context.Context, backupStorageId string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorage(ctx, backupStorageId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

// ListKubernetesClustersWithResponse request returning *ListKubernetesClustersResponse
func (c *ClientWithResponses) ListKubernetesClustersWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListKubernetesClustersResponse, error) {
	rsp, err := c.ListKubernetesClusters(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListKubernetesClustersResponse(rsp)
}

// RegisterKubernetesClusterWithBodyWithResponse request with arbitrary body returning *RegisterKubernetesClusterResponse
func (c *ClientWithResponses) RegisterKubernetesClusterWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error) {
	rsp, err := c.RegisterKubernetesClusterWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRegisterKubernetesClusterResponse(rsp)
}

func (c *ClientWithResponses) RegisterKubernetesClusterWithResponse(ctx context.Context, body RegisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*RegisterKubernetesClusterResponse, error) {
	rsp, err := c.RegisterKubernetesCluster(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseRegisterKubernetesClusterResponse(rsp)
}

// UnregisterKubernetesClusterWithBodyWithResponse request with arbitrary body returning *UnregisterKubernetesClusterResponse
func (c *ClientWithResponses) UnregisterKubernetesClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UnregisterKubernetesClusterResponse, error) {
	rsp, err := c.UnregisterKubernetesClusterWithBody(ctx, kubernetesId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUnregisterKubernetesClusterResponse(rsp)
}

func (c *ClientWithResponses) UnregisterKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, body UnregisterKubernetesClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UnregisterKubernetesClusterResponse, error) {
	rsp, err := c.UnregisterKubernetesCluster(ctx, kubernetesId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUnregisterKubernetesClusterResponse(rsp)
}

// GetKubernetesClusterWithResponse request returning *GetKubernetesClusterResponse
func (c *ClientWithResponses) GetKubernetesClusterWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResponse, error) {
	rsp, err := c.GetKubernetesCluster(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetKubernetesClusterResponse(rsp)
}

// ListDatabaseClusterRestoresWithResponse request returning *ListDatabaseClusterRestoresResponse
func (c *ClientWithResponses) ListDatabaseClusterRestoresWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error) {
	rsp, err := c.ListDatabaseClusterRestores(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClusterRestoresResponse(rsp)
}

// CreateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestoreWithBody(ctx, kubernetesId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestore(ctx, kubernetesId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

// DeleteDatabaseClusterRestoreWithResponse request returning *DeleteDatabaseClusterRestoreResponse
func (c *ClientWithResponses) DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error) {
	rsp, err := c.DeleteDatabaseClusterRestore(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterRestoreResponse(rsp)
}

// GetDatabaseClusterRestoreWithResponse request returning *GetDatabaseClusterRestoreResponse
func (c *ClientWithResponses) GetDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error) {
	rsp, err := c.GetDatabaseClusterRestore(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterRestoreResponse(rsp)
}

// UpdateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestoreWithBody(ctx, kubernetesId, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestore(ctx, kubernetesId, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

// ListDatabaseClustersWithResponse request returning *ListDatabaseClustersResponse
func (c *ClientWithResponses) ListDatabaseClustersWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error) {
	rsp, err := c.ListDatabaseClusters(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClustersResponse(rsp)
}

// CreateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterResponse
func (c *ClientWithResponses) CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseClusterWithBody(ctx, kubernetesId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseCluster(ctx, kubernetesId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

// DeleteDatabaseClusterWithResponse request returning *DeleteDatabaseClusterResponse
func (c *ClientWithResponses) DeleteDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error) {
	rsp, err := c.DeleteDatabaseCluster(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterResponse(rsp)
}

// GetDatabaseClusterWithResponse request returning *GetDatabaseClusterResponse
func (c *ClientWithResponses) GetDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error) {
	rsp, err := c.GetDatabaseCluster(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterResponse(rsp)
}

// UpdateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterResponse
func (c *ClientWithResponses) UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseClusterWithBody(ctx, kubernetesId, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseCluster(ctx, kubernetesId, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

// ListDatabaseEnginesWithResponse request returning *ListDatabaseEnginesResponse
func (c *ClientWithResponses) ListDatabaseEnginesWithResponse(ctx context.Context, kubernetesId string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error) {
	rsp, err := c.ListDatabaseEngines(ctx, kubernetesId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseEnginesResponse(rsp)
}

// GetDatabaseEngineWithResponse request returning *GetDatabaseEngineResponse
func (c *ClientWithResponses) GetDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error) {
	rsp, err := c.GetDatabaseEngine(ctx, kubernetesId, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseEngineResponse(rsp)
}

// UpdateDatabaseEngineWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseEngineResponse
func (c *ClientWithResponses) UpdateDatabaseEngineWithBodyWithResponse(ctx context.Context, kubernetesId string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error) {
	rsp, err := c.UpdateDatabaseEngineWithBody(ctx, kubernetesId, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseEngineResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseEngineWithResponse(ctx context.Context, kubernetesId string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error) {
	rsp, err := c.UpdateDatabaseEngine(ctx, kubernetesId, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseEngineResponse(rsp)
}

// ListPMMInstancesWithResponse request returning *ListPMMInstancesResponse
func (c *ClientWithResponses) ListPMMInstancesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListPMMInstancesResponse, error) {
	rsp, err := c.ListPMMInstances(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListPMMInstancesResponse(rsp)
}

// CreatePMMInstanceWithBodyWithResponse request with arbitrary body returning *CreatePMMInstanceResponse
func (c *ClientWithResponses) CreatePMMInstanceWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreatePMMInstanceResponse, error) {
	rsp, err := c.CreatePMMInstanceWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreatePMMInstanceResponse(rsp)
}

func (c *ClientWithResponses) CreatePMMInstanceWithResponse(ctx context.Context, body CreatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*CreatePMMInstanceResponse, error) {
	rsp, err := c.CreatePMMInstance(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreatePMMInstanceResponse(rsp)
}

// DeletePMMInstanceWithResponse request returning *DeletePMMInstanceResponse
func (c *ClientWithResponses) DeletePMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*DeletePMMInstanceResponse, error) {
	rsp, err := c.DeletePMMInstance(ctx, pmmInstanceId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeletePMMInstanceResponse(rsp)
}

// GetPMMInstanceWithResponse request returning *GetPMMInstanceResponse
func (c *ClientWithResponses) GetPMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, reqEditors ...RequestEditorFn) (*GetPMMInstanceResponse, error) {
	rsp, err := c.GetPMMInstance(ctx, pmmInstanceId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetPMMInstanceResponse(rsp)
}

// UpdatePMMInstanceWithBodyWithResponse request with arbitrary body returning *UpdatePMMInstanceResponse
func (c *ClientWithResponses) UpdatePMMInstanceWithBodyWithResponse(ctx context.Context, pmmInstanceId string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdatePMMInstanceResponse, error) {
	rsp, err := c.UpdatePMMInstanceWithBody(ctx, pmmInstanceId, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdatePMMInstanceResponse(rsp)
}

func (c *ClientWithResponses) UpdatePMMInstanceWithResponse(ctx context.Context, pmmInstanceId string, body UpdatePMMInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdatePMMInstanceResponse, error) {
	rsp, err := c.UpdatePMMInstance(ctx, pmmInstanceId, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdatePMMInstanceResponse(rsp)
}

// ParseListBackupStoragesResponse parses an HTTP response from a ListBackupStoragesWithResponse call
func ParseListBackupStoragesResponse(rsp *http.Response) (*ListBackupStoragesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupStoragesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStoragesList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateBackupStorageResponse parses an HTTP response from a CreateBackupStorageWithResponse call
func ParseCreateBackupStorageResponse(rsp *http.Response) (*CreateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteBackupStorageResponse parses an HTTP response from a DeleteBackupStorageWithResponse call
func ParseDeleteBackupStorageResponse(rsp *http.Response) (*DeleteBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetBackupStorageResponse parses an HTTP response from a GetBackupStorageWithResponse call
func ParseGetBackupStorageResponse(rsp *http.Response) (*GetBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateBackupStorageResponse parses an HTTP response from a UpdateBackupStorageWithResponse call
func ParseUpdateBackupStorageResponse(rsp *http.Response) (*UpdateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListKubernetesClustersResponse parses an HTTP response from a ListKubernetesClustersWithResponse call
func ParseListKubernetesClustersResponse(rsp *http.Response) (*ListKubernetesClustersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListKubernetesClustersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesClusterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseRegisterKubernetesClusterResponse parses an HTTP response from a RegisterKubernetesClusterWithResponse call
func ParseRegisterKubernetesClusterResponse(rsp *http.Response) (*RegisterKubernetesClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &RegisterKubernetesClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest KubernetesCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUnregisterKubernetesClusterResponse parses an HTTP response from a UnregisterKubernetesClusterWithResponse call
func ParseUnregisterKubernetesClusterResponse(rsp *http.Response) (*UnregisterKubernetesClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UnregisterKubernetesClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetKubernetesClusterResponse parses an HTTP response from a GetKubernetesClusterWithResponse call
func ParseGetKubernetesClusterResponse(rsp *http.Response) (*GetKubernetesClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetKubernetesClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClusterRestoresResponse parses an HTTP response from a ListDatabaseClusterRestoresWithResponse call
func ParseListDatabaseClusterRestoresResponse(rsp *http.Response) (*ListDatabaseClusterRestoresResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClusterRestoresResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestoreList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterRestoreResponse parses an HTTP response from a CreateDatabaseClusterRestoreWithResponse call
func ParseCreateDatabaseClusterRestoreResponse(rsp *http.Response) (*CreateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterRestoreResponse parses an HTTP response from a DeleteDatabaseClusterRestoreWithResponse call
func ParseDeleteDatabaseClusterRestoreResponse(rsp *http.Response) (*DeleteDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterRestoreResponse parses an HTTP response from a GetDatabaseClusterRestoreWithResponse call
func ParseGetDatabaseClusterRestoreResponse(rsp *http.Response) (*GetDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterRestoreResponse parses an HTTP response from a UpdateDatabaseClusterRestoreWithResponse call
func ParseUpdateDatabaseClusterRestoreResponse(rsp *http.Response) (*UpdateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClustersResponse parses an HTTP response from a ListDatabaseClustersWithResponse call
func ParseListDatabaseClustersResponse(rsp *http.Response) (*ListDatabaseClustersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClustersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterResponse parses an HTTP response from a CreateDatabaseClusterWithResponse call
func ParseCreateDatabaseClusterResponse(rsp *http.Response) (*CreateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterResponse parses an HTTP response from a DeleteDatabaseClusterWithResponse call
func ParseDeleteDatabaseClusterResponse(rsp *http.Response) (*DeleteDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterResponse parses an HTTP response from a GetDatabaseClusterWithResponse call
func ParseGetDatabaseClusterResponse(rsp *http.Response) (*GetDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterResponse parses an HTTP response from a UpdateDatabaseClusterWithResponse call
func ParseUpdateDatabaseClusterResponse(rsp *http.Response) (*UpdateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseEnginesResponse parses an HTTP response from a ListDatabaseEnginesWithResponse call
func ParseListDatabaseEnginesResponse(rsp *http.Response) (*ListDatabaseEnginesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseEnginesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngineList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseEngineResponse parses an HTTP response from a GetDatabaseEngineWithResponse call
func ParseGetDatabaseEngineResponse(rsp *http.Response) (*GetDatabaseEngineResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseEngineResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngine
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseEngineResponse parses an HTTP response from a UpdateDatabaseEngineWithResponse call
func ParseUpdateDatabaseEngineResponse(rsp *http.Response) (*UpdateDatabaseEngineResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseEngineResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngine
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListPMMInstancesResponse parses an HTTP response from a ListPMMInstancesWithResponse call
func ParseListPMMInstancesResponse(rsp *http.Response) (*ListPMMInstancesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListPMMInstancesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PMMInstancesList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreatePMMInstanceResponse parses an HTTP response from a CreatePMMInstanceWithResponse call
func ParseCreatePMMInstanceResponse(rsp *http.Response) (*CreatePMMInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreatePMMInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PMMInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeletePMMInstanceResponse parses an HTTP response from a DeletePMMInstanceWithResponse call
func ParseDeletePMMInstanceResponse(rsp *http.Response) (*DeletePMMInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeletePMMInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetPMMInstanceResponse parses an HTTP response from a GetPMMInstanceWithResponse call
func ParseGetPMMInstanceResponse(rsp *http.Response) (*GetPMMInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetPMMInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PMMInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdatePMMInstanceResponse parses an HTTP response from a UpdatePMMInstanceWithResponse call
func ParseUpdatePMMInstanceResponse(rsp *http.Response) (*UpdatePMMInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdatePMMInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PMMInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{
	"H4sIAAAAAAAC/+x9e3PbNvboV8GwO1O7K1FJur+9Xc/sdFzHbX1bpx472Zl7Y99diDySsCYBFgBlq9l8",
	"9zs4APgSKEux3CRb/ieRIB4H530ODt5FicgLwYFrFR29i1SygJziz+9oclsWV1pIOgfzIAWVSFZoJnh0",
	"5F4TZd8TxmdC5hRfjqJCigKkZoA9TcvkFvQrmmM3elVAdBQpLRmfR+9HEUuDj3lfewlznELglX3wLgJe",
	"5tHR20h9HY0i+lspIRpF80RFN6P1j0qZBTrDgX4tmYTU9MTSyE1p1FxPNRvXb92/mP4bEm36bwFS/cyU",
	"NsMxDTlC508SZtFR9MWk3omJ24ZJew+qBUZUSroy/08kUA2tZhdUUtvzxg0rTDPQINXaftEkAaV+glUQ",
	"xu3dbI/xegEkyUSZVsPY1pNEcE0ZB0kcDHu3u93hMSkVSJLCjHEwvZrm2AcRM6IX0EBA/Pvy1ZV9bdGR",
	"LLQu1NFkcltOQXLQoGImJqlIlJlTAoVWE7EEuWRwN7kT8pbx+fiO6cXYbqCamN7U5IuUq3FGp5CN8UE0",
	"iuCe5kWG23GnxiksQ8vagKwKEgm6D8xPh8ohLK63vDmvbbDbYuBLqumUKjjJSqVBrm9kpwFhCrfrChHd",
	"bBb+TV0rkthmihxfnMVrCNrLGlQByYNjXxWQOIyyk0hBGdgQpalGvOp8sD6BKdJSL425xU0dxRWQsBlL",
	"wswROJ1mkK73dWpfmM4omWV0TrQgtrXrWdUINxUiA8oRBskC0jKDAAu48q9spxlT2izXz7P6cFRzp9D6",
	"fDfddfrHieAzNi8lLjjez4qR1N0AwWWH+YdBbz/NFtdY66pGIovbjpuG+dwv3SahMVqNyMkl0QuqW4jn",
	"eVcmKuQIMBAN3Lw8EQULbeplu0E1kzKfgmxsb2Jfa0EkGF4cjSLLI6OjiHH99Yt6dMY1zEE2sakfmfyA",
	"iRR8A1w7TMgjQSVU16HeGDzEeNqisKf70IeGyVyJUiYQZhX2XbVRFLkSUfap4VRTIbTSkhZGFlHC4c7z",
	"qx5GEUai76p3IexxuzaTIve/PZqYPSzVJ4+7nS1pgCI0z9BOAZ8zDiFGYZ77eVdCwzZ/gN9a5rTe5wk+",
	"9326rlqcLEydRcYSGiRL+2adHl3f1adb0aEEi4DBkdwrQqVllL4xyVjOtEKkBZosOkPH5GxGuNBEgR6t",
	"fWQ6My9ZXgiFlNoBZFGisshXv8yio7fv1ie9JqBvRl2gX7zx8DE/qyk4vMnRLBlFBdUapPng/x1cX//5",
	"P+PDbw8O3j4b/+3mzwfX1zH++urw28P/VP/+fHh4cPD2p/MfXl+c3rDD/7zlZX5r//3n4C2c3mzfz+Hh",
	"t3+KRtH9uFYhx4zrsZBjt64jLUt4P4pyyIVcPRoo59iNh4vt9PMGzfsAbas+w9IznTYlenbTpcgOTmZU",
	"BSjkxDz2HVY94UPLSisFtACpmDIClSxFVubYjOUh0lfsN3j0Xl+x36qVmg49/+2fx+ey4U3Wj6Dql+Fr",
	"VuSq6G4/NgwZPArkFdorKizt3rQbBHVBfE2ciWpkunmKdqd9pUIjL80OWcuuPeI/7IvOAnzzh6SkJ4sN",
	"FlcuONPCQrs7+Hn1ruIf9ZMnMEQacwkp5UWer/d3cX6OJpgDuCIX5+dGBGnG52rdXGC5YxNrW5CJOQub",
	"1gVV6k7IsGOpKKcZS47TVIJlFgHLXC5B/iisp6bntcGssLG9tmNbCO/LBlsntsnUaVqJyItSQ1gExCEe",
	"yPIwE2S5QqOvpgFliKCa3qhytDCO2BL7V/bjkVUDjWZQKkjJdEX0gilSeXdics3Ja/PIIAsnNCsWlMwY",
	"ZCmhPPUzVxZ9PKm9XHGas8SD4jirFN0ZUF1KIHOqoe7b9mcGyfNSGzyMyZkmCeVE8GxFpoamNfL0amYI",
	"qB6r9rK5SCJhBhK40acEN/SrjTDm5EKkBm3jVmvV75wIGKJ5qTTJqU4WLSbUGqYQaRwAvWdWFyIldwtA",
	"Ra8JCrMfCIWc3iLeUF0jDF1SliG9Mq5YCoQ2tuxBlsT71POWBdaRCgbNxjktxrewUs1e1lu5bnJaIFGj",
	"9omCNU2ZgR7NLtruyd0E7meiPLbR5Werg7cZQU7vWV7mhOai5Oi56bIGRWiWiTuDCudCWq/80VY+0JZe",
	"Nckpp3MYV92OazqaREEG92sJati2SweH7sYx/uDGeYpDo6zqhykicqY1pMjOGnQ7IgwNclpmGtVYhzJs",
	"ZomfKQL3xsxjOlt50Q/piAi9AHnHFJiPKDf2XYayBLd+7CXAkmYlxPVMEsqNNQj3CUDqBvtdsex96Mm2",
	"Pp+CGgYZ0EXweVu1UVoUVvBWTp2AZiPF/SrQn3nsVS9s09a62ia3kZCFkR6SUR1sT+5YlhmBRosiYw4L",
	"TN9ztgTulMuYHBuEygVHWyahzqBxOlVHUmiBSCRFZvXTe0NmNCM2BGBehzzx8Qc6UuyaHvSjwH0hVMjT",
	"g8/bndm2D1iCrLBuvEvK5yG96+yi+d4P4D3iZxfe3yft+4OTs5eXZuNwtEMkHcNpPdRmUuTtvdUopJki",
	"XFiPCn7Z8q33xHzq6F5tHiGZO55pdisabbKZLIDM1yPUiqaGRt02C1lteTSqokuNfqu3N6PtdNvdPWB2",
	"Hz+GA6w18uD/GvxfH83/9bDrw+Kq83x4Qs0Fnwuz8AW1IsiJIvWrod1iPhUlT0BuRbxr8hO97TcPtXMB",
	"G4y19keEf6pA4qKofXkJNeyI66NLaaZFLW16MwfqeLzRt8xHfXkGqqBJh7EWIBPB6RiWIEHp7YyiUXNq",
	"IVC8/G5PAfEhHj7Ew4d4+BAPH+LhQzx8iIcP8fDBHhji4UM8fIiHD/HwIR4+xMOHePgQDx/i4UM8fIiH",
	"D/HwIR4+xMOHePgQDx/i4UM8fPB/DfHwJ4iHjyKlqS7Vw5FVbNYKE4gpWsu7BFcXQumwEfWje+Mh5FtW",
	"FlElrjzbk4bqkXjXmG0OSgUdkOf2hdWgtKTNWg+ETkWpw9pBw8MgpA7oBkLqam/N7y1mvRVjpOkqxBRp",
	"ulpnvdjaGJlbsl3v5ex3W2qhadZk7tv33YNVDo0qfy3+c/ZvL9Tf75LGUY0dTGLY79n+zakMtGD/6PMk",
	"Hl+ceWdik6ScK9HQlB0RQcOMCVFIUF6TN48pdzkmMblCp5UiaiHKLDXa0xKkJhISMefst6q3SgPMqAal",
	"a8UBDYIRunFyahiy6ZeUvNEDNglbBXOm49tv0CQwqmrJmV5hlQzJpqUWUk1SWEI2UWw+pjJZMA2JLiVM",
	"aMHGOFmMcas4T7+oVYEA7d0yHtDzf2LcafmupAZOtYaYd0Vdnl69rmUNQtUCsG6qalgaODA+A+lUbCly",
	"5/NNC8G45xMMuCaqnKJa4U1lokVMTqxRNQVSFinVaP1xckJzyE6ogieHpIGeGhuQqTCL1NSgcUNZbciE",
	"IddmyLUZcm2GXJsh12bItRlybYZcm8HXMOTaDLk2Q67NkGsz5NoMuTZDrs2QazPk2gy5NkOuzZBrM+Ta",
	"DLk2Q67NkGsz5NoM/q/B/zXk2gy5NkOuzX9drs1DeTT+IpiNWG0aOX+Gy7tABbtyXzUVByt+mUK9a+0m",
	"jYBzy+sCW11FU5cyCcU/H1rsJSgtJDy4XtduuxQiaRsPmURDJtEfL5PIUcrOCUXuu/iBdIH1a59s+k1P",
	"7sJ3jbeNDa1c60gy3q5xskeQOWhCfYaBFkSWnFii7knfsfcf9Y3u7r+SYslSl2rVnoqZRTUja4uiGecv",
	"rSrcp3HPFWZBwFSOg1c9N1i1776ytLKkGUvry6o8UzeCq2ITx2ax5r0hIVlmoOIQKiUSUoN4NFM22BSc",
	"pSecN8EbosxyYcbud71vzUWMTsKhz6vXx69eHl++HJFXp8eXP5+9Oh2Rk19+fml/HV+e/Hj2j1Nk7j+c",
	"XJAfhSYH3yMRc52tnHULqbEac5GiBwklwOGInAiRkYMzPtuu+bEh1iWQg0sqYWNbnA0C/mHf9Drggxk/",
	"YASydRQEb7/rDTGprwdMHzD988F0pbIzp9LYVr2yRKkHW7SzyPre/zNsybaoBM3aBnVM2/cgmh6C2Lak",
	"ZaY3TjMcPv9nb/A8XU+kXxvVt3kdXJhNPsMVKU15qirVWJWFsevc7jZS0lRMLtl8oQkXd4TpL5WNUxb3",
	"CSqchcrTaUx+FHewdI59ZwgWakSKOTaifGVd906CP4wx3aV2FvYIO9/rPR9g7veqPsbcyUBbJ31lPBq1",
	"caxZ+LrKRHAbampbUGvuaNuoNthS0JRldt8EB0KNsleZb0kpJaq0fgWo/R5fnBHvZ4zJeDy2oWilZZmg",
	"dWgsCZ46D33KJJoPynSObn5jpRFqdWbrii+oXpDYQjyulxIT8j36aLGQ5ohccyQP8r0QDt52zHdkMiGX",
	"NUnV0LeOZqvtzYT4UrWXFJsPf+LijodGx7GohCNyHR37sPF1NCLX0YUUcwlKMT43DwxSXkcvYS5pCul1",
	"ZLr9c0F1sjgHOYefYPV37Kx6fKUl1TBf/T037/G5MZsNMv49p0X14JwW1cfV7iny9sYo7Mvncb2j//q3",
	"EvzouoEII5EbPCj06joirVGPriMc1z/3kzy6RsQyj6XQYlrOjq6j6UqDGj0fSShGRmT+vR7hOvqX2ZPJ",
	"xFEjbqYi79cQOqNKv5aUK/zuNQuJ6/U2VSSCKk0M4rsUEL9kXbU2qGZMMsErHwkG9HBasUNPaw5PUd+3",
	"l7OWPAWZrYyUr3tNFpTPjX1GzurwobHdbg2eYDCDk1J5OxLnVfVoSMOitOsGlY4kgcLmZjSdQRvpudcj",
	"l9ceOUoWZU45+rFsBpJ/x1OMmfF5Rd+1r66GmgOMsW2nYCgTkcXZzWaqOb3/GfhcL6Kjr1/8r79+E0yy",
	"tkzuB+AgK62yPeX1Nk35Z+YUe/szntdtEPbtHb+jVps0TDQlZWHWYDgE40b8JDAibBbujFWUn63I8xcj",
	"MnXgWKf7t/c3cWDKTJG/jTrzYYoYsIqZkXJA7pheGIMRWajTJQMsFKr5xh3n4F//YqBuI+TR0bMeF6cK",
	"Adk+rxk7NTQ8lzTPqWYJYagwzRjIJnbY+BB+6AV3tbgvlSO8Br5cSJGWCUjkqD4426TIVQEWoawgJHBv",
	"YFE5jKxPCShHO8AO6eOxloveLQBZCbq/3DcSZ6WMfQApoWReUkm5BkjR00Ze+7YNGqe1b8UjdDNhykzR",
	"+WMQ6TvY/vzZi7/gRlQPWtGVt8fj/0vHv90cuB/Pxn/75+jo5qvG3xsbDgkoimGtouPZ9RAdIUsTM/Ja",
	"ljAi39NMwYi84ciL4kYsxLyPRhE2iEaRaxG8lDmso6KIwWyMCrkb/imCRGZEaOykcZyIfNLwXxk14Nwo",
	"ZjUlWQHa3UWbyUsTKZRq5Hxk7BZIJWUtfU4hoag3yCnTkspVPTvl1cJSwazMyIECIDEXKawT9KElWzpl",
	"GdMrQ5gpFsnOmFNXcqOqUq4tKkmYw71RPDE7zQbED1Kunj9/8fVVOU1FThn/PteTw28Pfi1phkaMUcm/",
	"z/Vhh2s+/2s7LPfWosfNwdux+/WVf3T4LYbTNjU4/GqCobgKzW7ejmuUi2++Ovy28e7wTw+qxQG5XIue",
	"itdUWLshEbcbrn/IzWBG9keadlBzG2IxSFoQjIh7Bb3tCvQMuePh29H2+6BYi5vTViGXRtu9RF6ID1MM",
	"IYonD1HsGNIKx6gC1DWEPn6X0McmSj7tOY/Xfv9A4NC5RIaA4RAw/OMEDC1lYJDAgt38shm9HV9hgCZs",
	"SrfD/TZr3SGF8LP0YeoP9VQ6gO/ioTztg79X0Js7EDzzVfkDGypXffZi6RtZ07l1ZrmWjJuKTfSl1nc9",
	"nq6vWlFqZjA5Xal3BnEFEHLaeeW3tPPtqH5gc9YMLgmRGSuDzgE9nQGHr2SaJbQZIGrkV+OXP1K16A/Y",
	"XVC96FWKS7Xl2awNh84HcP8O4K4S6XvPjQy78PS7sP7ALGXYlk9rW0JNzDKoFrKhNm/tgKuFZNhL4LaD",
	"cULJ7TeqeRbkUR4BO+5mT0Dd5nEeAK+9DKbGp2n4O5tyMPg/JYP/VEoRKDKIjzHYIzi63NsU1e+oDI2x",
	"djnlh1xLydJ9X0e52R5hjYpV9Wc32yzPs7utqGMdOAECuTg/P3NBtWCVhSrk1pS5IT74E6xsks1ZGJwW",
	"yhJo+gvPVvZQS6gYRzDbKwRB03LUHTkExcYS7ZWmfTeYtpabYNMtVh1c7VbLaK7goZm/QY6w1cwt89hy",
	"5u1YXd86NrZ6v3nmaiekbeJjAF3fcAlzZpB563tpfyls3GuGbCcXS1txrcEX+gqvzUQwR/rSdGJzKtY7",
	"IbAEbg9Qg8QsmPUjHESWnLtUga6mGAKm3ft2ymjPYr9rJ8UVphmYMddRADMK+/DXZo+G80NfL3z2qR/G",
	"tp6000b7uGQo4RQL5fhT404mt8rr+HpONlukykK1GL7VsXGxBLlkcDe5E/KW8fn4junF2AJZTZAPT75I",
	"uRpndArZGB/gSVbP/emdGqewDFdw6883Rc60M5tYwwEmUMzTguU0WRggr+Lidm4eKEzciJfPY0Np52Al",
	"dLcWhH3TKCrgxbnVhtWK6wVoljRCy1hqZEGXMCKMJ1mZmm2xtV+MHrmkkolSVYerLChjclyrTEYlMh1Y",
	"P58Lyb+zhQHNdEbET+x98HC4ZrwMIIx/41NwFGhHcr7kksbSpDnTRPDO6TVkQ0SCLiUHlz3hUjt80RNb",
	"0clodWRBFcmFo+LaEddMnjBaYUF/LaHSrqeuto0WhCmFL6zL0ql7XklvaIZmC6xPEZVHtEdsmU3JwHEb",
	"DvfaJ4XXLsEK7icWKpa9NVIGsK9G4kYhlGJYyGXWXGnrLDyu26diYc4xnjKkxoqbwR3JGS8NuHBzC6qw",
	"cszrxqlpb/rYtBEPbZvw5ZPAXNUf3EkLSl+pwGbdJDTzkHKQ5i73USpdqZAjUvIMlCIrUdr5SEiAVaDU",
	"4ha41cYpJ4Dqp9My4zAx57aE15mG/ESUXIeShrpt1k9JqnKqbK63Qzk3e9yOuwVLFvXxcKQuWzKp3n6/",
	"wNgm1IF/alHIM9uUIMMym2RhrSCDxGj+LuWue3bTzdxPSpHS5rwg9tappX4rMpgZOxFJiqdVJZG0tOXA",
	"QDKasd/qwhTVRHF3bT4uOQCG+O8TU1iVHJgsSm7YsZm/f6td8acqhxEbHdbrcYKVC4uX3TXZhVQ5Sx+0",
	"Em/UiSxFg45ysnweP/8fkgp/3L8xhsX9Kn3XLMJJrjCmfAVKsxxzyb5q1e0zhJuZ/cNJnKCxWFn9Zlw8",
	"DeB4WqBvLTw/RJ8V5mnd00QHE+b6CyT0OjWurGy26Z0+NU412MiXquFzcDzAezha3pcqCwlLgCVupZhj",
	"pEHmjLvsUMfeLGVXOab/QH6AAmoKRKOunhJaceJGlxhZQg5FSl6dnZjS5NYzFzvzmFyIosywIyxKBkSt",
	"lIY8JpdA07ERYU9ught1BRMfk9XYVVgZU56OK3aerIKpNpDNfmb8NpAf595Yd8eby5+7Xo5qX7Za/zW/",
	"5i9PLy5PT45fn74ktRJuqQzL3hgpTud0rWwMJ8/jF88MBoPRhtvshilSZJRzKzXx/LrRsv1nz/1nW/kN",
	"t1SXbGTvxPCcvgPk+NKfsnKawPpRfqzBw1x/ZEZZVsqW0pRQZUBk8DkvM82KDKwksvl9wBNDvSAhXVeD",
	"ED5hLdyCruI0lZ/KqMRGftvCRLgHONrIUIjRbHGHmVbkf1/98qrL+s7Rj4USiaTCMstCKD1j91X1GrSm",
	"OCikOm0xHYzuZww1u6jfQIox4yncY1L49zbH3eghtCiANnUKYf0L9SEHMbOTVyQt8YSpy5BfULTeOjCM",
	"ibXxaIb4eWpVdnV0zQm5RpvjOiLjBrJVDx0j9bnGHoT2QxQmb5/dxFv0YFUSO/mqDJ/r4jraKVH92Gan",
	"j6vs9MbrKs+VNkQMAiEm3TRdo+lZQkfOOLZlmyhmvQf97/050sfEUdHOkzpzrL/SlG2qfLOwUYucKv16",
	"72T+0ib0/3P5oo/WXQvnGHZqdhWhIjVVWgo7P/4/XtZ6dmkVaS08w2h+HuAaDQ3PUPOlSyj3RE3JVdOy",
	"qqIId1g/syK6Sr9RoGuVAUUjm3NDY454bPl1q77UBSS91e3zmLHEUdW7NY+c/kGVKv3RT8pXdSuPb7i5",
	"hu/hYdGR0UHwqIgfJGDjIZWHuduJ5QCWqBxD8saYP52hlEgYiiw8Q4ApYwg0D0zLi2PyyjCyLGu9tdzI",
	"75XtE1LHeVq1Pjd5rHYWNQG31lyK0FUgBgr4qgHqLrcPgcBZ5M21xtsndplRzZs9DEp+4USJHIiNMDIP",
	"85TNZiDrEIkzaiCth/iJ8fRjRzx4r/8LvU+Phg85uKstGst2GJ9nrntrI/oQtfPbpIc9nFvL1fFMY6Fq",
	"YZazXq1u1qzgWB3BYpwo+wmZwky4YkLVfjWOhlhfRBqTK7OjTn2xQS/rPWkGuJD/aHoLtoQvWgQaCEXL",
	"hoxdrphQVUe6Lb2qPhfijmSCY1XFO8p0NUt668N03e7j7UoHlSyA/G/OXnZ3M+7dpmq/+7aqi79hH2Wp",
	"QI7nJUthUh83Ul+ULISVjxSDG+SfXZp11TiBjeWPaZZVwoN/qX0L69Hy3qchNP7UofFEpCEzpZzPLef8",
	"8fXrC783pm19TMxynhF5RlhVq3BLGnGCdo8ysKGHDfH5PcfnH2FRNM/RoUMbNpzsaWYCPBotqqDFowyQ",
	"u8WqM3N7oB4Xdx19b/XA68gt9BGWCTn2mnqSUWn9X5Rb8nNQRPKbloZhgnVziiVIabRMpuNdjjdetY43",
	"1rtCfsFYyhG5jq5KjOQZW1Q2V/rk6Gi0CXROtU+5bUzoMsKKzwQGvZjGuNoFyERwSk6XIA1ftsgTNW7H",
	"iJ7Hz+JnLlGN04JFR9HX8bP4ha3duUC4TWyK89iFCvHZHHQ4FFaZrM5x2K4lYpZSgfosdd+04q8KT/lZ",
	"6w2HevHsmY9ZgY0YYLVlW4F58m+H1W5tD5BNeyQMnyPkupwf931WZjVeGBj9ZY8zsTk8gcHfcNUz/P/8",
	"HsP7+jTe5AbXcBSpMs+pXG29z5rOVX2zmIN5dIMFOEOphTaDxN3Y1ilBU+UXtZHHftLa1Kgqd/+dsIU3",
	"9wKvwEguUSAAw9eNWxdbC3AOWAezqJmz4or0/j6YPyD97ki/FXr24fz70RoXnbxrPxiz9L0ligxCh4Zf",
	"4nOrUXhjszOPNfqw33Tpo5G6cvR2zZZNO1cc1n0z895IBZ9kdxStLWENp0eNvekKsZs1fP9LSA0f8HIT",
	"Xm6HF/3MOCjJfwC9G6b9APozQrOBrX4y6LsFpm1QJKhOFqFrQ6RmNPPpmt4O6xkhJjYL0B2ZbDe1Dv54",
	"Dd8DiYOfHMrvXwvqT5fcTgtC+ChjYvUAuoq4eDfAoCN9TsS8G+E9oC/V7tytDE6fvQxpIHc4bHeuJTo/",
	"qe0ZPnIwYNmjzM8Hd91j2O03aoPteem6CaWdM+4dKGtIdNmXMf+kVmhffn4PDw4s6QOt0edPRwsDHexO",
	"B1sjbZsG2rx18q55O85mE7RxPKPm6YHB0f/fRzMbzplsr0EFj5gEtKjW2j4JDerBUzYBZGies6lLZuVi",
	"SbPo/WBD74OSPgixu7JlS1M6iLxr5vSnTx2/l540yIZ9mNVBpNhFMkz8abux+37sy/btFBDqLf7nEz53",
	"IhQzQrhInfqj0MuGQo4D4ewltvVYlPVUloarKW4REuubwQfRjO21p7Tjf78K1lfTMmw99UP+Y0f0tl9H",
	"H83v06LbfjYnjqocK7ATefERJnKMRfAhHdhfIMr5SI7zIMv7UF1j8s7wld0jpftgnLbjT59xjrqDv2oc",
	"+O/bWEzCM7xsJkqeutMF5y4d7a0/lXPju+m5ldKljoZX5GoXfBpq046ZvYMqtZ/I9BOxkx7j+xKTdtUT",
	"8IIfQA+M4L+CETxejxoI3rvR9kdt29hMZZDii4wmTyH9bfB7IPrfl+g/D/vPpSsM9t/u9t+szAYe2uSh",
	"++Nf+zbCHufo3ZuD94/q2R1cuk/n0n2kK/eDfLh7893+AZy24XVvK7Mf46sdaG0//sPH0teusupDHYV7",
	"IdOgp/CzNRIeZxwMPsGBP2z2Ce6dV2ydirMXYl93BQ6U/pk5/QZS3keK0RPQ8Q4+vr3QctDJN5Dz5+PO",
	"+zCb4BPw3w0saF/Oso9merjLjB70ktUVxrv3ID3aRXbqpvAH85A1rqwayOhRDrJH42aXjNwNUjtTUcN+",
	"31WZdxejPVKXdxP/7GQ/+Hl/Ljq4v2NsINw9quA70UAvzfYo4FZLfgLya6vfAwU+vdrcT3yfttY8MI0P",
	"ZRp7JN6Nsr7I87G/OW23yHHzzrXwyf3mJWhPeWZ/7bK1Ad/2En7t7rBHpCLP633dslRc64a+jYXimjfg",
	"PQ1X7bsQsYe9Bqb+EQ+UtC4IHPD8UQXiwkjZg+Zr3HLyrvn3gyrDNSfQE55sk8NmHasq3d3pN6DhdKY+",
	"VIT7JGJsnX3rZbhb2tob0esH0J8Fbg2s85O1Y7dF154KcEEddyPOuluAP1G0fVJNpXUB8s6aykep1DbQ",
	"2/5NwO1IDjuyZf+RKPCe3WiyfB4ZTHUfrd1MvwS50gvG50SCvQfP3RjRuOaukd3r/TTfqGjd5dLfmfcN",
	"BLrqBnU+qNs6uNLp1TsjHjFX0ihbEZ5zlVK/wyjfdQvutapLVpUOb97//wAAAP//JPKxgeYUAQA=",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %s", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
