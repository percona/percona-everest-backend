// Package api provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/deepmap/oapi-codegen version v1.13.0 DO NOT EDIT.
package api

import (
	"bytes"
	"compress/gzip"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/deepmap/oapi-codegen/pkg/runtime"
	"github.com/getkin/kin-openapi/openapi3"
	"github.com/labstack/echo/v4"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeGcs   BackupStorageType = "gcs"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeGcs   CreateBackupStorageParamsType = "gcs"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for DatabaseClusterSpecProxyExposeType.
const (
	DatabaseClusterSpecProxyExposeTypeExternal DatabaseClusterSpecProxyExposeType = "external"
	DatabaseClusterSpecProxyExposeTypeInternal DatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterSpecProxyType.
const (
	DatabaseClusterSpecProxyTypeHaproxy   DatabaseClusterSpecProxyType = "haproxy"
	DatabaseClusterSpecProxyTypeMongos    DatabaseClusterSpecProxyType = "mongos"
	DatabaseClusterSpecProxyTypePgbouncer DatabaseClusterSpecProxyType = "pgbouncer"
	DatabaseClusterSpecProxyTypeProxysql  DatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterRestoreStatusConditionsStatus.
const (
	False   DatabaseClusterRestoreStatusConditionsStatus = "False"
	True    DatabaseClusterRestoreStatusConditionsStatus = "True"
	Unknown DatabaseClusterRestoreStatusConditionsStatus = "Unknown"
)

// Defines values for DatabaseClusterWithNameSpecProxyExposeType.
const (
	DatabaseClusterWithNameSpecProxyExposeTypeExternal DatabaseClusterWithNameSpecProxyExposeType = "external"
	DatabaseClusterWithNameSpecProxyExposeTypeInternal DatabaseClusterWithNameSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterWithNameSpecProxyType.
const (
	DatabaseClusterWithNameSpecProxyTypeHaproxy   DatabaseClusterWithNameSpecProxyType = "haproxy"
	DatabaseClusterWithNameSpecProxyTypeMongos    DatabaseClusterWithNameSpecProxyType = "mongos"
	DatabaseClusterWithNameSpecProxyTypePgbouncer DatabaseClusterWithNameSpecProxyType = "pgbouncer"
	DatabaseClusterWithNameSpecProxyTypeProxysql  DatabaseClusterWithNameSpecProxyType = "proxysql"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	BucketName string            `json:"bucketName"`
	Id         string            `json:"id"`
	Name       string            `json:"name"`
	Region     string            `json:"region"`
	Type       BackupStorageType `json:"type"`
	Url        *string           `json:"url,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// BucketName The cloud storage bucket/container name
	BucketName string `json:"bucketName"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                        `json:"name"`
	Region    string                        `json:"region"`
	SecretKey string                        `json:"secretKey"`
	Type      CreateBackupStorageParamsType `json:"type"`
	Url       *string                       `json:"url,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// CreateKubernetesClusterParams kubernetes object
type CreateKubernetesClusterParams struct {
	Kubeconfig string  `json:"kubeconfig"`
	Name       string  `json:"name"`
	Namespace  *string `json:"namespace,omitempty"`
}

// DatabaseCluster defines model for DatabaseCluster.
type DatabaseCluster struct {
	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterSpecEngineResourcesCpu0 = int

// DatabaseClusterSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterSpecEngineResourcesCpu1 = string

// DatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterSpecEngineResourcesMemory0 = int

// DatabaseClusterSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterSpecEngineResourcesMemory1 = string

// DatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineStorageSize0 defines model for .
type DatabaseClusterSpecEngineStorageSize0 = int

// DatabaseClusterSpecEngineStorageSize1 defines model for .
type DatabaseClusterSpecEngineStorageSize1 = string

// DatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterSpecProxyExposeType string

// DatabaseClusterSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterSpecProxyResourcesCpu0 = int

// DatabaseClusterSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterSpecProxyResourcesCpu1 = string

// DatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterSpecProxyResourcesMemory0 = int

// DatabaseClusterSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterSpecProxyResourcesMemory1 = string

// DatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyType Type is the proxy type
type DatabaseClusterSpecProxyType string

// DatabaseClusterCredential kubernetes object
type DatabaseClusterCredential struct {
	Password *string `json:"password,omitempty"`
	Username *string `json:"username,omitempty"`
}

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	Items *[]DatabaseClusterWithName `json:"items,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		BackupName *string `json:"backupName,omitempty"`

		// BackupSource BackupSource represents settings of a source where to get a backup to run restoration.
		BackupSource *struct {
			// Azure BackupStorageProviderSpec represents set of settings to configure cloud provider.
			Azure *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"azure,omitempty"`
			Destination *string `json:"destination,omitempty"`
			Image       *string `json:"image,omitempty"`

			// S3 BackupStorageProviderSpec represents set of settings to configure cloud provider.
			S3 *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"s3,omitempty"`
			SslInternalSecretName *string `json:"sslInternalSecretName,omitempty"`
			SslSecretName         *string `json:"sslSecretName,omitempty"`
			StorageName           *string `json:"storageName,omitempty"`

			// StorageType BackupStorageType represents backup storage type.
			StorageType     string  `json:"storage_type"`
			VaultSecretName *string `json:"vaultSecretName,omitempty"`
		} `json:"backupSource,omitempty"`
		DatabaseCluster string `json:"databaseCluster"`

		// DatabaseType EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		DatabaseType string `json:"databaseType"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed  *time.Time `json:"completed,omitempty"`
		Conditions *[]struct {
			// LastTransitionTime lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
			LastTransitionTime time.Time `json:"lastTransitionTime"`

			// Message message is a human readable message indicating details about the transition. This may be an empty string.
			Message string `json:"message"`

			// ObservedGeneration observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
			ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

			// Reason reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
			Reason string `json:"reason"`

			// Status status of the condition, one of True, False, Unknown.
			Status DatabaseClusterRestoreStatusConditionsStatus `json:"status"`

			// Type type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
			Type string `json:"type"`
		} `json:"conditions,omitempty"`
		Destination   *string    `json:"destination,omitempty"`
		Lastscheduled *time.Time `json:"lastscheduled,omitempty"`
		Message       *string    `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State       *string `json:"state,omitempty"`
		StorageName *string `json:"storageName,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreStatusConditionsStatus status of the condition, one of True, False, Unknown.
type DatabaseClusterRestoreStatusConditionsStatus string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                   `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterWithName defines model for DatabaseClusterWithName.
type DatabaseClusterWithName struct {
	Name string `json:"name"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseClusterWithName_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseClusterWithName_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseClusterWithName_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterWithNameSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseClusterWithName_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterWithNameSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterWithNameSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterWithNameSpecEngineResourcesCpu0 = int

// DatabaseClusterWithNameSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterWithNameSpecEngineResourcesCpu1 = string

// DatabaseClusterWithName_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseClusterWithName_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterWithNameSpecEngineResourcesMemory0 = int

// DatabaseClusterWithNameSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterWithNameSpecEngineResourcesMemory1 = string

// DatabaseClusterWithName_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseClusterWithName_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecEngineStorageSize0 defines model for .
type DatabaseClusterWithNameSpecEngineStorageSize0 = int

// DatabaseClusterWithNameSpecEngineStorageSize1 defines model for .
type DatabaseClusterWithNameSpecEngineStorageSize1 = string

// DatabaseClusterWithName_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseClusterWithName_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterWithNameSpecMonitoringResourcesLimits0 = int

// DatabaseClusterWithNameSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterWithNameSpecMonitoringResourcesLimits1 = string

// DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseClusterWithName.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterWithNameSpecMonitoringResourcesRequests0 = int

// DatabaseClusterWithNameSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterWithNameSpecMonitoringResourcesRequests1 = string

// DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseClusterWithName.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterWithNameSpecProxyExposeType string

// DatabaseClusterWithNameSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterWithNameSpecProxyResourcesCpu0 = int

// DatabaseClusterWithNameSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterWithNameSpecProxyResourcesCpu1 = string

// DatabaseClusterWithName_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseClusterWithName_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterWithNameSpecProxyResourcesMemory0 = int

// DatabaseClusterWithNameSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterWithNameSpecProxyResourcesMemory1 = string

// DatabaseClusterWithName_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseClusterWithName_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterWithNameSpecProxyType Type is the proxy type
type DatabaseClusterWithNameSpecProxyType string

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		AllowedVersions *[]string `json:"allowedVersions,omitempty"`

		// Type EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// AvailableVersions Versions struct represents available versions of database engine components.
		AvailableVersions *struct {
			Backup *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"backup,omitempty"`
			Engine *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"engine,omitempty"`
			Proxy *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"proxy,omitempty"`
			Tools *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"tools,omitempty"`
		} `json:"availableVersions,omitempty"`
		OperatorVersion *string `json:"operatorVersion,omitempty"`

		// Status EngineState represents state of engine in a k8s cluster.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string           `json:"apiVersion,omitempty"`
	Items      *[]DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesCluster kubernetes object
type KubernetesCluster struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Namespace string `json:"namespace"`
}

// KubernetesClusterList defines model for KubernetesClusterList.
type KubernetesClusterList = []KubernetesCluster

// PMMInstance PMM instance information
type PMMInstance struct {
	ApiKeySecretId string  `json:"apiKeySecretId"`
	Id             *string `json:"id,omitempty"`
	Url            string  `json:"url"`
}

// PMMInstanceCreateParams PMM instance create information
type PMMInstanceCreateParams struct {
	ApiKey string `json:"apiKey"`
	Url    string `json:"url"`
}

// PMMInstanceUpdateParams PMM instance update information
type PMMInstanceUpdateParams struct {
	ApiKey *string `json:"apiKey,omitempty"`
	Url    *string `json:"url,omitempty"`
}

// PMMInstancesList defines model for PMMInstancesList.
type PMMInstancesList = []PMMInstance

// UnregisterKubernetesClusterParams Options for removing a kubernetes cluster
type UnregisterKubernetesClusterParams struct {
	// Force Remove the kubernetes cluster even if there are database clusters running.
	Force *bool `json:"force,omitempty"`
}

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName *string `json:"bucketName,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      *string `json:"name,omitempty"`
	Region    *string `json:"region,omitempty"`
	SecretKey *string `json:"secretKey,omitempty"`
	Url       *string `json:"url,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// RegisterKubernetesClusterJSONRequestBody defines body for RegisterKubernetesCluster for application/json ContentType.
type RegisterKubernetesClusterJSONRequestBody = CreateKubernetesClusterParams

// UnregisterKubernetesClusterJSONRequestBody defines body for UnregisterKubernetesCluster for application/json ContentType.
type UnregisterKubernetesClusterJSONRequestBody = UnregisterKubernetesClusterParams

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = DatabaseClusterWithName

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// UpdateDatabaseEngineJSONRequestBody defines body for UpdateDatabaseEngine for application/json ContentType.
type UpdateDatabaseEngineJSONRequestBody = DatabaseEngine

// CreatePMMInstanceJSONRequestBody defines body for CreatePMMInstance for application/json ContentType.
type CreatePMMInstanceJSONRequestBody = PMMInstanceCreateParams

// UpdatePMMInstanceJSONRequestBody defines body for UpdatePMMInstance for application/json ContentType.
type UpdatePMMInstanceJSONRequestBody = PMMInstanceUpdateParams

// AsDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu0
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu0() (DatabaseClusterSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu1
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu1() (DatabaseClusterSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory0
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory0() (DatabaseClusterSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory1
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory1() (DatabaseClusterSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineStorageSize0 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize0
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize0() (DatabaseClusterSpecEngineStorageSize0, error) {
	var body DatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineStorageSize1 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize1
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize1() (DatabaseClusterSpecEngineStorageSize1, error) {
	var body DatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu0
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu0() (DatabaseClusterSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu1
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu1() (DatabaseClusterSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory0
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory0() (DatabaseClusterSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory1
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory1() (DatabaseClusterSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecEngineResourcesCpu0 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu as a DatabaseClusterWithNameSpecEngineResourcesCpu0
func (t DatabaseClusterWithName_Spec_Engine_Resources_Cpu) AsDatabaseClusterWithNameSpecEngineResourcesCpu0() (DatabaseClusterWithNameSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterWithNameSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu as the provided DatabaseClusterWithNameSpecEngineResourcesCpu0
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Cpu) FromDatabaseClusterWithNameSpecEngineResourcesCpu0(v DatabaseClusterWithNameSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterWithNameSpecEngineResourcesCpu0
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Cpu) MergeDatabaseClusterWithNameSpecEngineResourcesCpu0(v DatabaseClusterWithNameSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecEngineResourcesCpu1 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu as a DatabaseClusterWithNameSpecEngineResourcesCpu1
func (t DatabaseClusterWithName_Spec_Engine_Resources_Cpu) AsDatabaseClusterWithNameSpecEngineResourcesCpu1() (DatabaseClusterWithNameSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterWithNameSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu as the provided DatabaseClusterWithNameSpecEngineResourcesCpu1
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Cpu) FromDatabaseClusterWithNameSpecEngineResourcesCpu1(v DatabaseClusterWithNameSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterWithNameSpecEngineResourcesCpu1
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Cpu) MergeDatabaseClusterWithNameSpecEngineResourcesCpu1(v DatabaseClusterWithNameSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecEngineResourcesMemory0 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory as a DatabaseClusterWithNameSpecEngineResourcesMemory0
func (t DatabaseClusterWithName_Spec_Engine_Resources_Memory) AsDatabaseClusterWithNameSpecEngineResourcesMemory0() (DatabaseClusterWithNameSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterWithNameSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory as the provided DatabaseClusterWithNameSpecEngineResourcesMemory0
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Memory) FromDatabaseClusterWithNameSpecEngineResourcesMemory0(v DatabaseClusterWithNameSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory, using the provided DatabaseClusterWithNameSpecEngineResourcesMemory0
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Memory) MergeDatabaseClusterWithNameSpecEngineResourcesMemory0(v DatabaseClusterWithNameSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecEngineResourcesMemory1 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory as a DatabaseClusterWithNameSpecEngineResourcesMemory1
func (t DatabaseClusterWithName_Spec_Engine_Resources_Memory) AsDatabaseClusterWithNameSpecEngineResourcesMemory1() (DatabaseClusterWithNameSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterWithNameSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory as the provided DatabaseClusterWithNameSpecEngineResourcesMemory1
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Memory) FromDatabaseClusterWithNameSpecEngineResourcesMemory1(v DatabaseClusterWithNameSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Resources_Memory, using the provided DatabaseClusterWithNameSpecEngineResourcesMemory1
func (t *DatabaseClusterWithName_Spec_Engine_Resources_Memory) MergeDatabaseClusterWithNameSpecEngineResourcesMemory1(v DatabaseClusterWithNameSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecEngineStorageSize0 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size as a DatabaseClusterWithNameSpecEngineStorageSize0
func (t DatabaseClusterWithName_Spec_Engine_Storage_Size) AsDatabaseClusterWithNameSpecEngineStorageSize0() (DatabaseClusterWithNameSpecEngineStorageSize0, error) {
	var body DatabaseClusterWithNameSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineStorageSize0 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size as the provided DatabaseClusterWithNameSpecEngineStorageSize0
func (t *DatabaseClusterWithName_Spec_Engine_Storage_Size) FromDatabaseClusterWithNameSpecEngineStorageSize0(v DatabaseClusterWithNameSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size, using the provided DatabaseClusterWithNameSpecEngineStorageSize0
func (t *DatabaseClusterWithName_Spec_Engine_Storage_Size) MergeDatabaseClusterWithNameSpecEngineStorageSize0(v DatabaseClusterWithNameSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecEngineStorageSize1 returns the union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size as a DatabaseClusterWithNameSpecEngineStorageSize1
func (t DatabaseClusterWithName_Spec_Engine_Storage_Size) AsDatabaseClusterWithNameSpecEngineStorageSize1() (DatabaseClusterWithNameSpecEngineStorageSize1, error) {
	var body DatabaseClusterWithNameSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecEngineStorageSize1 overwrites any union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size as the provided DatabaseClusterWithNameSpecEngineStorageSize1
func (t *DatabaseClusterWithName_Spec_Engine_Storage_Size) FromDatabaseClusterWithNameSpecEngineStorageSize1(v DatabaseClusterWithNameSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Engine_Storage_Size, using the provided DatabaseClusterWithNameSpecEngineStorageSize1
func (t *DatabaseClusterWithName_Spec_Engine_Storage_Size) MergeDatabaseClusterWithNameSpecEngineStorageSize1(v DatabaseClusterWithNameSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterWithNameSpecMonitoringResourcesLimits0
func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterWithNameSpecMonitoringResourcesLimits0() (DatabaseClusterWithNameSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterWithNameSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterWithNameSpecMonitoringResourcesLimits0
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterWithNameSpecMonitoringResourcesLimits0(v DatabaseClusterWithNameSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterWithNameSpecMonitoringResourcesLimits0
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterWithNameSpecMonitoringResourcesLimits0(v DatabaseClusterWithNameSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterWithNameSpecMonitoringResourcesLimits1
func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterWithNameSpecMonitoringResourcesLimits1() (DatabaseClusterWithNameSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterWithNameSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterWithNameSpecMonitoringResourcesLimits1
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterWithNameSpecMonitoringResourcesLimits1(v DatabaseClusterWithNameSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterWithNameSpecMonitoringResourcesLimits1
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterWithNameSpecMonitoringResourcesLimits1(v DatabaseClusterWithNameSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterWithNameSpecMonitoringResourcesRequests0
func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterWithNameSpecMonitoringResourcesRequests0() (DatabaseClusterWithNameSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterWithNameSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterWithNameSpecMonitoringResourcesRequests0
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterWithNameSpecMonitoringResourcesRequests0(v DatabaseClusterWithNameSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterWithNameSpecMonitoringResourcesRequests0
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterWithNameSpecMonitoringResourcesRequests0(v DatabaseClusterWithNameSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterWithNameSpecMonitoringResourcesRequests1
func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterWithNameSpecMonitoringResourcesRequests1() (DatabaseClusterWithNameSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterWithNameSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterWithNameSpecMonitoringResourcesRequests1
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterWithNameSpecMonitoringResourcesRequests1(v DatabaseClusterWithNameSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterWithNameSpecMonitoringResourcesRequests1
func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterWithNameSpecMonitoringResourcesRequests1(v DatabaseClusterWithNameSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecProxyResourcesCpu0 returns the union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu as a DatabaseClusterWithNameSpecProxyResourcesCpu0
func (t DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) AsDatabaseClusterWithNameSpecProxyResourcesCpu0() (DatabaseClusterWithNameSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterWithNameSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterWithNameSpecProxyResourcesCpu0
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) FromDatabaseClusterWithNameSpecProxyResourcesCpu0(v DatabaseClusterWithNameSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterWithNameSpecProxyResourcesCpu0
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterWithNameSpecProxyResourcesCpu0(v DatabaseClusterWithNameSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecProxyResourcesCpu1 returns the union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu as a DatabaseClusterWithNameSpecProxyResourcesCpu1
func (t DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) AsDatabaseClusterWithNameSpecProxyResourcesCpu1() (DatabaseClusterWithNameSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterWithNameSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterWithNameSpecProxyResourcesCpu1
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) FromDatabaseClusterWithNameSpecProxyResourcesCpu1(v DatabaseClusterWithNameSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterWithNameSpecProxyResourcesCpu1
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterWithNameSpecProxyResourcesCpu1(v DatabaseClusterWithNameSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterWithNameSpecProxyResourcesMemory0 returns the union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory as a DatabaseClusterWithNameSpecProxyResourcesMemory0
func (t DatabaseClusterWithName_Spec_Proxy_Resources_Memory) AsDatabaseClusterWithNameSpecProxyResourcesMemory0() (DatabaseClusterWithNameSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterWithNameSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory as the provided DatabaseClusterWithNameSpecProxyResourcesMemory0
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Memory) FromDatabaseClusterWithNameSpecProxyResourcesMemory0(v DatabaseClusterWithNameSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterWithNameSpecProxyResourcesMemory0
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Memory) MergeDatabaseClusterWithNameSpecProxyResourcesMemory0(v DatabaseClusterWithNameSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterWithNameSpecProxyResourcesMemory1 returns the union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory as a DatabaseClusterWithNameSpecProxyResourcesMemory1
func (t DatabaseClusterWithName_Spec_Proxy_Resources_Memory) AsDatabaseClusterWithNameSpecProxyResourcesMemory1() (DatabaseClusterWithNameSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterWithNameSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterWithNameSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory as the provided DatabaseClusterWithNameSpecProxyResourcesMemory1
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Memory) FromDatabaseClusterWithNameSpecProxyResourcesMemory1(v DatabaseClusterWithNameSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterWithNameSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseClusterWithName_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterWithNameSpecProxyResourcesMemory1
func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Memory) MergeDatabaseClusterWithNameSpecProxyResourcesMemory1(v DatabaseClusterWithNameSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseClusterWithName_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseClusterWithName_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// ServerInterface represents all server handlers.
type ServerInterface interface {
	// List of the created backup storages
	// (GET /backup-storages)
	ListBackupStorages(ctx echo.Context) error
	// Create a new backup storage object
	// (POST /backup-storages)
	CreateBackupStorage(ctx echo.Context) error
	// Delete the specified backup storage
	// (DELETE /backup-storages/{backup-storage-id})
	DeleteBackupStorage(ctx echo.Context, backupStorageId string) error
	// Get the specified backup storage
	// (GET /backup-storages/{backup-storage-id})
	GetBackupStorage(ctx echo.Context, backupStorageId string) error
	// Partial update of the specified backup storage
	// (PATCH /backup-storages/{backup-storage-id})
	UpdateBackupStorage(ctx echo.Context, backupStorageId string) error
	// List of the registered kubernetes clusters
	// (GET /kubernetes)
	ListKubernetesClusters(ctx echo.Context) error
	// Register kubernetes cluster in Everest
	// (POST /kubernetes)
	RegisterKubernetesCluster(ctx echo.Context) error
	// Remove the specified kubernetes cluster from Everest
	// (DELETE /kubernetes/{kubernetes-id})
	UnregisterKubernetesCluster(ctx echo.Context, kubernetesId string) error
	// Get the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id})
	GetKubernetesCluster(ctx echo.Context, kubernetesId string) error
	// List of the created database cluster restores on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-cluster-restores)
	ListDatabaseClusterRestores(ctx echo.Context, kubernetesId string) error
	// Create a database cluster restore on the specified kubernetes cluster
	// (POST /kubernetes/{kubernetes-id}/database-cluster-restores)
	CreateDatabaseClusterRestore(ctx echo.Context, kubernetesId string) error
	// Delete the specified cluster restore on the specified kubernetes cluster
	// (DELETE /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	DeleteDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// Returns the specified cluster restore on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	GetDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// Replace the specified cluster restore on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	UpdateDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// List of the created database clusters on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters)
	ListDatabaseClusters(ctx echo.Context, kubernetesId string) error
	// Create a database cluster on the specified kubernetes cluster
	// (POST /kubernetes/{kubernetes-id}/database-clusters)
	CreateDatabaseCluster(ctx echo.Context, kubernetesId string) error
	// Delete the specified database cluster on the specified kubernetes cluster
	// (DELETE /kubernetes/{kubernetes-id}/database-clusters/{name})
	DeleteDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Get the specified database cluster on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters/{name})
	GetDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Replace the specified database cluster on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-clusters/{name})
	UpdateDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Get the specified database cluster credentials on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters/{name}/credentials)
	GetDatabaseClusterCredentials(ctx echo.Context, kubernetesId string, name string) error
	// List of the available database engines on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-engines)
	ListDatabaseEngines(ctx echo.Context, kubernetesId string) error
	// Get the specified database engine on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-engines/{name})
	GetDatabaseEngine(ctx echo.Context, kubernetesId string, name string) error
	// Update the specified database engine on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-engines/{name})
	UpdateDatabaseEngine(ctx echo.Context, kubernetesId string, name string) error
	// List of the created PMM instances
	// (GET /pmm-instances)
	ListPMMInstances(ctx echo.Context) error
	// Create a new PMM instance object
	// (POST /pmm-instances)
	CreatePMMInstance(ctx echo.Context) error
	// Delete the specified PMM instance
	// (DELETE /pmm-instances/{pmm-instance-id})
	DeletePMMInstance(ctx echo.Context, pmmInstanceId string) error
	// Get the specified PMM instance
	// (GET /pmm-instances/{pmm-instance-id})
	GetPMMInstance(ctx echo.Context, pmmInstanceId string) error
	// Update the specified PMM instance
	// (PATCH /pmm-instances/{pmm-instance-id})
	UpdatePMMInstance(ctx echo.Context, pmmInstanceId string) error
}

// ServerInterfaceWrapper converts echo contexts to parameters.
type ServerInterfaceWrapper struct {
	Handler ServerInterface
}

// ListBackupStorages converts echo context to params.
func (w *ServerInterfaceWrapper) ListBackupStorages(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListBackupStorages(ctx)
	return err
}

// CreateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) CreateBackupStorage(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateBackupStorage(ctx)
	return err
}

// DeleteBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteBackupStorage(ctx, backupStorageId)
	return err
}

// GetBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) GetBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetBackupStorage(ctx, backupStorageId)
	return err
}

// UpdateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateBackupStorage(ctx, backupStorageId)
	return err
}

// ListKubernetesClusters converts echo context to params.
func (w *ServerInterfaceWrapper) ListKubernetesClusters(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListKubernetesClusters(ctx)
	return err
}

// RegisterKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) RegisterKubernetesCluster(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.RegisterKubernetesCluster(ctx)
	return err
}

// UnregisterKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) UnregisterKubernetesCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UnregisterKubernetesCluster(ctx, kubernetesId)
	return err
}

// GetKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) GetKubernetesCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetKubernetesCluster(ctx, kubernetesId)
	return err
}

// ListDatabaseClusterRestores converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusterRestores(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseClusterRestores(ctx, kubernetesId)
	return err
}

// CreateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateDatabaseClusterRestore(ctx, kubernetesId)
	return err
}

// DeleteDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// GetDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// ListDatabaseClusters converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusters(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseClusters(ctx, kubernetesId)
	return err
}

// CreateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateDatabaseCluster(ctx, kubernetesId)
	return err
}

// DeleteDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// GetDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// GetDatabaseClusterCredentials converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterCredentials(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseClusterCredentials(ctx, kubernetesId, name)
	return err
}

// ListDatabaseEngines converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseEngines(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseEngines(ctx, kubernetesId)
	return err
}

// GetDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseEngine(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseEngine(ctx, kubernetesId, name)
	return err
}

// ListPMMInstances converts echo context to params.
func (w *ServerInterfaceWrapper) ListPMMInstances(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListPMMInstances(ctx)
	return err
}

// CreatePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) CreatePMMInstance(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreatePMMInstance(ctx)
	return err
}

// DeletePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) DeletePMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeletePMMInstance(ctx, pmmInstanceId)
	return err
}

// GetPMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) GetPMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetPMMInstance(ctx, pmmInstanceId)
	return err
}

// UpdatePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) UpdatePMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdatePMMInstance(ctx, pmmInstanceId)
	return err
}

// This is a simple interface which specifies echo.Route addition functions which
// are present on both echo.Echo and echo.Group, since we want to allow using
// either of them for path registration
type EchoRouter interface {
	CONNECT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	DELETE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	GET(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	HEAD(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	OPTIONS(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PATCH(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	POST(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PUT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	TRACE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
}

// RegisterHandlers adds each server route to the EchoRouter.
func RegisterHandlers(router EchoRouter, si ServerInterface) {
	RegisterHandlersWithBaseURL(router, si, "")
}

// Registers handlers, and prepends BaseURL to the paths, so that the paths
// can be served under a prefix.
func RegisterHandlersWithBaseURL(router EchoRouter, si ServerInterface, baseURL string) {
	wrapper := ServerInterfaceWrapper{
		Handler: si,
	}

	router.GET(baseURL+"/backup-storages", wrapper.ListBackupStorages)
	router.POST(baseURL+"/backup-storages", wrapper.CreateBackupStorage)
	router.DELETE(baseURL+"/backup-storages/:backup-storage-id", wrapper.DeleteBackupStorage)
	router.GET(baseURL+"/backup-storages/:backup-storage-id", wrapper.GetBackupStorage)
	router.PATCH(baseURL+"/backup-storages/:backup-storage-id", wrapper.UpdateBackupStorage)
	router.GET(baseURL+"/kubernetes", wrapper.ListKubernetesClusters)
	router.POST(baseURL+"/kubernetes", wrapper.RegisterKubernetesCluster)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id", wrapper.UnregisterKubernetesCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id", wrapper.GetKubernetesCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores", wrapper.ListDatabaseClusterRestores)
	router.POST(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores", wrapper.CreateDatabaseClusterRestore)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.DeleteDatabaseClusterRestore)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.GetDatabaseClusterRestore)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.UpdateDatabaseClusterRestore)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters", wrapper.ListDatabaseClusters)
	router.POST(baseURL+"/kubernetes/:kubernetes-id/database-clusters", wrapper.CreateDatabaseCluster)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.DeleteDatabaseCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.GetDatabaseCluster)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.UpdateDatabaseCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name/credentials", wrapper.GetDatabaseClusterCredentials)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-engines", wrapper.ListDatabaseEngines)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-engines/:name", wrapper.GetDatabaseEngine)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-engines/:name", wrapper.UpdateDatabaseEngine)
	router.GET(baseURL+"/pmm-instances", wrapper.ListPMMInstances)
	router.POST(baseURL+"/pmm-instances", wrapper.CreatePMMInstance)
	router.DELETE(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.DeletePMMInstance)
	router.GET(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.GetPMMInstance)
	router.PATCH(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.UpdatePMMInstance)
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{
	"H4sIAAAAAAAC/+x9e3PbNrb4V8GwO1O7lag47e6v65lOx3Wc1r/Uicd2eude27cLkZCENQmwAChbTfPd",
	"7+DgwYdAWbLkxN7qP4kA8Tg473Nw+CFKeF5wRpiS0f6HSCYTkmP4+SNObsriXHGBx0Q/SIlMBC0U5Sza",
	"t81ImnZE2YiLHENjLyoEL4hQlMBIwzK5IeotzmEYNStItB9JJSgbRx97EU2Dj1lXf0HGsIRAk3nwISKs",
	"zKP9y0h+E/Ui/EcpSNSLxomMrnvzL5UiCwwGE/1eUkFSPRJNI7ukXn0/fjV23Gp8Pvw3SZQevwFI+QuV",
	"Sk9HFckBOn8TZBTtR18MqpMY2GMYNM/AbzDCQuCZ/n8oCFak0e0UC2xGXnhghe5GFBFy7rxwkhAp35BZ",
	"EMbN02zOcTEhKMl4mfppTO9BwpnClBGBLAw7j7s54AEqJREoJSPKiB5Vd4cxEB8hNSE1BIS/r96em2aD",
	"jmiiVCH3B4ObckgEI4rImPJByhOp15SQQskBnxIxpeR2cMvFDWXj/i1Vk745QDnQo8nBFymT/QwPSdaH",
	"B1EvInc4LzI4jlvZT8k0tK0FyCpJIojqAvPjoXIIi6sjr69rGew2GPjGg/cwK6UiogsLq3NAdow29uke",
	"CWcjOl7IFiro55RR/VIXVskCJxa1RrjMVLQfFUQknOE+mRJBpJp/Mwyy2tJCoHiFFR5iSSwI9JTNrcmC",
	"JPMgab12XpDEIrwElE6J1OtAUmEFaN96IZ5nuEDqnSyAmnGHliEUJKEjmoR5N2F4mJF0fqwj06AHw2iU",
	"4TFSHJnedmRZgXXIeUYwA6xPJiQtMxLAjXPXZAbNqFR6u26d/sVexTxD+3PDtPfpHpsTLAVsON7MjoET",
	"2QmC2w6zN019bpkNpjY3VIXSBt8ssw+z4XftLqE5Gp3Q4RlSE6waiOdYa8Y9cgT4myJMNx7ygoYO9azZ",
	"wa+kzIdE1I43Mc2KI0G0qIh6kWHh0X5EmfrmZTU7ZYqMiahjUzcyuQkTwdkCuLYI3iGBl/nzUK9NHmIG",
	"TUndMXzoxRQrfM5LkZAwqzBt/qAw0i8gaZ6OuEBDzpVUAhdaVGLEyC1KLEcKM4owEv3o20LYY09tJHju",
	"fjs00WdYyiePu60jqYEitM7QSRE2poyEGIV+7tadWm6NTPd7+G0l+ZpjHsJzN6YdqsHJwtRZZDTBQbI0",
	"LfP0aMf2ry5Fh4IYBAzOZJsQFoZRus4oozlVEpCW4GTSmjpGxyPEuEKSqN7cS3ow3Ujzgkug1BYgixJ0",
	"WTZ7N4r2Lz/ML3pOubjutYF++t7BR//0S7B4k4PV1IsKrBQR+oX/3bm6+vrP/u4POzuXL/r/vP565+oq",
	"hl9f7f6w+6f/9/Xu7s7O5ZuTny5Oj67p7p+XrMxvzL8/dy7J0fXy4+zu/vC3qBfd9SvNqk+Z6nPRt/va",
	"V6IkH3tRTnIuZmsD5QSGcXAxgz5v0HwM0Lbssnsd02lSomM3bYps4WSGZYBCDvVjN6AfCR4aVgoUohsL",
	"IiSVWqCiKc/KHLrRPET6kv5B1j7rc/qH36ke0PHf7nU8lwOvs34AVbcMnzNyZ0X7+KFjyB6TRJyDOSXD",
	"0u59s0NQF4RmZC1oLdP1UzCLTZMMzTzVJ2QMz+aMv5qG1gZc9/ukpCOLBQZhzhlV3EC7PfmJb/P8o3ry",
	"CIZIbS0hpbzI8/nxTk9OwASzAJfo9OREiyBF2VjOmws0t2xi7ggyPqZhy7/AUt5yEfZ7FeUwo8lBmgpi",
	"mEXAcSCmRPzMjSOpo1ljVtgXMHdiSwjvsxpbR6bL0GpaCc+LUpGwCIhDPJDmYSZIcwlGX0UDUhOBX17P",
	"+4EoA2yJXZN5uWfUQK0ZlJKkaDhDakIl8s6nGF0xdKEfaWRhCGfFBKMRJVmKMEvdyqVBH0dqr2YM5zRx",
	"oDjIvKI7IliVgqAxVqQa24ynJ8nzUmk8jNGxQglmiLNshoaaphXwdL8yAFSHVXtW3yQSZEQEYVqf4kzT",
	"r9LCmKFTnmq0jRu9A/BfYIjmpVQoxyqZNJhQY5qCp3EA9I5ZnfIU3U4IKHp1UOjzACjk+AbwBqsKYfAU",
	"0wzolTJJU4Jw7ciW883ca4G1pIJGs36Oi/4Nmcn6KPO97DA5LoCoQfsEwZqmVEMPZ6dN7+lqAveZKI9N",
	"dPnF6OBNRpDjO5qXOcI5Lxl4btqsQSKcZfxWo8IJFyZosL+Ui7ahVw1yzPCY9P2w/YqOBlGQwf1eErk9",
	"tjMLh/bBUXbvwTmKA6PMj0Ml4jlViqTAzmp020MUDHJcZgrUWIsydGSIn0pE7rSZR1U2c6KfpD3E1YSI",
	"WyqJfgkzbd9lIEvg6PtOAkxxVpK4WkmCmbYGyV1CSGon+6RY9jH0ZFmfT4E1gwzoIvC8qdpIxQsjeL1T",
	"J6DZCH43C4ynHzvVC/o0ta6mya0lZKGlh6BYBfujW5plWqDhosioxQI99phOCbPKZYwONELlnIEtk2Br",
	"0FidqiUpFAckEjwz+umdJjOcIROh0M0Np0rS5QNfzpFi9nSvH4XcFVyGPD3wvDmY6XuPJUgL48Y7w2wc",
	"0ruOT+vtbgLnET8+df4+Ydp3Do9fnemDg9l2gXQ0p3VQGwmeN89WgZCmEjFuPCrwZsO33hGSqoKPlXnk",
	"4iqaZ+rTinqLbCYDIP12D7SioaZRe8xc+COPej74VRvXt173ltNtV/eAmXP8HA6wxsxb/9fW//XZ/F/3",
	"uz4MrlrPhyPUnLMx1xufYCOCrCiSv2vaLcZDXrKEiKWId05+grf9Ouisw6qU90dWoVsjTMCHYC2vElyd",
	"cKnCRtTPtsVByPX0FpEXV47tCU31QLxzzDYnUgYdkCemwWhQSuB66g3CQ16qsHZQ8zBwoQK6ARfKn63+",
	"vcSql2KMOJ2FmCJOZ/OsF3prI3NJtuu8nN1uS8UVzurMffmxO7DKopH318I/a/92Qt1C4h3LZobq7kN3",
	"yBVYIsvgUJCUMEVx9pBki7onqsqoEJyrLnfmfP5FuPfH+5fuUqEWEq3uZN01ZiBjP3jvXF0vMtoFlaBW",
	"tlXEkO/OqTpLJWO1FvZfVE3AqRsK9t639TMiFRfk3t3bfg7ZzmEpXst2W7Q7FKazRAenx/ObxQX9tcsp",
	"fHB67PzCde5ovcKaPZqJAcZUW4OFINIZZfqxP54YnYP/USI54WWW6pOaEqGQIAkfM/qHH80r8xlWRB+y",
	"0wHBtuuBRy7HWrbCsZesNgJ0CRt4Y6rim+/AutNWR8momkH+maDDUnEhBymZkmwg6biPRTKhiiSqFGSA",
	"C9qHxUK6gozz9ItKqwtQww1lAZPtDWXWYLPJarDUCmLOq3h2dH5RqQ0AVYvfvqusYKnhQNmICGstCZ5b",
	"931acMocy6eEKSTLIWiIzuuBFI/RobGPhwSVRYoVGPIMHeKcZIdYkkeHpIae7GuQybC0U1hjc83uqIn3",
	"ZdKmLKWsnD1l34vvyY2YT4M0uUYdiRo/1lprB+rjCEAyzoizgpajMVEIu3QKxZEoGTJE3ZGrZPIBu2a3",
	"+aCCT2lq88qaS9Gr8CsyhjfYrC6Js7Cvxh0pvUHAeC/J246MzmYuqKGVKc5oWiVvOhavpbRnEwd6s7pd",
	"k5AoMyLjEColXiBKE1kLrtIRzvtgxqTeLhnRu1Xzj2147DAc5z2/OHj76uDsVQ+9PTo4++X47VEPHb77",
	"5ZX5dXB2+PPxr0fA3H86PEU/c4V2XgMRM5XNrClPUm0i5zwFdxlIgN0eOuQ8QzvHbLRc9wNNrFOCds6w",
	"IAv7wmoA8Pc74ucBH0xvIlo8G69IMBu8M54mv9li+hbTnw+mS5kdW5XG9OqUJVLe26OZMtfV/lvYbG9Q",
	"CdjwNeoYNu8F6BGC2DbFZaYWLjOcK/BbZ6ZAOp8vPTer63MR3JjJtIMdSYVZKr1qLMtCG7H2dGv5dzJG",
	"Z3Q8UYjxW0TVl9IEZYu7BBTOQubpMEY/81sytVEMa/UWsoeKMXTCbGbiFFaC348x7a22NraGU8PpPQ/w",
	"bXSqPtr4yYgyEQlvKWu1sa9o+PpGwpmJqzXtqTnfu+lUmW8pUZhm5tw4IwhrZc8bc0kpBKi0bgeg/R6c",
	"HiPnVI1Rv983cXepRJmAragtCZbacERKBZgPUg8OMQ1tpSFsdGYTdyiwmqDYQDyuthIj9Boc0mDq9tAV",
	"A/JArzm38DZzfkCDATqrSKqCvvGqG21vxPmXsrmlWL/4hvFbFpod5sKC7KOr6MDFyK+iHrqKTgUfCyIl",
	"ZWP9QCPlVfSKjAVOSXoV6WG/LrBKJidEjMkbMvseBvOPz5XAioxn3+e6HZ5rI1oj4/c5LvyDE1z4l/3p",
	"SXR5rRX26V5cnei//i0527+qIUKP5xoPCjW7ilBj1v2rCOZ1z90i968AsfRjwRUflqP9q2g4U0T29nqC",
	"FD0tMr+vZriK/qXPZDCw1AiHKdHHOYTOsFQXAjMJ713QkLie7+PDLlgqpBHf5ru4LSvfW6OaNsk48w4h",
	"iF7CsmKLnsYcHoK+by4rlSwlIptpKV+NmkwwG2v7DB1XsVJtu91oPIHIDUOldHYkrMuPqEnDoLQdBpSO",
	"JCGFSUSpe74W0nOn+zGv3I8YTcocM3DamXQr18ZSCBCysafvyjFZQc0CRtu2Q6IpE5DF2s16qTm++4Ww",
	"sZpE+9+8/H//+C6YUW6Y3E+EEeG1yuaS5/vU5Z9eU+zsz3hc9QHYN0/8FhttUjPRFJWF3oPmEJRp8ZOQ",
	"HqKj8GDUU342Q3sve2howTFP95d313FgyVSif/Za66ESabDykZZyBN1SNdEGI7BQq0sGWCjx641bntB/",
	"fKuhbtIBov0XHf5cGQKyeV4xdqxpeCxwnmNFE0RBYRpRIurYYYJh8KIT3H5zX0pLeDV8ORU8LRMigKO6",
	"SHSdImcFMQhlBCEidxoW3mFkfEoEM7ADzJQu+Gy46O2EACsB95d9R8CqpLYPSIowGpdYYKYIScHThi5c",
	"3xqN48q34hC6nh2ml2j9MYD0LWzfe/HyWzgI/6ARSro86P8P7v9xvWN/vOj/87fe/vVXtb/XJvYTUBTD",
	"WkXLje0g2gOWxkfoQpSkh17jTJIees+AF8W1wI9uj3oRdIh6ke0RvKQY1lFBxEDqiUfumn8KAZFpERpb",
	"aRwnPB/U/FdaDTjRillFSUaAtk/RpC3jRHApawkuGb0hyEtZQ59DkmDQG8SQKoHFrFqddGphKcmozNCO",
	"JATFjKdknqB3DdniIc2ommnCTOEaYUatupJrVRUzZVBJkDG504onpOKZ6P9OyuTe3stvzsthynNM2etc",
	"DXZ/2Pm9xBkYMVolf52r3RbX3PtHMwZ5adDjeueyb3995R7t/gCxw0Uddr8aQNzRo9n1Zb9Cufj6q90f",
	"am27f7tXLQ7I5Ur0eF7jsXZB1nE7N+E+N4Oe2d3fWkHNrYnFIGmRYPjfKehNV6BjyC0P34q238clMpG6",
	"wg9LBWBqfTcSh0EuTLENUTx6iGKtAJeLUQWoaxv6+CShjyUo2UchNflkmU1rCad8PyyPeiWcCeTLtHrc",
	"E8r0XAJimLX9HnVctmy23zO6dQFtA6TbAOlfJ0BqKAOCIgbs+pdJ1275RgM0YfL1Le43RckK+aHP0mer",
	"HuqZtQBfxSN71AV/Z5DUTyB4oc/7P2sqZnWxZuo6GVdB40J6xdUXVRLpujfR9vDasSrFsJ6eZnXDzhXE",
	"HiDoqNXkjrT1bq96YBISNS5xnmmrypQ5UpOAg1tQRRNcD4jVkufhzZ+xnHQHKE+xmnQaAaVc8uLdgooC",
	"W3B/AnD7WxKdl4K2p/D4pzD/QG9leyxP61hCXfQ2sOKipjYv7XCshGTYK2KPgzKE0c13sn7RZy0PiJl3",
	"seej6rOex8NpL1tT42k6OqxNuXVwPCUHx5EQXAT4hX4MwS3OIMTQpKhux2xojrlyhQ/Jnb+nbukDChQu",
	"X4K0eu16me2tVHR0HjgBAjk9OTm2QcRgCQ0fYlxYGRYX9A2ZmaSi43RBddiOuxMPKeKqe/baM4egWNui",
	"KXLZVdOysd0Eui6x6+Bul9pGfQf3rfw9cISlVm6Yx5Irb8Ymu/axsNfHxStfrVJuHR8D6PqeCTKmGpmX",
	"rlT6rjBxvhGwnZxPTTm9Gl/oqqo34sGc8DM9iMkhmR8EkSlh5nY8EZD1M3+BBYmSMZsa0dYUQ8A0Z78t",
	"DvyfVxy4k03M4QDlIOZxQXOcTDSQZ3FxM9YPJCSqxNO9WFPaCTESul3ow7TUKkY4cW60YTljakIUTWqh",
	"dKgjM8FT0kOUJVmZ6mMxhX20HjnFgvJS+ptzBpQxOqhUJq0S6QGMn8+mIHwwVR/1cnrILexj8Oa/oqwM",
	"IIxrcSlHkihLcq6eloK6szlViLPW1URgQ0gQVQpGbLaITWVxFW1MuS6t1aEJlijnloorR1w9WURrhQX+",
	"vSReux7awkWKIyolNBiXpVX3nJJe0wz1ERifIiiPYI+YGqqCEsttGLlTLgm+cgl6uB8aqBj2VkuRgLFq",
	"iSoFl5JClZ5RfaeNQgewb5d6BjnWcIUUaytuRG5RTlmpwQWHW2AJZYEualfinelj0mQctE2Cm0t6syWd",
	"4CQNKF0ZCpNllODMQcpCmtlcTyGVVyF7qGQZkRLNeGnWI0hCqAel4jeEGW0cM0RA/bRaZhwm5tzUZztW",
	"JD/kJVOhJKl2n/krsLIcSpPbblHOrh6O43ZCk0l19x+oy9TDqo7fbTA2CYTEPTUo5JhtioBh6UMysJYk",
	"I4nW/G2KYftirl25W5REpcnxAeytUmndUWRkpO1EICmW+jIxaWlqvRFBcUb/qKqO+IXC6Zr8Y7RDKOC/",
	"S8ShPhkymZRMs2O9fteqbGUvn7MJnXar/VjByrjBy/aezEZ8jtaDduKMOp6lYNBhhqZ78d7fUcpdLYfa",
	"HAb3fbqy3oSVXGFM+YpIRXPInfuqUZRRE26mzw8WcQjGorf69bxw+8HytMDYijt+CD4ryEu7w4kKJgh2",
	"V7/odGqcG9ls0lldKqCssZEvZc3nYHmA83A0vC8+6wrquyV2p5BTpYjIKbPZsJa9Gcr2ObW/Aj8AATUk",
	"SIGuniLsOXFtSIgsAYdCJfN3RYY4uXHMxaw8Rqe8KDMYCCrOESRnUpE8RmcEp30twh7dBNfqCiR6JrO+",
	"LZ/Txyzte3aezIKpRSQb/ULZTSAf0LYYd8f7s1/aXg5/Lkvt/4pdsVdHp2dHhwcXR69QpYQbKoOaRlqK",
	"4zGeqwnE0F788oXGYKK14Sa7oRIVGWbMSE0oTqC1bPfannstXu6G+lLqkonsHWqe01UdABrdrTKrCczX",
	"aYACS9SOh0aYZqVoKE0JlhpEGp/zMlO0yIiRRCafkbBEUy8RJJ1XgwA+YS3cgM5zGu+n0iqxlt+m6hSc",
	"AczW0xSiNVs4Yaok+v/n7962Wd8J+LFAIqGUG2ZZcKlG9M6XJgJrihEJVKcMphOt+2lDzWzqDyJ4n7KU",
	"3EES/GuT06/1EFwUBNd1Cm78C9WlDj4yi5coLeFGrb0RMMFgvbVgGCNj4+EM8PPIqOxy/4ohdAU2x1WE",
	"+jVk8w8tI3W51Q6E5kUQJpcvruMlRjAqiVm8r7Foh7iKVkrMPzDZ+H2fjV9r9nm9uCZiAAgxaqcla03P",
	"EDpwxr6pyYUhyz/of+/OCT9AlopWXtSxZf1eUzZXA+pVqxrk5PXrjZP5K3OB4bfpyy5atz2sY9iq2T5C",
	"hSqqNBR2cvDfTtY6dmkUacUdw6i/HuAaNQ1PU/OZTaB3RI3Red2y8lGEWyiO6onO6zeSqEplANFIx0zT",
	"mCUeU1vfqC9VdVBndbu8bahf5Uc35pHVP7CUpbvqitms6uXwDQ5X8z24HNvTOghcjXGTBGw8oPIwdzs0",
	"HMAQlWVIzhhzt1Gk5AkFkQV3JiBlDIDmgGl4cYzeakaWZY1Ww43cWZkxSWo5T6OQ6yKP1cqiJuDWGgse",
	"+s6LhgI01UDd5vYhEFiLvL7XePnELj2rbtnApOgdQ5LnBJkII3UwT+loREQVIrFGDUmrKd5Qln7uiAfr",
	"9H+B92lt+KCd28qiMWyHsnFmhzc2ogtRW79NutvBuZWYHYwUVCHnejvzpQhH9fKc/soZZUiaV9CQjLit",
	"FOXPq3YVxvgi0hid6xO16osJehnvST3ABfxH4Rti6jODRaAIwmDZoL7NFePSD6Sa0suPOeG3KOMMSmbe",
	"Yqr8KvGNC9O1h4+XqwtV0gDyvz9+1T7NuPOY/Hl3HVUbf8M+ylIS0R+XNCWD6nqV/KKkIaxcUwwukH9m",
	"a8ZVYwU21LbGWeaFB/tSuR7Go+W8T9vQ+GOHxhOehsyUcjw2nPPni4tTdza6b3UtznCeHnqBqC9EuSSN",
	"WEG7QRlY08O28fkNx+fXsCjq9wbBoU0W3GSqZwKsjRY+aLGWAXI7mbVWbgoIwOauotdGD7yK7EbXsEzQ",
	"gdPUkwwL4//CzJCfhSKQ37DUDJMYNyefEiG0lklVvMp1zvPGdc7qVNA7iKXso6vovIRInrZFRX2nj46O",
	"WpsA51TzVt/ChC4trNiIQ9CLKoirnZpvOKIj8w1Hy62j2qdPor34RfzCJqoxXNBoP/omfhG/NIVZJwC3",
	"gUlx7ttQITwbExUOhXmT1ToOm7VT9FY8qI9T+07z869wq9FYbzDVyxcvXMyKmIgBlNI25bUH/7ZYbfe2",
	"ytdiTfgcINfm/HDuozKr8ELD6NsNrsTk8AQmf89kx/R//xTTu3o8zuQmtmMvkmWeYzFb+pwVHsvqs3Hu",
	"C73XUF01lFpoMkjs5/haJXd8flETeQLf9o38twx+5Kaq6kbg1f0V4QAML2qf1GxswDpgLcyies6KrcD8",
	"aTB/i/SrI/1S6NmF8x97c1x08KH5oE/Tj4YoMhK6JP0KnhuNwhmbrXXM0Yd5p00ftdSV/cs5WzZtfb+y",
	"Gpvqdi0VXJLdfjS3hTmc7tXOpi3Erufw/duQGr7Fy0V4uRxedDPjoCT/iajVMO0nop4Rmm3Z6pNB3yUw",
	"bYEigVUyCX0TRiiKM5eu6eywjhliZLIA7ZXJZlfj4I/n8D2QOPjkUH7zWlB3uuRyWhDAR2oTqwPQPuLi",
	"3ABbHek5EfNqhHePvlS5c5cyOF32MkkDucNhu3Mu0flRbc/wlYMtlq1lft576g7Dbr6TC2zPMztMKO2c",
	"MudAmUOis66M+Ue1Qrvy8zt4cGBLD7RG9x6PFrZ0sDodLI20TRpo8tbBh/qnjxaboLXrGRVPD0wO/v8u",
	"mllwz2R5DSp4xSSgRTX29iQ0qHtv2QSQoX7PpioRlvMpzqKPWxt6E5T0IMRuy5YlTekg8s6Z00+fOj6V",
	"nrSVDZswq4NIsYpkGLjbdn37ft+VKVwpINRZ7NAlfK5EKHqGcFE++VehlwWFK7eEs5HY1roo66gsDVeP",
	"XCIk1rWCB9GMGbWjlOV/vgrWVcMzbD11Q/5zR/SW30cXzW/Solt+NYeWqiwrMAt5+RkWcgBF/0m6ZX+B",
	"KOeaHOdelvdQXWPwQfOV1SOlm2CcZuCnzzh77cnf1i78dx0sJOFpXjbiJUvt7YITm4526W7lXLthOr7C",
	"aVNHwzuytQuehtq0YmbvVpXaTGT6kdhJh/F9Bkm78hF4wU9EbRnBfwQjWF+P2hK8c6NtjtqWsZnKIMUX",
	"GU4eQ/qb4PeW6D8t0T8P+8+mK2ztv9Xtv1GZbXlonYdujn9t2ghbz9G7MQfvX9Wzu3XpPp5Ld01X7oN8",
	"uBvz3f71nLb+mz7LSu11vLVbatuMB3FdCltVWj3UVbgRQg36Cp+tmbCeefBpnAFbMl3bObdxkl06J2Yj",
	"NDfvk9sS3DPzvi0S7FuSXjXn5xHoeQWn20ZoOuh1e75k/axcYw/Trlf0hW1pfH330FNRtQeJIFBmCWfd",
	"vqIl2FRtmA0pAoe1hW11guelE1Rnt9UKHkUrWJ3c1ucc9sNf93qUq2r87W+Gre1OPrJL+It5k2ufd9uS",
	"01rO5LVxs01G9mtrK1NRzdO1qsi1HxFcU8rahT87yUrcup+LSHTf49sS7gbl4Eo00EmzHbaxMWAfgfya",
	"lvGWAh/fLO4mvo1bxVum8SSYxgaJd6GsL/K8774yuFqWRf37hOEqF/UPBj5mfYu5DxNu8W0jqQrtE3aI",
	"VOR5da5LllVsfM1yYVHF+tciH4erdn08tIO9Bpb+GS9fNT6mucXztYophpGyA83nuOXgQ/3vg6oo1hfQ",
	"EchvksNiHcuXuW+NG9BwWkvfVk98EmHw1rl1Mtwlbe2F6PUTUc8Ct7as88nascuia0e1xKCOuxBn7Rez",
	"nyjaPqqm0vhY+Mqaymeparilt82bgMuRHAxkPpEBRAHfpI4G071IY6p9qU0rR1MiZmpC2RgJYr4Zab+u",
	"UvskZC0T3vlpvpPRvMulezDnGwgM1Q7qPGjYKrjSGtU5I9ZYK6qVeAmv2V8/WWGWH9vFKRuVWH1V0OuP",
	"/xcAAP//95hJPBLYAAA=",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %s", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
