// Package api provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/deepmap/oapi-codegen version v1.13.0 DO NOT EDIT.
package api

import (
	"bytes"
	"compress/gzip"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/deepmap/oapi-codegen/pkg/runtime"
	"github.com/getkin/kin-openapi/openapi3"
	"github.com/labstack/echo/v4"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeGcs   BackupStorageType = "gcs"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeGcs   CreateBackupStorageParamsType = "gcs"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for CreateDatabaseClusterSpecProxyExposeType.
const (
	CreateDatabaseClusterSpecProxyExposeTypeExternal CreateDatabaseClusterSpecProxyExposeType = "external"
	CreateDatabaseClusterSpecProxyExposeTypeInternal CreateDatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for CreateDatabaseClusterSpecProxyType.
const (
	CreateDatabaseClusterSpecProxyTypeHaproxy   CreateDatabaseClusterSpecProxyType = "haproxy"
	CreateDatabaseClusterSpecProxyTypeMongos    CreateDatabaseClusterSpecProxyType = "mongos"
	CreateDatabaseClusterSpecProxyTypePgbouncer CreateDatabaseClusterSpecProxyType = "pgbouncer"
	CreateDatabaseClusterSpecProxyTypeProxysql  CreateDatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DBClusterSpecProxyExposeType.
const (
	DBClusterSpecProxyExposeTypeExternal DBClusterSpecProxyExposeType = "external"
	DBClusterSpecProxyExposeTypeInternal DBClusterSpecProxyExposeType = "internal"
)

// Defines values for DBClusterSpecProxyType.
const (
	DBClusterSpecProxyTypeHaproxy   DBClusterSpecProxyType = "haproxy"
	DBClusterSpecProxyTypeMongos    DBClusterSpecProxyType = "mongos"
	DBClusterSpecProxyTypePgbouncer DBClusterSpecProxyType = "pgbouncer"
	DBClusterSpecProxyTypeProxysql  DBClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterSpecProxyExposeType.
const (
	External DatabaseClusterSpecProxyExposeType = "external"
	Internal DatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterSpecProxyType.
const (
	Haproxy   DatabaseClusterSpecProxyType = "haproxy"
	Mongos    DatabaseClusterSpecProxyType = "mongos"
	Pgbouncer DatabaseClusterSpecProxyType = "pgbouncer"
	Proxysql  DatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterRestoreStatusConditionsStatus.
const (
	False   DatabaseClusterRestoreStatusConditionsStatus = "False"
	True    DatabaseClusterRestoreStatusConditionsStatus = "True"
	Unknown DatabaseClusterRestoreStatusConditionsStatus = "Unknown"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	BucketName string            `json:"bucketName"`
	Id         string            `json:"id"`
	Name       string            `json:"name"`
	Region     string            `json:"region"`
	Type       BackupStorageType `json:"type"`
	Url        *string           `json:"url,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// BucketName The cloud storage bucket/container name
	BucketName string `json:"bucketName"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                        `json:"name"`
	Region    string                        `json:"region"`
	SecretKey string                        `json:"secretKey"`
	Type      CreateBackupStorageParamsType `json:"type"`
	Url       *string                       `json:"url,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// CreateDatabaseCluster DatabaseCluster is the Schema for the database clusters API.
type CreateDatabaseCluster struct {
	Name string `json:"name"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *CreateDatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *CreateDatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size CreateDatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *CreateDatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *CreateDatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *CreateDatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`
}

// CreateDatabaseClusterSpecEngineResourcesCpu0 defines model for .
type CreateDatabaseClusterSpecEngineResourcesCpu0 = int

// CreateDatabaseClusterSpecEngineResourcesCpu1 defines model for .
type CreateDatabaseClusterSpecEngineResourcesCpu1 = string

// CreateDatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type CreateDatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecEngineResourcesMemory0 defines model for .
type CreateDatabaseClusterSpecEngineResourcesMemory0 = int

// CreateDatabaseClusterSpecEngineResourcesMemory1 defines model for .
type CreateDatabaseClusterSpecEngineResourcesMemory1 = string

// CreateDatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type CreateDatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecEngineStorageSize0 defines model for .
type CreateDatabaseClusterSpecEngineStorageSize0 = int

// CreateDatabaseClusterSpecEngineStorageSize1 defines model for .
type CreateDatabaseClusterSpecEngineStorageSize1 = string

// CreateDatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type CreateDatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesLimits0 = int

// CreateDatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesLimits1 = string

// CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for CreateDatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesRequests0 = int

// CreateDatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type CreateDatabaseClusterSpecMonitoringResourcesRequests1 = string

// CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for CreateDatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type CreateDatabaseClusterSpecProxyExposeType string

// CreateDatabaseClusterSpecProxyResourcesCpu0 defines model for .
type CreateDatabaseClusterSpecProxyResourcesCpu0 = int

// CreateDatabaseClusterSpecProxyResourcesCpu1 defines model for .
type CreateDatabaseClusterSpecProxyResourcesCpu1 = string

// CreateDatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type CreateDatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyResourcesMemory0 defines model for .
type CreateDatabaseClusterSpecProxyResourcesMemory0 = int

// CreateDatabaseClusterSpecProxyResourcesMemory1 defines model for .
type CreateDatabaseClusterSpecProxyResourcesMemory1 = string

// CreateDatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type CreateDatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// CreateDatabaseClusterSpecProxyType Type is the proxy type
type CreateDatabaseClusterSpecProxyType string

// CreateKubernetesClusterParams kubernetes object
type CreateKubernetesClusterParams struct {
	Kubeconfig string  `json:"kubeconfig"`
	Name       string  `json:"name"`
	Namespace  *string `json:"namespace,omitempty"`
}

// DBCluster DatabaseCluster is the Schema for the databaseclusters API.
type DBCluster struct {
	Name string `json:"name"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DBCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DBCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DBCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DBClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DBCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DBCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DBClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status"`
}

// DBClusterSpecEngineResourcesCpu0 defines model for .
type DBClusterSpecEngineResourcesCpu0 = int

// DBClusterSpecEngineResourcesCpu1 defines model for .
type DBClusterSpecEngineResourcesCpu1 = string

// DBCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DBCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DBClusterSpecEngineResourcesMemory0 defines model for .
type DBClusterSpecEngineResourcesMemory0 = int

// DBClusterSpecEngineResourcesMemory1 defines model for .
type DBClusterSpecEngineResourcesMemory1 = string

// DBCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DBCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DBClusterSpecEngineStorageSize0 defines model for .
type DBClusterSpecEngineStorageSize0 = int

// DBClusterSpecEngineStorageSize1 defines model for .
type DBClusterSpecEngineStorageSize1 = string

// DBCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DBCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DBClusterSpecMonitoringResourcesLimits0 defines model for .
type DBClusterSpecMonitoringResourcesLimits0 = int

// DBClusterSpecMonitoringResourcesLimits1 defines model for .
type DBClusterSpecMonitoringResourcesLimits1 = string

// DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DBCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DBClusterSpecMonitoringResourcesRequests0 defines model for .
type DBClusterSpecMonitoringResourcesRequests0 = int

// DBClusterSpecMonitoringResourcesRequests1 defines model for .
type DBClusterSpecMonitoringResourcesRequests1 = string

// DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DBCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DBClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DBClusterSpecProxyExposeType string

// DBClusterSpecProxyResourcesCpu0 defines model for .
type DBClusterSpecProxyResourcesCpu0 = int

// DBClusterSpecProxyResourcesCpu1 defines model for .
type DBClusterSpecProxyResourcesCpu1 = string

// DBCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DBCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DBClusterSpecProxyResourcesMemory0 defines model for .
type DBClusterSpecProxyResourcesMemory0 = int

// DBClusterSpecProxyResourcesMemory1 defines model for .
type DBClusterSpecProxyResourcesMemory1 = string

// DBCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DBCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DBClusterSpecProxyType Type is the proxy type
type DBClusterSpecProxyType string

// DatabaseCluster DatabaseCluster is the Schema for the databaseclusters API.
type DatabaseCluster struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec *struct {
		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
				ObjectStorageName string `json:"objectStorageName"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupName BackupName is the name of the backup from backup location to use
			BackupName string `json:"backupName"`

			// ObjectStorageName ObjectStorageName is the name of the ObjectStorage CR that defines the storage location
			ObjectStorageName string `json:"objectStorageName"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type string `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring specification
		Monitoring *struct {
			// Enabled Enabled is a flag to enable monitoring
			Enabled bool `json:"enabled"`

			// Pmm PMMSpec contains PMM settings.
			Pmm *struct {
				Image         *string `json:"image,omitempty"`
				Login         *string `json:"login,omitempty"`
				Password      *string `json:"password,omitempty"`
				PublicAddress *string `json:"publicAddress,omitempty"`
				ServerHost    *string `json:"serverHost,omitempty"`
				ServerUser    *string `json:"serverUser,omitempty"`
			} `json:"pmm,omitempty"`

			// Resources ResourceRequirements describes the compute resource requirements.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterSpecEngineResourcesCpu0 = int

// DatabaseClusterSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterSpecEngineResourcesCpu1 = string

// DatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterSpecEngineResourcesMemory0 = int

// DatabaseClusterSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterSpecEngineResourcesMemory1 = string

// DatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineStorageSize0 defines model for .
type DatabaseClusterSpecEngineStorageSize0 = int

// DatabaseClusterSpecEngineStorageSize1 defines model for .
type DatabaseClusterSpecEngineStorageSize1 = string

// DatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterSpecProxyExposeType string

// DatabaseClusterSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterSpecProxyResourcesCpu0 = int

// DatabaseClusterSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterSpecProxyResourcesCpu1 = string

// DatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterSpecProxyResourcesMemory0 = int

// DatabaseClusterSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterSpecProxyResourcesMemory1 = string

// DatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyType Type is the proxy type
type DatabaseClusterSpecProxyType string

// DatabaseClusterCredential kubernetes object
type DatabaseClusterCredential struct {
	Password *string `json:"password,omitempty"`
	Username *string `json:"username,omitempty"`
}

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	Items *[]DBCluster `json:"items,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		BackupName *string `json:"backupName,omitempty"`

		// BackupSource BackupSource represents settings of a source where to get a backup to run restoration.
		BackupSource *struct {
			// Azure BackupStorageProviderSpec represents set of settings to configure cloud provider.
			Azure *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"azure,omitempty"`
			Destination *string `json:"destination,omitempty"`
			Image       *string `json:"image,omitempty"`

			// S3 BackupStorageProviderSpec represents set of settings to configure cloud provider.
			S3 *struct {
				Bucket *string `json:"bucket,omitempty"`

				// ContainerName A container name is a valid DNS name that conforms to the Azure naming rules.
				ContainerName     *string `json:"containerName,omitempty"`
				CredentialsSecret string  `json:"credentialsSecret"`
				EndpointUrl       *string `json:"endpointUrl,omitempty"`
				Prefix            *string `json:"prefix,omitempty"`
				Region            *string `json:"region,omitempty"`

				// StorageClass STANDARD, NEARLINE, COLDLINE, ARCHIVE for GCP Hot (Frequently accessed or modified data), Cool (Infrequently accessed or modified data), Archive (Rarely accessed or modified data) for Azure.
				StorageClass *string `json:"storageClass,omitempty"`
			} `json:"s3,omitempty"`
			SslInternalSecretName *string `json:"sslInternalSecretName,omitempty"`
			SslSecretName         *string `json:"sslSecretName,omitempty"`
			StorageName           *string `json:"storageName,omitempty"`

			// StorageType BackupStorageType represents backup storage type.
			StorageType     string  `json:"storage_type"`
			VaultSecretName *string `json:"vaultSecretName,omitempty"`
		} `json:"backupSource,omitempty"`
		DatabaseCluster string `json:"databaseCluster"`

		// DatabaseType EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		DatabaseType string `json:"databaseType"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed  *time.Time `json:"completed,omitempty"`
		Conditions *[]struct {
			// LastTransitionTime lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
			LastTransitionTime time.Time `json:"lastTransitionTime"`

			// Message message is a human readable message indicating details about the transition. This may be an empty string.
			Message string `json:"message"`

			// ObservedGeneration observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
			ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

			// Reason reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
			Reason string `json:"reason"`

			// Status status of the condition, one of True, False, Unknown.
			Status DatabaseClusterRestoreStatusConditionsStatus `json:"status"`

			// Type type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
			Type string `json:"type"`
		} `json:"conditions,omitempty"`
		Destination   *string    `json:"destination,omitempty"`
		Lastscheduled *time.Time `json:"lastscheduled,omitempty"`
		Message       *string    `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State       *string `json:"state,omitempty"`
		StorageName *string `json:"storageName,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreStatusConditionsStatus status of the condition, one of True, False, Unknown.
type DatabaseClusterRestoreStatusConditionsStatus string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                   `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		AllowedVersions *[]string `json:"allowedVersions,omitempty"`

		// Type EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// AvailableVersions Versions struct represents available versions of database engine components.
		AvailableVersions *struct {
			Backup *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"backup,omitempty"`
			Engine *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"engine,omitempty"`
			Proxy *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"proxy,omitempty"`
			Tools *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"tools,omitempty"`
		} `json:"availableVersions,omitempty"`
		OperatorVersion *string `json:"operatorVersion,omitempty"`

		// Status EngineState represents state of engine in a k8s cluster.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string           `json:"apiVersion,omitempty"`
	Items      *[]DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesCluster kubernetes object
type KubernetesCluster struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Namespace string `json:"namespace"`
}

// KubernetesClusterList defines model for KubernetesClusterList.
type KubernetesClusterList = []KubernetesCluster

// PMMInstance PMM instance information
type PMMInstance struct {
	ApiKeySecretId string  `json:"apiKeySecretId"`
	Id             *string `json:"id,omitempty"`
	Url            string  `json:"url"`
}

// PMMInstanceCreateParams PMM instance create information
type PMMInstanceCreateParams struct {
	ApiKey string `json:"apiKey"`
	Url    string `json:"url"`
}

// PMMInstanceUpdateParams PMM instance update information
type PMMInstanceUpdateParams struct {
	ApiKey *string `json:"apiKey,omitempty"`
	Url    *string `json:"url,omitempty"`
}

// PMMInstancesList defines model for PMMInstancesList.
type PMMInstancesList = []PMMInstance

// UnregisterKubernetesClusterParams Options for removing a kubernetes cluster
type UnregisterKubernetesClusterParams struct {
	// Force Remove the kubernetes cluster even if there are database clusters running.
	Force *bool `json:"force,omitempty"`
}

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName *string `json:"bucketName,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      *string `json:"name,omitempty"`
	Region    *string `json:"region,omitempty"`
	SecretKey *string `json:"secretKey,omitempty"`
	Url       *string `json:"url,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// RegisterKubernetesClusterJSONRequestBody defines body for RegisterKubernetesCluster for application/json ContentType.
type RegisterKubernetesClusterJSONRequestBody = CreateKubernetesClusterParams

// UnregisterKubernetesClusterJSONRequestBody defines body for UnregisterKubernetesCluster for application/json ContentType.
type UnregisterKubernetesClusterJSONRequestBody = UnregisterKubernetesClusterParams

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = CreateDatabaseCluster

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// UpdateDatabaseEngineJSONRequestBody defines body for UpdateDatabaseEngine for application/json ContentType.
type UpdateDatabaseEngineJSONRequestBody = DatabaseEngine

// CreatePMMInstanceJSONRequestBody defines body for CreatePMMInstance for application/json ContentType.
type CreatePMMInstanceJSONRequestBody = PMMInstanceCreateParams

// UpdatePMMInstanceJSONRequestBody defines body for UpdatePMMInstance for application/json ContentType.
type UpdatePMMInstanceJSONRequestBody = PMMInstanceUpdateParams

// AsCreateDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as a CreateDatabaseClusterSpecEngineResourcesCpu0
func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) AsCreateDatabaseClusterSpecEngineResourcesCpu0() (CreateDatabaseClusterSpecEngineResourcesCpu0, error) {
	var body CreateDatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as the provided CreateDatabaseClusterSpecEngineResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) FromCreateDatabaseClusterSpecEngineResourcesCpu0(v CreateDatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu, using the provided CreateDatabaseClusterSpecEngineResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MergeCreateDatabaseClusterSpecEngineResourcesCpu0(v CreateDatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as a CreateDatabaseClusterSpecEngineResourcesCpu1
func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) AsCreateDatabaseClusterSpecEngineResourcesCpu1() (CreateDatabaseClusterSpecEngineResourcesCpu1, error) {
	var body CreateDatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu as the provided CreateDatabaseClusterSpecEngineResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) FromCreateDatabaseClusterSpecEngineResourcesCpu1(v CreateDatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Cpu, using the provided CreateDatabaseClusterSpecEngineResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MergeCreateDatabaseClusterSpecEngineResourcesCpu1(v CreateDatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as a CreateDatabaseClusterSpecEngineResourcesMemory0
func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) AsCreateDatabaseClusterSpecEngineResourcesMemory0() (CreateDatabaseClusterSpecEngineResourcesMemory0, error) {
	var body CreateDatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as the provided CreateDatabaseClusterSpecEngineResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) FromCreateDatabaseClusterSpecEngineResourcesMemory0(v CreateDatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory, using the provided CreateDatabaseClusterSpecEngineResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) MergeCreateDatabaseClusterSpecEngineResourcesMemory0(v CreateDatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as a CreateDatabaseClusterSpecEngineResourcesMemory1
func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) AsCreateDatabaseClusterSpecEngineResourcesMemory1() (CreateDatabaseClusterSpecEngineResourcesMemory1, error) {
	var body CreateDatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory as the provided CreateDatabaseClusterSpecEngineResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) FromCreateDatabaseClusterSpecEngineResourcesMemory1(v CreateDatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Resources_Memory, using the provided CreateDatabaseClusterSpecEngineResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) MergeCreateDatabaseClusterSpecEngineResourcesMemory1(v CreateDatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecEngineStorageSize0 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as a CreateDatabaseClusterSpecEngineStorageSize0
func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) AsCreateDatabaseClusterSpecEngineStorageSize0() (CreateDatabaseClusterSpecEngineStorageSize0, error) {
	var body CreateDatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as the provided CreateDatabaseClusterSpecEngineStorageSize0
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) FromCreateDatabaseClusterSpecEngineStorageSize0(v CreateDatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size, using the provided CreateDatabaseClusterSpecEngineStorageSize0
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) MergeCreateDatabaseClusterSpecEngineStorageSize0(v CreateDatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecEngineStorageSize1 returns the union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as a CreateDatabaseClusterSpecEngineStorageSize1
func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) AsCreateDatabaseClusterSpecEngineStorageSize1() (CreateDatabaseClusterSpecEngineStorageSize1, error) {
	var body CreateDatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size as the provided CreateDatabaseClusterSpecEngineStorageSize1
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) FromCreateDatabaseClusterSpecEngineStorageSize1(v CreateDatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Engine_Storage_Size, using the provided CreateDatabaseClusterSpecEngineStorageSize1
func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) MergeCreateDatabaseClusterSpecEngineStorageSize1(v CreateDatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesLimits0() (CreateDatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesLimits0(v CreateDatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesLimits0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesLimits0(v CreateDatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesLimits1() (CreateDatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesLimits1(v CreateDatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesLimits1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesLimits1(v CreateDatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesRequests0() (CreateDatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesRequests0(v CreateDatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesRequests0
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesRequests0(v CreateDatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsCreateDatabaseClusterSpecMonitoringResourcesRequests1() (CreateDatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body CreateDatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromCreateDatabaseClusterSpecMonitoringResourcesRequests1(v CreateDatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided CreateDatabaseClusterSpecMonitoringResourcesRequests1
func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeCreateDatabaseClusterSpecMonitoringResourcesRequests1(v CreateDatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as a CreateDatabaseClusterSpecProxyResourcesCpu0
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) AsCreateDatabaseClusterSpecProxyResourcesCpu0() (CreateDatabaseClusterSpecProxyResourcesCpu0, error) {
	var body CreateDatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as the provided CreateDatabaseClusterSpecProxyResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) FromCreateDatabaseClusterSpecProxyResourcesCpu0(v CreateDatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided CreateDatabaseClusterSpecProxyResourcesCpu0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MergeCreateDatabaseClusterSpecProxyResourcesCpu0(v CreateDatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as a CreateDatabaseClusterSpecProxyResourcesCpu1
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) AsCreateDatabaseClusterSpecProxyResourcesCpu1() (CreateDatabaseClusterSpecProxyResourcesCpu1, error) {
	var body CreateDatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu as the provided CreateDatabaseClusterSpecProxyResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) FromCreateDatabaseClusterSpecProxyResourcesCpu1(v CreateDatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided CreateDatabaseClusterSpecProxyResourcesCpu1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MergeCreateDatabaseClusterSpecProxyResourcesCpu1(v CreateDatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as a CreateDatabaseClusterSpecProxyResourcesMemory0
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) AsCreateDatabaseClusterSpecProxyResourcesMemory0() (CreateDatabaseClusterSpecProxyResourcesMemory0, error) {
	var body CreateDatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as the provided CreateDatabaseClusterSpecProxyResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) FromCreateDatabaseClusterSpecProxyResourcesMemory0(v CreateDatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory, using the provided CreateDatabaseClusterSpecProxyResourcesMemory0
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MergeCreateDatabaseClusterSpecProxyResourcesMemory0(v CreateDatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsCreateDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as a CreateDatabaseClusterSpecProxyResourcesMemory1
func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) AsCreateDatabaseClusterSpecProxyResourcesMemory1() (CreateDatabaseClusterSpecProxyResourcesMemory1, error) {
	var body CreateDatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCreateDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory as the provided CreateDatabaseClusterSpecProxyResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) FromCreateDatabaseClusterSpecProxyResourcesMemory1(v CreateDatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCreateDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the CreateDatabaseCluster_Spec_Proxy_Resources_Memory, using the provided CreateDatabaseClusterSpecProxyResourcesMemory1
func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MergeCreateDatabaseClusterSpecProxyResourcesMemory1(v CreateDatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t CreateDatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *CreateDatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineResourcesCpu0 returns the union data inside the DBCluster_Spec_Engine_Resources_Cpu as a DBClusterSpecEngineResourcesCpu0
func (t DBCluster_Spec_Engine_Resources_Cpu) AsDBClusterSpecEngineResourcesCpu0() (DBClusterSpecEngineResourcesCpu0, error) {
	var body DBClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesCpu0 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Cpu as the provided DBClusterSpecEngineResourcesCpu0
func (t *DBCluster_Spec_Engine_Resources_Cpu) FromDBClusterSpecEngineResourcesCpu0(v DBClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Cpu, using the provided DBClusterSpecEngineResourcesCpu0
func (t *DBCluster_Spec_Engine_Resources_Cpu) MergeDBClusterSpecEngineResourcesCpu0(v DBClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineResourcesCpu1 returns the union data inside the DBCluster_Spec_Engine_Resources_Cpu as a DBClusterSpecEngineResourcesCpu1
func (t DBCluster_Spec_Engine_Resources_Cpu) AsDBClusterSpecEngineResourcesCpu1() (DBClusterSpecEngineResourcesCpu1, error) {
	var body DBClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesCpu1 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Cpu as the provided DBClusterSpecEngineResourcesCpu1
func (t *DBCluster_Spec_Engine_Resources_Cpu) FromDBClusterSpecEngineResourcesCpu1(v DBClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Cpu, using the provided DBClusterSpecEngineResourcesCpu1
func (t *DBCluster_Spec_Engine_Resources_Cpu) MergeDBClusterSpecEngineResourcesCpu1(v DBClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineResourcesMemory0 returns the union data inside the DBCluster_Spec_Engine_Resources_Memory as a DBClusterSpecEngineResourcesMemory0
func (t DBCluster_Spec_Engine_Resources_Memory) AsDBClusterSpecEngineResourcesMemory0() (DBClusterSpecEngineResourcesMemory0, error) {
	var body DBClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesMemory0 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Memory as the provided DBClusterSpecEngineResourcesMemory0
func (t *DBCluster_Spec_Engine_Resources_Memory) FromDBClusterSpecEngineResourcesMemory0(v DBClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Memory, using the provided DBClusterSpecEngineResourcesMemory0
func (t *DBCluster_Spec_Engine_Resources_Memory) MergeDBClusterSpecEngineResourcesMemory0(v DBClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineResourcesMemory1 returns the union data inside the DBCluster_Spec_Engine_Resources_Memory as a DBClusterSpecEngineResourcesMemory1
func (t DBCluster_Spec_Engine_Resources_Memory) AsDBClusterSpecEngineResourcesMemory1() (DBClusterSpecEngineResourcesMemory1, error) {
	var body DBClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineResourcesMemory1 overwrites any union data inside the DBCluster_Spec_Engine_Resources_Memory as the provided DBClusterSpecEngineResourcesMemory1
func (t *DBCluster_Spec_Engine_Resources_Memory) FromDBClusterSpecEngineResourcesMemory1(v DBClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DBCluster_Spec_Engine_Resources_Memory, using the provided DBClusterSpecEngineResourcesMemory1
func (t *DBCluster_Spec_Engine_Resources_Memory) MergeDBClusterSpecEngineResourcesMemory1(v DBClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecEngineStorageSize0 returns the union data inside the DBCluster_Spec_Engine_Storage_Size as a DBClusterSpecEngineStorageSize0
func (t DBCluster_Spec_Engine_Storage_Size) AsDBClusterSpecEngineStorageSize0() (DBClusterSpecEngineStorageSize0, error) {
	var body DBClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineStorageSize0 overwrites any union data inside the DBCluster_Spec_Engine_Storage_Size as the provided DBClusterSpecEngineStorageSize0
func (t *DBCluster_Spec_Engine_Storage_Size) FromDBClusterSpecEngineStorageSize0(v DBClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineStorageSize0 performs a merge with any union data inside the DBCluster_Spec_Engine_Storage_Size, using the provided DBClusterSpecEngineStorageSize0
func (t *DBCluster_Spec_Engine_Storage_Size) MergeDBClusterSpecEngineStorageSize0(v DBClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecEngineStorageSize1 returns the union data inside the DBCluster_Spec_Engine_Storage_Size as a DBClusterSpecEngineStorageSize1
func (t DBCluster_Spec_Engine_Storage_Size) AsDBClusterSpecEngineStorageSize1() (DBClusterSpecEngineStorageSize1, error) {
	var body DBClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecEngineStorageSize1 overwrites any union data inside the DBCluster_Spec_Engine_Storage_Size as the provided DBClusterSpecEngineStorageSize1
func (t *DBCluster_Spec_Engine_Storage_Size) FromDBClusterSpecEngineStorageSize1(v DBClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecEngineStorageSize1 performs a merge with any union data inside the DBCluster_Spec_Engine_Storage_Size, using the provided DBClusterSpecEngineStorageSize1
func (t *DBCluster_Spec_Engine_Storage_Size) MergeDBClusterSpecEngineStorageSize1(v DBClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecMonitoringResourcesLimits0 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DBClusterSpecMonitoringResourcesLimits0
func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDBClusterSpecMonitoringResourcesLimits0() (DBClusterSpecMonitoringResourcesLimits0, error) {
	var body DBClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesLimits0
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDBClusterSpecMonitoringResourcesLimits0(v DBClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesLimits0
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesLimits0(v DBClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecMonitoringResourcesLimits1 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DBClusterSpecMonitoringResourcesLimits1
func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDBClusterSpecMonitoringResourcesLimits1() (DBClusterSpecMonitoringResourcesLimits1, error) {
	var body DBClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesLimits1
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDBClusterSpecMonitoringResourcesLimits1(v DBClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesLimits1
func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesLimits1(v DBClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecMonitoringResourcesRequests0 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DBClusterSpecMonitoringResourcesRequests0
func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDBClusterSpecMonitoringResourcesRequests0() (DBClusterSpecMonitoringResourcesRequests0, error) {
	var body DBClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesRequests0
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDBClusterSpecMonitoringResourcesRequests0(v DBClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesRequests0
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesRequests0(v DBClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecMonitoringResourcesRequests1 returns the union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DBClusterSpecMonitoringResourcesRequests1
func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDBClusterSpecMonitoringResourcesRequests1() (DBClusterSpecMonitoringResourcesRequests1, error) {
	var body DBClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DBClusterSpecMonitoringResourcesRequests1
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDBClusterSpecMonitoringResourcesRequests1(v DBClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DBClusterSpecMonitoringResourcesRequests1
func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDBClusterSpecMonitoringResourcesRequests1(v DBClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecProxyResourcesCpu0 returns the union data inside the DBCluster_Spec_Proxy_Resources_Cpu as a DBClusterSpecProxyResourcesCpu0
func (t DBCluster_Spec_Proxy_Resources_Cpu) AsDBClusterSpecProxyResourcesCpu0() (DBClusterSpecProxyResourcesCpu0, error) {
	var body DBClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesCpu0 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Cpu as the provided DBClusterSpecProxyResourcesCpu0
func (t *DBCluster_Spec_Proxy_Resources_Cpu) FromDBClusterSpecProxyResourcesCpu0(v DBClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Cpu, using the provided DBClusterSpecProxyResourcesCpu0
func (t *DBCluster_Spec_Proxy_Resources_Cpu) MergeDBClusterSpecProxyResourcesCpu0(v DBClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecProxyResourcesCpu1 returns the union data inside the DBCluster_Spec_Proxy_Resources_Cpu as a DBClusterSpecProxyResourcesCpu1
func (t DBCluster_Spec_Proxy_Resources_Cpu) AsDBClusterSpecProxyResourcesCpu1() (DBClusterSpecProxyResourcesCpu1, error) {
	var body DBClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesCpu1 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Cpu as the provided DBClusterSpecProxyResourcesCpu1
func (t *DBCluster_Spec_Proxy_Resources_Cpu) FromDBClusterSpecProxyResourcesCpu1(v DBClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Cpu, using the provided DBClusterSpecProxyResourcesCpu1
func (t *DBCluster_Spec_Proxy_Resources_Cpu) MergeDBClusterSpecProxyResourcesCpu1(v DBClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDBClusterSpecProxyResourcesMemory0 returns the union data inside the DBCluster_Spec_Proxy_Resources_Memory as a DBClusterSpecProxyResourcesMemory0
func (t DBCluster_Spec_Proxy_Resources_Memory) AsDBClusterSpecProxyResourcesMemory0() (DBClusterSpecProxyResourcesMemory0, error) {
	var body DBClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesMemory0 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Memory as the provided DBClusterSpecProxyResourcesMemory0
func (t *DBCluster_Spec_Proxy_Resources_Memory) FromDBClusterSpecProxyResourcesMemory0(v DBClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Memory, using the provided DBClusterSpecProxyResourcesMemory0
func (t *DBCluster_Spec_Proxy_Resources_Memory) MergeDBClusterSpecProxyResourcesMemory0(v DBClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDBClusterSpecProxyResourcesMemory1 returns the union data inside the DBCluster_Spec_Proxy_Resources_Memory as a DBClusterSpecProxyResourcesMemory1
func (t DBCluster_Spec_Proxy_Resources_Memory) AsDBClusterSpecProxyResourcesMemory1() (DBClusterSpecProxyResourcesMemory1, error) {
	var body DBClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDBClusterSpecProxyResourcesMemory1 overwrites any union data inside the DBCluster_Spec_Proxy_Resources_Memory as the provided DBClusterSpecProxyResourcesMemory1
func (t *DBCluster_Spec_Proxy_Resources_Memory) FromDBClusterSpecProxyResourcesMemory1(v DBClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDBClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DBCluster_Spec_Proxy_Resources_Memory, using the provided DBClusterSpecProxyResourcesMemory1
func (t *DBCluster_Spec_Proxy_Resources_Memory) MergeDBClusterSpecProxyResourcesMemory1(v DBClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DBCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DBCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu0
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu0() (DatabaseClusterSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu1
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu1() (DatabaseClusterSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory0
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory0() (DatabaseClusterSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory1
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory1() (DatabaseClusterSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineStorageSize0 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize0
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize0() (DatabaseClusterSpecEngineStorageSize0, error) {
	var body DatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineStorageSize1 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize1
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize1() (DatabaseClusterSpecEngineStorageSize1, error) {
	var body DatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu0
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu0() (DatabaseClusterSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu1
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu1() (DatabaseClusterSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory0
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory0() (DatabaseClusterSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory1
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory1() (DatabaseClusterSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// ServerInterface represents all server handlers.
type ServerInterface interface {
	// List of the created backup storages
	// (GET /backup-storages)
	ListBackupStorages(ctx echo.Context) error
	// Create a new backup storage object
	// (POST /backup-storages)
	CreateBackupStorage(ctx echo.Context) error
	// Delete the specified backup storage
	// (DELETE /backup-storages/{backup-storage-id})
	DeleteBackupStorage(ctx echo.Context, backupStorageId string) error
	// Get the specified backup storage
	// (GET /backup-storages/{backup-storage-id})
	GetBackupStorage(ctx echo.Context, backupStorageId string) error
	// Partial update of the specified backup storage
	// (PATCH /backup-storages/{backup-storage-id})
	UpdateBackupStorage(ctx echo.Context, backupStorageId string) error
	// List of the registered kubernetes clusters
	// (GET /kubernetes)
	ListKubernetesClusters(ctx echo.Context) error
	// Register kubernetes cluster in Everest
	// (POST /kubernetes)
	RegisterKubernetesCluster(ctx echo.Context) error
	// Remove the specified kubernetes cluster from Everest
	// (DELETE /kubernetes/{kubernetes-id})
	UnregisterKubernetesCluster(ctx echo.Context, kubernetesId string) error
	// Get the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id})
	GetKubernetesCluster(ctx echo.Context, kubernetesId string) error
	// List of the created database cluster restores on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-cluster-restores)
	ListDatabaseClusterRestores(ctx echo.Context, kubernetesId string) error
	// Create a database cluster restore on the specified kubernetes cluster
	// (POST /kubernetes/{kubernetes-id}/database-cluster-restores)
	CreateDatabaseClusterRestore(ctx echo.Context, kubernetesId string) error
	// Delete the specified cluster restore on the specified kubernetes cluster
	// (DELETE /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	DeleteDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// Returns the specified cluster restore on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	GetDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// Replace the specified cluster restore on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-cluster-restores/{name})
	UpdateDatabaseClusterRestore(ctx echo.Context, kubernetesId string, name string) error
	// List of the created database clusters on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters)
	ListDatabaseClusters(ctx echo.Context, kubernetesId string) error
	// Create a database cluster on the specified kubernetes cluster
	// (POST /kubernetes/{kubernetes-id}/database-clusters)
	CreateDatabaseCluster(ctx echo.Context, kubernetesId string) error
	// Delete the specified database cluster on the specified kubernetes cluster
	// (DELETE /kubernetes/{kubernetes-id}/database-clusters/{name})
	DeleteDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Get the specified database cluster on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters/{name})
	GetDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Replace the specified database cluster on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-clusters/{name})
	UpdateDatabaseCluster(ctx echo.Context, kubernetesId string, name string) error
	// Get the specified database cluster credentials on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-clusters/{name}/credentials)
	GetDatabaseClusterCredentials(ctx echo.Context, kubernetesId string, name string) error
	// List of the available database engines on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-engines)
	ListDatabaseEngines(ctx echo.Context, kubernetesId string) error
	// Get the specified database engine on the specified kubernetes cluster
	// (GET /kubernetes/{kubernetes-id}/database-engines/{name})
	GetDatabaseEngine(ctx echo.Context, kubernetesId string, name string) error
	// Update the specified database engine on the specified kubernetes cluster
	// (PUT /kubernetes/{kubernetes-id}/database-engines/{name})
	UpdateDatabaseEngine(ctx echo.Context, kubernetesId string, name string) error
	// List of the created PMM instances
	// (GET /pmm-instances)
	ListPMMInstances(ctx echo.Context) error
	// Create a new PMM instance object
	// (POST /pmm-instances)
	CreatePMMInstance(ctx echo.Context) error
	// Delete the specified PMM instance
	// (DELETE /pmm-instances/{pmm-instance-id})
	DeletePMMInstance(ctx echo.Context, pmmInstanceId string) error
	// Get the specified PMM instance
	// (GET /pmm-instances/{pmm-instance-id})
	GetPMMInstance(ctx echo.Context, pmmInstanceId string) error
	// Update the specified PMM instance
	// (PATCH /pmm-instances/{pmm-instance-id})
	UpdatePMMInstance(ctx echo.Context, pmmInstanceId string) error
}

// ServerInterfaceWrapper converts echo contexts to parameters.
type ServerInterfaceWrapper struct {
	Handler ServerInterface
}

// ListBackupStorages converts echo context to params.
func (w *ServerInterfaceWrapper) ListBackupStorages(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListBackupStorages(ctx)
	return err
}

// CreateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) CreateBackupStorage(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateBackupStorage(ctx)
	return err
}

// DeleteBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteBackupStorage(ctx, backupStorageId)
	return err
}

// GetBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) GetBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetBackupStorage(ctx, backupStorageId)
	return err
}

// UpdateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "backup-storage-id" -------------
	var backupStorageId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "backup-storage-id", runtime.ParamLocationPath, ctx.Param("backup-storage-id"), &backupStorageId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter backup-storage-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateBackupStorage(ctx, backupStorageId)
	return err
}

// ListKubernetesClusters converts echo context to params.
func (w *ServerInterfaceWrapper) ListKubernetesClusters(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListKubernetesClusters(ctx)
	return err
}

// RegisterKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) RegisterKubernetesCluster(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.RegisterKubernetesCluster(ctx)
	return err
}

// UnregisterKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) UnregisterKubernetesCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UnregisterKubernetesCluster(ctx, kubernetesId)
	return err
}

// GetKubernetesCluster converts echo context to params.
func (w *ServerInterfaceWrapper) GetKubernetesCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetKubernetesCluster(ctx, kubernetesId)
	return err
}

// ListDatabaseClusterRestores converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusterRestores(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseClusterRestores(ctx, kubernetesId)
	return err
}

// CreateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateDatabaseClusterRestore(ctx, kubernetesId)
	return err
}

// DeleteDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// GetDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseClusterRestore(ctx, kubernetesId, name)
	return err
}

// ListDatabaseClusters converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusters(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseClusters(ctx, kubernetesId)
	return err
}

// CreateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreateDatabaseCluster(ctx, kubernetesId)
	return err
}

// DeleteDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeleteDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// GetDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseCluster(ctx, kubernetesId, name)
	return err
}

// GetDatabaseClusterCredentials converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterCredentials(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseClusterCredentials(ctx, kubernetesId, name)
	return err
}

// ListDatabaseEngines converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseEngines(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListDatabaseEngines(ctx, kubernetesId)
	return err
}

// GetDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetDatabaseEngine(ctx, kubernetesId, name)
	return err
}

// UpdateDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "kubernetes-id" -------------
	var kubernetesId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "kubernetes-id", runtime.ParamLocationPath, ctx.Param("kubernetes-id"), &kubernetesId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter kubernetes-id: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdateDatabaseEngine(ctx, kubernetesId, name)
	return err
}

// ListPMMInstances converts echo context to params.
func (w *ServerInterfaceWrapper) ListPMMInstances(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.ListPMMInstances(ctx)
	return err
}

// CreatePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) CreatePMMInstance(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.CreatePMMInstance(ctx)
	return err
}

// DeletePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) DeletePMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.DeletePMMInstance(ctx, pmmInstanceId)
	return err
}

// GetPMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) GetPMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.GetPMMInstance(ctx, pmmInstanceId)
	return err
}

// UpdatePMMInstance converts echo context to params.
func (w *ServerInterfaceWrapper) UpdatePMMInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "pmm-instance-id" -------------
	var pmmInstanceId string

	err = runtime.BindStyledParameterWithLocation("simple", false, "pmm-instance-id", runtime.ParamLocationPath, ctx.Param("pmm-instance-id"), &pmmInstanceId)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter pmm-instance-id: %s", err))
	}

	// Invoke the callback with all the unmarshalled arguments
	err = w.Handler.UpdatePMMInstance(ctx, pmmInstanceId)
	return err
}

// This is a simple interface which specifies echo.Route addition functions which
// are present on both echo.Echo and echo.Group, since we want to allow using
// either of them for path registration
type EchoRouter interface {
	CONNECT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	DELETE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	GET(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	HEAD(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	OPTIONS(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PATCH(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	POST(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PUT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	TRACE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
}

// RegisterHandlers adds each server route to the EchoRouter.
func RegisterHandlers(router EchoRouter, si ServerInterface) {
	RegisterHandlersWithBaseURL(router, si, "")
}

// Registers handlers, and prepends BaseURL to the paths, so that the paths
// can be served under a prefix.
func RegisterHandlersWithBaseURL(router EchoRouter, si ServerInterface, baseURL string) {
	wrapper := ServerInterfaceWrapper{
		Handler: si,
	}

	router.GET(baseURL+"/backup-storages", wrapper.ListBackupStorages)
	router.POST(baseURL+"/backup-storages", wrapper.CreateBackupStorage)
	router.DELETE(baseURL+"/backup-storages/:backup-storage-id", wrapper.DeleteBackupStorage)
	router.GET(baseURL+"/backup-storages/:backup-storage-id", wrapper.GetBackupStorage)
	router.PATCH(baseURL+"/backup-storages/:backup-storage-id", wrapper.UpdateBackupStorage)
	router.GET(baseURL+"/kubernetes", wrapper.ListKubernetesClusters)
	router.POST(baseURL+"/kubernetes", wrapper.RegisterKubernetesCluster)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id", wrapper.UnregisterKubernetesCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id", wrapper.GetKubernetesCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores", wrapper.ListDatabaseClusterRestores)
	router.POST(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores", wrapper.CreateDatabaseClusterRestore)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.DeleteDatabaseClusterRestore)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.GetDatabaseClusterRestore)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-cluster-restores/:name", wrapper.UpdateDatabaseClusterRestore)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters", wrapper.ListDatabaseClusters)
	router.POST(baseURL+"/kubernetes/:kubernetes-id/database-clusters", wrapper.CreateDatabaseCluster)
	router.DELETE(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.DeleteDatabaseCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.GetDatabaseCluster)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name", wrapper.UpdateDatabaseCluster)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-clusters/:name/credentials", wrapper.GetDatabaseClusterCredentials)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-engines", wrapper.ListDatabaseEngines)
	router.GET(baseURL+"/kubernetes/:kubernetes-id/database-engines/:name", wrapper.GetDatabaseEngine)
	router.PUT(baseURL+"/kubernetes/:kubernetes-id/database-engines/:name", wrapper.UpdateDatabaseEngine)
	router.GET(baseURL+"/pmm-instances", wrapper.ListPMMInstances)
	router.POST(baseURL+"/pmm-instances", wrapper.CreatePMMInstance)
	router.DELETE(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.DeletePMMInstance)
	router.GET(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.GetPMMInstance)
	router.PATCH(baseURL+"/pmm-instances/:pmm-instance-id", wrapper.UpdatePMMInstance)
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{
	"H4sIAAAAAAAC/+x9e3PjNvLgV0ExWxU7K1Ezk/3tZV21lXI8TuJLnLjsma26G/t2IbIlYU0CDADKVmbn",
	"u1+hAfAlUJZsOZnZ8D+JBPFo9LsbjfdRIvJCcOBaRUfvI5UsIKf48xua3JbFlRaSzsE8SEElkhWaCR4d",
	"uddE2feE8ZmQOcWXo6iQogCpGWBP0zK5Bf0TzbEbvSogOoqUlozPow+jiKXBx7yvvYQ5TiHwyj54HwEv",
	"8+joXaS+jEYR/bWUEI2ieaKim9H6R6XMAp3hQL+UTEJqemJp5KY0aq6nmo3rt+5fTP8NiTb9twCpfmRK",
	"m+GYhhyh8ycJs+go+mxS78TEbcOkvQfVAiMqJV2Z/ycSqIZWswsqqe1544YVphlokGptv2iSgFI/wCoI",
	"4/Zutsd4swCSZKJMq2Fs60kiuKaMgyQOhr3b3e7wmJQKJElhxjiYXk1z7IOIGdELaCAg/n3905V9bdGR",
	"LLQu1NFkcltOQXLQoGImJqlIlJlTAoVWE7EEuWRwN7kT8pbx+fiO6cXYbqCamN7U5LOUq3FGp5CN8UE0",
	"iuCe5kWG23GnxiksQ8vagKwKEgm6D8zPh8ohLK63vDmvbbDbYuBrqumUKjjJSqVBrm9kpwFhCrfrChHd",
	"bBb+TV0rkthmihxfnMVrCNrLGlQByYNjXxWQOIyyk0hBGdgQpalGvOp8sD6BKdJSL425xU0dxRWQsBlL",
	"wswROJ1mkK73dWpfmM4omWV0TrQgtrXrWdUINxUiA8oRBskC0jKDAAu48q9spxlT2izXz7P6cFRzp9D6",
	"fDfddfrHieAzNi8lLjjez4qR1N0AwWWH+YdBbz/NFtdY66pGIovbjpuG+dzP3SahMVqNyMkl0QuqW4jn",
	"eVcmKuQIMBAN3Lw8EQULbeplu0E1kzKfgmxsb2Jfa0EkGF4cjSLLI6OjiHH95at6dMY1zEE2sakfmfyA",
	"iRR8A1w7TMgjQSVU16HeGDzEeNqisKf70IeGyVyJUiYQZhX2XbVRFLkSUfap4VRTIbTSkhZGFlHC4c7z",
	"qx5GEUaib6p3IexxuzaTIve/PZqYPSzVR4+7nS1pgCI0z9BOAZ8zDiFGYZ77eVdCwzZ/gN9a5rTe5wk+",
	"9326rlqcLEydRcYSGiRL+2adHl3f1adb0aEEi4DBkdwrQqVllL4xyVjOtEKkBZosOkPH5GxGuNBEgR6t",
	"fWQ6My9ZXgiFlNoBZFGisshXP8+io3fv1ye9JqBvRl2gX7z18DE/qyk4vMnRLBlFBdUapPng/x1cX//5",
	"P+PDrw8O3r0Y/+3mzwfX1zH++uLw68P/VP/+fHh4cPDuh/Pv3lyc3rDD/7zjZX5r//3n4B2c3mzfz+Hh",
	"13+KRtH9uFYhx4zrsZBjt64jLUv4MIpyyIVcPRko59iNh4vt9NMGzYcAbas+w9IznTYlenbTpcgOTmZU",
	"BSjkxDz2HVY94UPLSisFtACpmDIClSxFVubYjOUh0lfsV3jyXl+xX6uVmg49/+2fx6ey4U3Wj6Dql+Fr",
	"VuSq6G4/NgwZPArkFdorKizt3rYbBHVBfE2ciWpkunmKdqd9pUIjL80OWcuuPeI/7IvOAnzzh6SkJ4sN",
	"FlcuONPCQrs7+Hn1ruIf9ZNnMEQacwkp5UWer/d3cX6OJpgDuCIX5+dGBGnG52rdXGC5YxNrW5CJOQub",
	"1gVV6k7IsGOpKKcZS47TVIJlFgHLXC5Bfi+sp6bntcGssLG9tmNbCO/LBlsntsnUaVqJyItSQ1gExCEe",
	"yPIwE2S5QqOvpgFliKCa3qhytDCO2BL7V/bjkVUDjWZQKkjJdEX0gilSeXdics3JG/PIIAsnNCsWlMwY",
	"ZCmhPPUzVxZ9PKm9XnGas8SD4jirFN0ZUF1KIHOqoe7b9mcGyfNSGzyMyZkmCeVE8GxFpoamNfL0amYI",
	"qB6r9rK5SCJhBhK40acEN/SrjTDm5EKkBm3jVmvV75wIGKJ5qTTJqU4WLSbUGqYQaRwAvWdWFyIldwtA",
	"Ra8JCrMfCIWc3iLeUF0jDF1SliG9Mq5YCoQ2tuxBlsT71POWBdaRCgbNxjktxrewUs1e1lu5bnJaIFGj",
	"9omCNU2ZgR7NLtruyd0E7ieiPLbR5Uerg7cZQU7vWV7mhOai5Oi56bIGRWiWiTuDCudCWq/80VY+0JZe",
	"Nckpp3MYV92OazqaREEG90sJati2SweH7sYx/uDGeYpDo6zqhykicqY1pMjOGnQ7IgwNclpmGtVYhzJs",
	"ZomfKQL3xsxjOlt50Q/piAi9AHnHFJiPKDf2XYayBLd+7CXAkmYlxPVMEsqNNQj3CUDqBvtNsexD6Mm2",
	"Pp+CGgYZ0EXweVu1UVoUVvBWTp2AZiPF/SrQn3nsVS9s09a62ia3kZCFkR6SUR1sT+5YlhmBRosiYw4L",
	"TN9ztgTulMuYHBuEygVHWyahzqBxOlVHUmiBSCRFZvXTe0NmNCM2BGBehzzx8SMdKXZND/pR4L4QKuTp",
	"weftzmzbByxBVlg33iXl85DedXbRfO8H8B7xswvv75P2/cHJ2etLs3E42iGSjuG0HmozKfL23moU0kwR",
	"LqxHBb9s+dZ7Yj51dK82j5DMHc80uxWNNtlMFkDm6xFqRVNDo26bhay2PBpV0aVGv9Xbm9F2uu3uHjC7",
	"j7+HA6w18uD/Gvxfv5v/62HXh8VV5/nwhJoLPhdm4QtqRZATReoXQ7vFfCpKnoDcinjX5Cd6228eaucC",
	"Nhhr7Y8I/1CBxEVR+/ISatgR10eX0kyLWtr0Zg7U8Xijb5mP+vIMVEGTDmMtQCaC0zEsQYLS2xlFo+bU",
	"QqB4/c2eAuJDPHyIhw/x8CEePsTDh3j4EA8f4uGDPTDEw4d4+BAPH+LhQzx8iIcP8fAhHj7Ew4d4+BAP",
	"H+LhQzx8iIcP8fAhHj7Ew4d4+OD/GuLhzxAPH0VKU12qhyOr2KwVJhBTtJZ3Ca4uhNJhI+p798ZDyLes",
	"LKJKXHm2Jw3VI/GuMdsclAo6IM/tC6tBaUmbtR4InYpSh7WDhodBSB3QDYTU1d6a31vMeivGSNNViCnS",
	"dLXOerG1MTK3ZLvey9nvttRC06zJ3LfvuwerHBpV/lr85+zfXqh/2CWNoxo7mMSw37P9m1MZaMH+0edJ",
	"PL44887EJkk5V6KhKTsigoYZE6KQoLwmbx5T7nJMYnKFTitF1EKUWWq0pyVITSQkYs7Zr1VvlQaYUQ1K",
	"14oDGgQjdOPk1DBk0y8peaMHbBK2CuZMx7dfoUlgVNWSM73CKhmSTUstpJqksIRsoth8TGWyYBoSXUqY",
	"0IKNcbIY41Zxnn5WqwIB2rtlPKDn/8C40/JdSQ2cag0x74q6PL16U8sahKoFYN1U1bA0cGB8BtKp2FLk",
	"zuebFoJxzycYcE1UOUW1wpvKRIuYnFijagqkLFKq0frj5ITmkJ1QBc8OSQM9NTYgU2EWqalB44ay2pAJ",
	"Q67NkGsz5NoMuTZDrs2QazPk2gy5NoOvYci1GXJthlybIddmyLUZcm2GXJsh12bItRlybYZcmyHXZsi1",
	"GXJthlybIddmyLUZ/F+D/2vItRlybYZcm/+6XJuH8mhOJKTANaPZY2qiNL1MdeETKYTuc1Wul0kJt95i",
	"6v4Om40EaRo5V4xLGUHboPK8NXUeqzkwhSrj2iUgAb+cV2O2ukWnrsISCt0+tNhLUFpIeHC9rt122U/S",
	"Nh6SoIYkqD9eEpSjlJ1zodx38QOZDus3VtnMoZ60i28abxsbWkUFkGS8SebEpiBz0IT65AgtiCw5sUTd",
	"k3lkr27qG91d3SXFkqUuS6w9FTOLakbWjEYL1N+3VbhP457b14KAqXweP/VcvtW+tsvSypJmLK3v2fJM",
	"3cjcik0cm8Wa94aEZJmBikOolFQiUNk4WXCWnnDeBi+3MsuFGbvf9ao4F+w6CUdtr94c//T6+PL1iPx0",
	"enz549lPpyNy8vOPr+2v48uT78/+cYrM/buTC/K90OTgWyRirrOVM8whNQZvLlJ0fqEEOByREyEycnDG",
	"Z9s1PzbEugRycEklbGyLs0HAP+xWXwd8MFkJjEC2Po7gxX290TH15YDpA6Z/OpiuVHbmVBrbqleWKPVg",
	"i3YCXN/7f4aN8BaVoEXeoI5p+wpH00MQ25a0zPTGaYYj///sjfun62cA1kb1bd4EF2bz5nBFSlOeqko1",
	"VmVhTFK3u41sOhWTSzZfaMLFHWH6c2VDrMV9ggpnofJ0GpPvxR0sXUzC2bCFGpFijo0oX9mog5PgD2NM",
	"d6mdhT3BReH1nkd4KnpVH2PuZKBtfKGye43aONYsfNNmIriNkrUtqDVPum1UG2wpaMoyu2+CA6FG2avM",
	"t6SUElVavwLUfo8vzoh3kcZkPB7bKLrSskzQOjSWBE9dcCFlEs0HZTrHCIWx0gi1OrONIhRUL0hsIR7X",
	"S4kJ+Rbdy2jcjsg1R/Ig3wrh4G3HfE8mE3JZk1QNfesjt9reTIjPVXtJsfnwBy7ueGh0HItKOCLX0bGP",
	"eF9HI3IdXUgxl6AU43PzwCDldfQa5pKmkF5Hpts/F1Qni3OQc/gBVn/HzqrHV1pSDfPV33PzHp8bs9kg",
	"499zWlQPzmlRfVztniLvbozCvnwZ1zv6r38rwY+uG4gwErnBg0KvriPSGvXoOsJx/XM/yaNrRCzzWAot",
	"puXs6DqarjSo0cuRhGJkRObf6xGuo3+ZPZlMHDXiZiryYQ2hM6r0G0m5wu/esJC4Xm9TBVGo0sQgvste",
	"8UvWVWuDasYkE7xy72AsEqcVO/S05vAU9X17r2zJU5DZykj5utdkQfnc2GfkrI58Gtvt1uAJxmE4KZW3",
	"I3FeVY+GNCxKu25Q6UgSKGxaSdOPtZGee52Jee1MpGRR5pSjC84mT/l3PMVwH59X9F27GWuoOcAY23YK",
	"hjIRWZzdbKaa0/sfgc/1Ijr68tX/+utXwfxwy+S+Aw6y0irbU15v05R/Zk6xtz/jed0GYd/e8TtqtUnD",
	"RFNSFmYNhkMwbsRPAiPCZuHOWEX52Yq8fDUiUweOdbp/d38TB6bMFPnbqDMfpogBq5gZKQfkjumFMRiR",
	"hTpdMsBCoZpv3PFr/vUvBuo2uB8dvejxzqoQkO3zmrFTQ8NzSfOcapYQhgrTjIFsYocNbeGHXnBXi/tc",
	"OcJr4MuFFGmZgESO6uPKTYpcFWARygpCAvcGFpXDyPqUgHK0A+yQPpRsuejdApCVoPvLfSNxVsrYB5AS",
	"SuYllZRrgBQ9beSNb9ugcVr7VjxCN3O9zBSdPwaRvoPtL1+8+gtuRPWgFRh6dzz+v3T8682B+/Fi/Ld/",
	"jo5uvmj8vbGRnICiGNYqOk5pD9ERsjQxI29kCSPyLc0UjMhbjrwoboRxzPtoFGGDaBS5FsH7pMM6KooY",
	"TCSpkLvhnyJIZEaExk4ax4nIJw3/lVEDzo1iVlOSFaDdXbRJyDSRQqlGukrGboFUUtbS5xQSinqDnDIt",
	"qVzVs1NeLSwVzMqMHCgAEnORwjpBH1qypVOWMb0yhJlife+MOXUlN6oq5dqikoQ53BvFExPrbCz/IOXq",
	"5ctXX16V01TklPFvcz05/Prgl5JmaMQYlfzbXB92uObLv7Yjiu8setwcvBu7X1/4R4dfYyRwU4PDLyYY",
	"RazQ7ObduEa5+OaLw68b7w7/9KBaHJDLteipeE2FtRtyiLuZBg+5GczI/jTWDmpuQywGSQuCwXyvoLdd",
	"gZ4hdzx8O9p+jwoTuTltFXJptN1L5IX4MMUQonj2EMWOIa1wjCpAXUPo4zcJfWyi5NOeo4Tt9w8EDp1L",
	"ZAgYDgHDP07A0FIGBgks2M0vm4zc8RUGaMJmozvcb7PWHbIfP0kfpn6sp9IBfBcP5Wkf/L2C3tyB4HG1",
	"yh/YULnqYyNL38iazq3j1rVk3FQno+9UQNfj6fqqFaVm8pXTlXpnEFcAIaedV35LO9+O6gc23c7gkhCZ",
	"sTLoHNDTGXD4SqZZQpsBokZqOH75PVWL/oDdBdWLXqW4VFseK9twXn4A928A7uoMQO+Rl2EXnn8X1h+Y",
	"pQzb8nFtS6iJWQbVQjbU5q0dcLWQDHsJ3HYwTii5/Uo1j7E8ySNgx93sCajbPM0D4LWXwdT4OA1/Z1MO",
	"Bv/HZPCfSikC9RHxMQZ7BEeXe5ui+h2VoTHW7tV8TPY4S/d9k+Zme4Q1im3Vn91sszzP7raijnXgBAjk",
	"4vz8zAXVggUiqpBbU+aG+OAPsLJJNmdhcFooS6Dpzzxb2fM4oeT8YLZXCIKm5ag7cgiKjSXa21j7Ll9t",
	"LTfBplusOrjarZbRXMFDM3+LHGGrmVvmseXM27G6vnVsbPVh88zVTkjbxMcAur7lEubMIPPWV+r+XNi4",
	"1wzZTi6Wtlhcgy/01YybiWCO9KXpxOZUrHdCYAncnv0GiVkw60c4iCw5d6kCXU0xBEy79+2U0Z7FftNO",
	"iitMMzBjrqMAZhT24a/NHg3nh75Z+OxTP4xtPWmnjfZxyVDCKdb48QfenUxuVQbypahstkiVhWoxfKsT",
	"72IJcsngbnIn5C3j8/Ed04uxBbKaIB+efJZyNc7oFLIxPsBDuJ770zs1TmEZLj7Xn2+KnGlnNrGGA0yg",
	"mKcFy2myMEBexcXt3DxQmLgRL1/GhtLOwUrobhkL+6ZRD8GLc6sNqxXXC9AsaYSWsUrKgi5hRBhPsjI1",
	"22LL1hg9ckklE6WqzoVZUMbkuFaZjEpkOrB+PheSf29rGprpjIif2IfguXbNeBlAGP/Gp+Ao0I7kfLUo",
	"jVVVc6aJ4J2Dd8iGiARdSg4ue8Kldvh6LbYYldHqyIIqkgtHxbUjrpk8YbTCgv5SQqVdT11ZHi0IUwpf",
	"WJelU/e8kt7QDM0WWJ8iKo9oj9gKoZKB4zYc7rVPCq9dghXcTyxULHtrpAxgX43EjUIoxbAGzay50tYx",
	"fly3T8XCnGM8IEmNFTeDO5IzXhpw4eYWVGHRmzeNA9/e9LFpIx7aNuHLJ4G5gkW4kxaUvsiCzbpJaOYh",
	"5SDNXe6jVLpSIUek5BkoRVaitPORkACrQKnFLXCrjVNOANVPp2XGYWLObfWxMw35iSi5DiUNddusH/BU",
	"5VTZXG+Hcm72uB13C5Ys6pPtSF222lO9/X6BsU2oA//UopBntilBhmU2ycJaQQaJ0fxdyl332KmbuZ+U",
	"IqXNeUHsrVNL/VZkMDN2IpIUT6siKGlpK5mBZDRjv9Y1NaqJ4u7afFxyAAzx3yemsCo5MFmU3LBjM3//",
	"Vru6VVUOIzY6rNfjBCsXFi+7a7ILqXKWHrUSb9SJLEWDjnKyfBm//B+SCl+poDGGxf0qfdcswkmuMKZ8",
	"AUqzHHPJvmiVHDSEm5n9w0mcoLFYWf1mXDwN4HhaoG8tPD9EnxXmad3TRAcT5vprO/Q6Na6sbLbpnT41",
	"TjXYyOeq4XNwPMB7OFrelyoLCauXJW6lmGOkQeaMu+xQx94sZVc5pv9AfoACagpEo66eElpx4kaXGFlC",
	"DkVKXp2dmNLk1jMXO/OYXIiizLAjrKcGRK2Uhjwml0DTsRFhz26CG3UFEx+T1dgVhxlTno4rdp6sgqk2",
	"kM1+ZPw2kB/n3lh3x9vLH7tejmpftlr/Nb/mr08vLk9Pjt+cvia1Em6pDCv2GClO53St4g0nL+NXLwwG",
	"g9GG2+yGKVJklHMrNfHovdGy/Wcv/Wfxdme0t1KXbGTvxPCcvrPv+NKfsnKawHoVAiwfxFx/ZEZZVsqW",
	"0pRQZUBk8DkvM82KDKwksvl9wBNDvSAhXVeDED5hLdyCruI0lZ/KqMRGftuaSrgHONrIUIjRbHGHmVbk",
	"f1/9/FOX9Z2jHwslEkmFZZaFUHrG7qvCO2hNcVBIddpiOhjdzxhqdlG/ghRjxlO4x6Twb22Ou9FDaFEA",
	"beoUwvoX6kMOYmYnr0ha4glTlyG/oGi9dWAYE2vj0Qzx89Sq7OromhNyjTbHdUTGDWSrHjpG6nONPQjt",
	"hyhM3r24ibfowaokdvJVBUHXxXW0U6L6sc1OH1fZ6Y3XVZ4rbYgYBEJMumm6RtOzhI6ccWwrTlHMeg/6",
	"3/tzpI+Jo6KdJ3XmWH+lKdtU+WZNphY5Vfr13sn8tU3o/+fyVR+tuxbOMezU7CpCRWqqtBR2fvx/vKz1",
	"7NIq0lp4htH8PMA1GhqeoeZLl1DuiZqSq6ZlVUUR7rD0Z0V0lX6jQNcqA4pGNueGxhzx2MrxVn2pa196",
	"q9vnMWN1pqp3ax45/YMqVfqjn5Sv6lYe33BzDd/Dw6Ijo4PgURE/SMDGQyoPc7cTywEsUTmG5I0xfzpD",
	"KZEwFFl4hgBTxhBoHpiWF8fkJ8PIsqz11nIjv1e2T0gd52mVKd3ksdpZ1ATcWnMpQreYGCjgqwaou9w+",
	"BAJnkTfXGm+f2GVGNW/2MCj5mRMlciA2wsg8zFM2m4GsQyTOqIG0HuIHxtPfO+LBe/1f6H16MnzIwV1t",
	"0Vi2w/g8c91bG9GHqJ3fJj3s4dxaro5nGmtsC7Oc9UJ7s2bxyeoIFuNE2U/IFGbC1UGq9qtxNMT6ItKY",
	"XJkddeqLDXpZ70kzwIX8R9NbsNWH0SLQQChaNmTscsWEqjrSbelV9bkQdyQTHAtC3lGmq1nSWx+m63Yf",
	"b1f1qGQB5H979rq7m3HvNlX73bdVXfwN+yhLBXI8L1kKk/q4kfqsZCGsfKIY3CD/7NKsq8YJbKzcTLOs",
	"Eh78c+1bWI+W9z4NofHnDo0nIg2ZKeV8bjnn92/eXPi9MW3rY2KW84zIC8KqMotb0ogTtHuUgQ09bIjP",
	"7zk+/wSLonmODh3asOFkTzMT4MloUQUtnmSA3C1WnZnbA/W4uOvoW6sHXkduoU+wTMix19STjErr/6Lc",
	"kp+DIpLftDQME6ybUyxBSqNlMh3vcrzxqnW8sd4V8jPGUo7IdXRVYiTP2KKyudJnR0ejTaBzqn3KbWNC",
	"lxFWfCYw6MU0xtUuQCaCU3K6BGn4skWeqHGxR/QyfhG/cIlqnBYsOoq+jF/Er2zZ0QXCbWJTnMcuVIjP",
	"5qDDobDKZHWOw3YtEbOUCtRnqfumFX9VeMrPWm841KsXL3zMCmzEAAtF2+LRk387rHZre4Bs2iNh+Bwh",
	"1+X8uO+zMqvxwsDoL3ucic3hCQz+lque4f/ntxje16fxJje4hqNIlXlO5WrrfdZ0rupL0RzMoxusHRpK",
	"LbQZJO6yuU4Jmiq/qI089pPWpkZVpf5vhK0Zuhd4BUZyiQIBGL5pXBjZWoBzwDqYRc2cFVdf+LfB/AHp",
	"d0f6rdCzD+c/jNa46OR9+8GYpR8sUWQQOjT8Gp9bjcIbm515rNGH/aZLH43UlaN3a7Zs2rmdse6bmfdG",
	"Kvgku6NobQlrOD1q7E1XiN2s4ftfQmr4gJeb8HI7vOhnxkFJ/h3o3TDtO9CfEJoNbPWjQd8tMG2DIkF1",
	"sgjdeCI1o5lP1/R2WM8IMbFZgO7IZLupdfDHa/geSBz86FB+/1pQf7rkdloQwkcZE6sH0FXExbsBBh3p",
	"UyLm3QjvAX2pduduZXD67GVIA7nDYbtzLdH5WW3P8JGDAcueZH4+uOsew26/Uhtsz0vXTSjtnHHvQFlD",
	"osu+jPlntUL78vN7eHBgSY+0Rl8+Hy0MdLA7HWyNtG0aaPPWyfvmxT6bTdDG8YyapwcGR/9/H81sOGey",
	"vQYVPGIS0KJaa/soNKgHT9kEkKF5zqYumZWLJc2iD4MNvQ9KehRid2XLlqZ0EHnXzOmPnzp+Kz1pkA37",
	"MKuDSLGLZJj403Zj9/3Yl+3bKSDUW/zPJ3zuRChmhHCROvVHoZcNhRwHwtlLbOupKOupLA1XU9wiJNY3",
	"g0fRjO21p7Tjf78K1lfTMmw99UP+947obb+OPprfp0W3/WxOHFU5VmAn8up3mMgxFsGHdGB/gSjnEznO",
	"gyzvsbrG5L3hK7tHSvfBOG3HHz/jHHUH/6lx4L9vYzEJz/CymSh56k4XnLt0tHf+VM6N76bnVkqXOhpe",
	"katd8HGoTTtm9g6q1H4i08/ETnqM70tM2lXPwAu+Az0wgv8KRvB0PWogeO9G2x+1bWMzlUGKLzKaPIf0",
	"t8Hvgeh/W6L/NOw/l64w2H+723+zMht4aJOH7o9/7dsIe5qjd28O3j+qZ3dw6T6fS/eJrtxH+XD35rv9",
	"Azhtw+veVmY/xVc70Np+/IdPpa9dZdVjHYV7IdOgp/CTNRKeZhwMPsGBP2z2Ce6dV2ydirMXYl93BQ6U",
	"/ok5/QZS3keK0TPQ8Q4+vr3QctDJN5Dzp+POe5xN8BH47wYWtC9n2cdiekwSCVh0imb9nrMtuGijmz3p",
	"JyeNiQ287dNSVeq9GzjGsygtu5Pb0zmHuwbtQf96fTdB9wa1JzvXT90U/mC+9cZldwM5Pcm1/mTc7JKR",
	"u3tuZypqeP52FbnuSsUnSlk38U9OsoKf96ciEv3thAPh7lEO7kQDvTTbY7pb+/oZyK9tuA8U+PwGdz/x",
	"fdz29sA0Hss09ki8G2V9kedjf+fibjknzdsawzU/mtcnPme1j7VrGgd820viRneHPSIVeV7v65ZFJlt3",
	"e24sMdm8O/N5uGrfVao97DUw9d/xKFrratEBz59UWjKMlD1ovsYtJ++bfx9VU7I5gZ7EhjY5bNaxqqL/",
	"nX4DGk5n6kMtyY8iOt/Zt16Gu6WtvRG9vgP9SeDWwDo/Wjt2W3TtqR0Z1HE34qy7P/wjRdtn1VRaV6fv",
	"rKn8LjUeB3rbvwm4HclhR/bCECQKvKE7mixfRgZT3UddWjldglzpBeNzIsHeoOnummlckNk4F+D9NF+p",
	"aN3l0t+Z9w0EuuoGdR7VbR1c6fTqnRFPmCtpFLwJz7k6jLPDKN90S3W26tJWNVJvPvz/AAAA//9SozLw",
	"2xkBAA==",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %s", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %s", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
