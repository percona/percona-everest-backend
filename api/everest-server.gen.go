// Package api provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/deepmap/oapi-codegen version v1.16.2 DO NOT EDIT.
package api

import (
	"bytes"
	"compress/gzip"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/labstack/echo/v4"
	"github.com/oapi-codegen/runtime"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for DatabaseClusterSpecDataSourcePitrType.
const (
	DatabaseClusterSpecDataSourcePitrTypeDate   DatabaseClusterSpecDataSourcePitrType = "date"
	DatabaseClusterSpecDataSourcePitrTypeLatest DatabaseClusterSpecDataSourcePitrType = "latest"
)

// Defines values for DatabaseClusterSpecEngineType.
const (
	Postgresql DatabaseClusterSpecEngineType = "postgresql"
	Psmdb      DatabaseClusterSpecEngineType = "psmdb"
	Pxc        DatabaseClusterSpecEngineType = "pxc"
)

// Defines values for DatabaseClusterSpecProxyExposeType.
const (
	External DatabaseClusterSpecProxyExposeType = "external"
	Internal DatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterSpecProxyType.
const (
	Haproxy   DatabaseClusterSpecProxyType = "haproxy"
	Mongos    DatabaseClusterSpecProxyType = "mongos"
	Pgbouncer DatabaseClusterSpecProxyType = "pgbouncer"
	Proxysql  DatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterRestoreSpecDataSourcePitrType.
const (
	DatabaseClusterRestoreSpecDataSourcePitrTypeDate   DatabaseClusterRestoreSpecDataSourcePitrType = "date"
	DatabaseClusterRestoreSpecDataSourcePitrTypeLatest DatabaseClusterRestoreSpecDataSourcePitrType = "latest"
)

// Defines values for MonitoringInstanceBaseType.
const (
	MonitoringInstanceBaseTypePmm MonitoringInstanceBaseType = "pmm"
)

// Defines values for MonitoringInstanceBaseWithNameType.
const (
	MonitoringInstanceBaseWithNameTypePmm MonitoringInstanceBaseWithNameType = "pmm"
)

// Defines values for MonitoringInstanceCreateParamsType.
const (
	MonitoringInstanceCreateParamsTypePmm MonitoringInstanceCreateParamsType = "pmm"
)

// Defines values for MonitoringInstanceUpdateParamsType.
const (
	MonitoringInstanceUpdateParamsTypePmm MonitoringInstanceUpdateParamsType = "pmm"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	BucketName       string            `json:"bucketName"`
	Description      *string           `json:"description,omitempty"`
	Name             string            `json:"name"`
	Region           string            `json:"region,omitempty"`
	TargetNamespaces []string          `json:"targetNamespaces"`
	Type             BackupStorageType `json:"type"`
	Url              *string           `json:"url,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// BucketName The cloud storage bucket/container name
	BucketName  string  `json:"bucketName"`
	Description *string `json:"description,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name             string                        `json:"name"`
	Region           string                        `json:"region,omitempty"`
	SecretKey        string                        `json:"secretKey"`
	TargetNamespaces []string                      `json:"targetNamespaces"`
	Type             CreateBackupStorageParamsType `json:"type"`
	Url              *string                       `json:"url,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// DatabaseCluster DatabaseCluster is the Schema for the databaseclusters API.
type DatabaseCluster struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec *struct {
		// AllowUnsafeConfiguration AllowUnsafeConfiguration field used to ensure that the user can create configurations unfit for production use.
		AllowUnsafeConfiguration *bool `json:"allowUnsafeConfiguration,omitempty"`

		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			Enabled bool `json:"enabled"`

			// Pitr PITR is the configuration of the point in time recovery
			Pitr *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage where the PITR is enabled
				BackupStorageName *string `json:"backupStorageName,omitempty"`

				// Enabled Enabled is a flag to enable PITR
				Enabled bool `json:"enabled"`

				// UploadIntervalSec UploadIntervalSec number of seconds between the binlogs uploads
				UploadIntervalSec *int `json:"uploadIntervalSec,omitempty"`
			} `json:"pitr,omitempty"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage CR that defines the storage location
				BackupStorageName string `json:"backupStorageName"`

				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupSource BackupSource is the backup source to restore from
			BackupSource *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage used for backups.
				BackupStorageName string `json:"backupStorageName"`

				// Path Path is the path to the backup file/directory.
				Path string `json:"path"`
			} `json:"backupSource,omitempty"`

			// DbClusterBackupName DBClusterBackupName is the name of the DB cluster backup to restore from
			DbClusterBackupName *string `json:"dbClusterBackupName,omitempty"`

			// Pitr PITR is the point-in-time recovery configuration
			Pitr *struct {
				// Date Date is the UTC date to recover to. The accepted format: "2006-01-02T15:04:05Z".
				Date *string `json:"date,omitempty"`

				// Type Type is the type of recovery.
				Type *DatabaseClusterSpecDataSourcePitrType `json:"type,omitempty"`
			} `json:"pitr,omitempty"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type DatabaseClusterSpecEngineType `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// Monitoring Monitoring is the monitoring configuration
		Monitoring *struct {
			// MonitoringConfigName MonitoringConfigName is the name of a monitoringConfig CR.
			MonitoringConfigName *string `json:"monitoringConfigName,omitempty"`

			// Resources Resources defines resource limitations for the monitoring.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container.
				//  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.
				//  This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
					Name string `json:"name"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate proxy specification will be applied for the given engine. A common use case for setting this field is to control the external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation) to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica. If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// ActiveStorage ActiveStorage is the storage used in cluster (psmdb only)
		ActiveStorage *string `json:"activeStorage,omitempty"`

		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecDataSourcePitrType Type is the type of recovery.
type DatabaseClusterSpecDataSourcePitrType string

// DatabaseClusterSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterSpecEngineResourcesCpu0 = int

// DatabaseClusterSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterSpecEngineResourcesCpu1 = string

// DatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterSpecEngineResourcesMemory0 = int

// DatabaseClusterSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterSpecEngineResourcesMemory1 = string

// DatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineStorageSize0 defines model for .
type DatabaseClusterSpecEngineStorageSize0 = int

// DatabaseClusterSpecEngineStorageSize1 defines model for .
type DatabaseClusterSpecEngineStorageSize1 = string

// DatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineType Type is the engine type
type DatabaseClusterSpecEngineType string

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterSpecProxyExposeType string

// DatabaseClusterSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterSpecProxyResourcesCpu0 = int

// DatabaseClusterSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterSpecProxyResourcesCpu1 = string

// DatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterSpecProxyResourcesMemory0 = int

// DatabaseClusterSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterSpecProxyResourcesMemory1 = string

// DatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyType Type is the proxy type
type DatabaseClusterSpecProxyType string

// DatabaseClusterBackup DatabaseClusterBackup is the Schema for the databaseclusterbackups API.
type DatabaseClusterBackup struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterBackupSpec defines the desired state of DatabaseClusterBackup.
	Spec *struct {
		// BackupStorageName BackupStorageName is the name of the BackupStorage used for backups.
		BackupStorageName string `json:"backupStorageName"`

		// DbClusterName DBClusterName is the original database cluster name.
		DbClusterName string `json:"dbClusterName"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterBackupStatus defines the observed state of DatabaseClusterBackup.
	Status *struct {
		// Completed Completed is the time when the job was completed.
		Completed *time.Time `json:"completed,omitempty"`

		// Created Created is the timestamp of the upstream backup's creation.
		Created *time.Time `json:"created,omitempty"`

		// Destination Destination is the full path to the backup.
		Destination *string `json:"destination,omitempty"`

		// Gaps Gaps identifies if there are gaps detected in the PITR logs
		Gaps bool `json:"gaps"`

		// State State is the DatabaseBackup state.
		State *string `json:"state,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterBackupList DatabaseClusterBackupList is an object that contains the list of the existing database cluster backups.
type DatabaseClusterBackupList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                  `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterBackup `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterCredential kubernetes object
type DatabaseClusterCredential struct {
	Password *string `json:"password,omitempty"`
	Username *string `json:"username,omitempty"`
}

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string            `json:"apiVersion,omitempty"`
	Items      *[]DatabaseCluster `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterPitr point-in-time recovery related data
type DatabaseClusterPitr struct {
	EarliestDate *time.Time `json:"earliestDate,omitempty"`

	// Gaps indicates if there are pitr logs gaps detected after this backup was taken
	Gaps             *bool      `json:"gaps,omitempty"`
	LatestBackupName *string    `json:"latestBackupName,omitempty"`
	LatestDate       *time.Time `json:"latestDate,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		// DataSource DataSource defines a data source for restoration.
		DataSource struct {
			// BackupSource BackupSource is the backup source to restore from
			BackupSource *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage used for backups.
				BackupStorageName string `json:"backupStorageName"`

				// Path Path is the path to the backup file/directory.
				Path string `json:"path"`
			} `json:"backupSource,omitempty"`

			// DbClusterBackupName DBClusterBackupName is the name of the DB cluster backup to restore from
			DbClusterBackupName *string `json:"dbClusterBackupName,omitempty"`

			// Pitr PITR is the point-in-time recovery configuration
			Pitr *struct {
				// Date Date is the UTC date to recover to. The accepted format: "2006-01-02T15:04:05Z".
				Date *string `json:"date,omitempty"`

				// Type Type is the type of recovery.
				Type *DatabaseClusterRestoreSpecDataSourcePitrType `json:"type,omitempty"`
			} `json:"pitr,omitempty"`
		} `json:"dataSource"`

		// DbClusterName DBClusterName defines the cluster name to restore.
		DbClusterName string `json:"dbClusterName"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed *time.Time `json:"completed,omitempty"`
		Message   *string    `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State *string `json:"state,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreSpecDataSourcePitrType Type is the type of recovery.
type DatabaseClusterRestoreSpecDataSourcePitrType string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                   `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		AllowedVersions *[]string `json:"allowedVersions,omitempty"`

		// Type EngineType stands for the supported database engines. Right now it's only pxc and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// AvailableVersions Versions struct represents available versions of database engine components.
		AvailableVersions *struct {
			Backup *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"backup,omitempty"`
			Engine *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"engine,omitempty"`
			Proxy *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"proxy,omitempty"`
			Tools *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`
				Status    *string `json:"status,omitempty"`
			} `json:"tools,omitempty"`
		} `json:"availableVersions,omitempty"`
		OperatorVersion *string `json:"operatorVersion,omitempty"`

		// Status EngineState represents state of engine in a k8s cluster.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string           `json:"apiVersion,omitempty"`
	Items      *[]DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesClusterInfo kubernetes cluster info
type KubernetesClusterInfo struct {
	ClusterType       string   `json:"clusterType"`
	StorageClassNames []string `json:"storageClassNames"`
}

// KubernetesClusterMonitoring Kubernetes cluster monitoring configuration
type KubernetesClusterMonitoring struct {
	Enable bool `json:"enable"`

	// MonitoringInstanceName Name of the monitoring instance to use for monitoring the Kubernetes cluster
	MonitoringInstanceName string `json:"monitoringInstanceName,omitempty"`
}

// KubernetesClusterResources kubernetes cluster resources
type KubernetesClusterResources struct {
	Available ResourcesAvailable `json:"available"`
	Capacity  ResourcesCapacity  `json:"capacity"`
}

// ResourcesAvailable defines model for .
type ResourcesAvailable struct {
	CpuMillis   *uint64 `json:"cpuMillis,omitempty"`
	DiskSize    *uint64 `json:"diskSize,omitempty"`
	MemoryBytes *uint64 `json:"memoryBytes,omitempty"`
}

// ResourcesCapacity defines model for .
type ResourcesCapacity struct {
	CpuMillis   *uint64 `json:"cpuMillis,omitempty"`
	DiskSize    *uint64 `json:"diskSize,omitempty"`
	MemoryBytes *uint64 `json:"memoryBytes,omitempty"`
}

// MonitoringInstance Monitoring instance information
type MonitoringInstance = MonitoringInstanceBaseWithName

// MonitoringInstanceBase Monitoring instance information
type MonitoringInstanceBase struct {
	Type MonitoringInstanceBaseType `json:"type,omitempty"`
	Url  string                     `json:"url,omitempty"`
}

// MonitoringInstanceBaseType defines model for MonitoringInstanceBase.Type.
type MonitoringInstanceBaseType string

// MonitoringInstanceBaseWithName defines model for MonitoringInstanceBaseWithName.
type MonitoringInstanceBaseWithName struct {
	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name string                             `json:"name,omitempty"`
	Type MonitoringInstanceBaseWithNameType `json:"type,omitempty"`
	Url  string                             `json:"url,omitempty"`
}

// MonitoringInstanceBaseWithNameType defines model for MonitoringInstanceBaseWithName.Type.
type MonitoringInstanceBaseWithNameType string

// MonitoringInstanceCreateParams defines model for MonitoringInstanceCreateParams.
type MonitoringInstanceCreateParams struct {
	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name string                             `json:"name,omitempty"`
	Pmm  *PMMMonitoringInstanceSpec         `json:"pmm,omitempty"`
	Type MonitoringInstanceCreateParamsType `json:"type,omitempty"`
	Url  string                             `json:"url,omitempty"`
}

// PMMMonitoringInstanceSpec defines model for .
type PMMMonitoringInstanceSpec struct {
	ApiKey   string `json:"apiKey,omitempty"`
	Password string `json:"password,omitempty"`
	User     string `json:"user,omitempty"`
}

// MonitoringInstanceCreateParamsType defines model for MonitoringInstanceCreateParams.Type.
type MonitoringInstanceCreateParamsType string

// MonitoringInstancePMM defines model for MonitoringInstancePMM.
type MonitoringInstancePMM struct {
	Pmm *PMMMonitoringInstanceSpec `json:"pmm,omitempty"`
}

// MonitoringInstanceUpdateParams defines model for MonitoringInstanceUpdateParams.
type MonitoringInstanceUpdateParams struct {
	Pmm  *PMMMonitoringInstanceSpec         `json:"pmm,omitempty"`
	Type MonitoringInstanceUpdateParamsType `json:"type,omitempty"`
	Url  string                             `json:"url,omitempty"`
}

// MonitoringInstanceUpdateParamsType defines model for MonitoringInstanceUpdateParams.Type.
type MonitoringInstanceUpdateParamsType string

// MonitoringInstancesList defines model for MonitoringInstancesList.
type MonitoringInstancesList = []MonitoringInstance

// NamespaceList defines model for NamespaceList.
type NamespaceList = []string

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName       *string   `json:"bucketName,omitempty"`
	Description      *string   `json:"description,omitempty"`
	Region           *string   `json:"region,omitempty"`
	SecretKey        *string   `json:"secretKey,omitempty"`
	TargetNamespaces *[]string `json:"targetNamespaces,omitempty"`
	Url              *string   `json:"url,omitempty"`
}

// Version Everest version info
type Version struct {
	FullCommit  string `json:"fullCommit"`
	ProjectName string `json:"projectName"`
	Version     string `json:"version"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// SetKubernetesClusterMonitoringJSONRequestBody defines body for SetKubernetesClusterMonitoring for application/json ContentType.
type SetKubernetesClusterMonitoringJSONRequestBody = KubernetesClusterMonitoring

// CreateDatabaseClusterBackupJSONRequestBody defines body for CreateDatabaseClusterBackup for application/json ContentType.
type CreateDatabaseClusterBackupJSONRequestBody = DatabaseClusterBackup

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = DatabaseCluster

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// CreateMonitoringInstanceJSONRequestBody defines body for CreateMonitoringInstance for application/json ContentType.
type CreateMonitoringInstanceJSONRequestBody = MonitoringInstanceCreateParams

// UpdateMonitoringInstanceJSONRequestBody defines body for UpdateMonitoringInstance for application/json ContentType.
type UpdateMonitoringInstanceJSONRequestBody = MonitoringInstanceUpdateParams

// UpdateDatabaseEngineJSONRequestBody defines body for UpdateDatabaseEngine for application/json ContentType.
type UpdateDatabaseEngineJSONRequestBody = DatabaseEngine

// AsDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu0
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu0() (DatabaseClusterSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu1
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu1() (DatabaseClusterSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory0
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory0() (DatabaseClusterSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory1
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory1() (DatabaseClusterSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineStorageSize0 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize0
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize0() (DatabaseClusterSpecEngineStorageSize0, error) {
	var body DatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineStorageSize1 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize1
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize1() (DatabaseClusterSpecEngineStorageSize1, error) {
	var body DatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu0
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu0() (DatabaseClusterSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu1
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu1() (DatabaseClusterSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory0
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory0() (DatabaseClusterSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory1
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory1() (DatabaseClusterSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JsonMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// ServerInterface represents all server handlers.
type ServerInterface interface {
	// List of the created backup storages
	// (GET /backup-storages)
	ListBackupStorages(ctx echo.Context) error
	// Create a new backup storage object
	// (POST /backup-storages)
	CreateBackupStorage(ctx echo.Context) error
	// Delete the specified backup storage
	// (DELETE /backup-storages/{name})
	DeleteBackupStorage(ctx echo.Context, name string) error
	// Get the specified backup storage
	// (GET /backup-storages/{name})
	GetBackupStorage(ctx echo.Context, name string) error
	// Partial update of the specified backup storage
	// (PATCH /backup-storages/{name})
	UpdateBackupStorage(ctx echo.Context, name string) error
	// Get the cluster type and storage classes of a kubernetes cluster
	// (GET /cluster-info)
	GetKubernetesClusterInfo(ctx echo.Context) error
	// Manage Kubernetes cluster monitoring configuration
	// (POST /cluster-monitoring)
	SetKubernetesClusterMonitoring(ctx echo.Context) error
	// Create a database cluster backup
	// (POST /database-cluster-backups)
	CreateDatabaseClusterBackup(ctx echo.Context) error
	// Delete the specified cluster backup
	// (DELETE /database-cluster-backups/{name})
	DeleteDatabaseClusterBackup(ctx echo.Context, name string) error
	// Returns the specified cluster backup
	// (GET /database-cluster-backups/{name})
	GetDatabaseClusterBackup(ctx echo.Context, name string) error
	// Create a database cluster restore
	// (POST /database-cluster-restores)
	CreateDatabaseClusterRestore(ctx echo.Context) error
	// Delete the specified cluster restore
	// (DELETE /database-cluster-restores/{name})
	DeleteDatabaseClusterRestore(ctx echo.Context, name string) error
	// Returns the specified cluster restore
	// (GET /database-cluster-restores/{name})
	GetDatabaseClusterRestore(ctx echo.Context, name string) error
	// Replace the specified cluster restore
	// (PUT /database-cluster-restores/{name})
	UpdateDatabaseClusterRestore(ctx echo.Context, name string) error
	// List of the created database clusters
	// (GET /database-clusters)
	ListDatabaseClusters(ctx echo.Context) error
	// Create a database cluster
	// (POST /database-clusters)
	CreateDatabaseCluster(ctx echo.Context) error
	// Delete the specified database cluster
	// (DELETE /database-clusters/{name})
	DeleteDatabaseCluster(ctx echo.Context, name string) error
	// Get the specified database cluster
	// (GET /database-clusters/{name})
	GetDatabaseCluster(ctx echo.Context, name string) error
	// Replace the specified database cluster
	// (PUT /database-clusters/{name})
	UpdateDatabaseCluster(ctx echo.Context, name string) error
	// List of the created database cluster backups
	// (GET /database-clusters/{name}/backups)
	ListDatabaseClusterBackups(ctx echo.Context, name string) error
	// Get the specified database cluster credentials
	// (GET /database-clusters/{name}/credentials)
	GetDatabaseClusterCredentials(ctx echo.Context, name string) error
	// Get the Point-in-Time related data for the specified database cluster
	// (GET /database-clusters/{name}/pitr)
	GetDatabaseClusterPitr(ctx echo.Context, name string) error
	// List of the created database cluster restores
	// (GET /database-clusters/{name}/restores)
	ListDatabaseClusterRestores(ctx echo.Context, name string) error
	// List of the created monitoring instances
	// (GET /monitoring-instances)
	ListMonitoringInstances(ctx echo.Context) error
	// Create a new monitoring instance object
	// (POST /monitoring-instances)
	CreateMonitoringInstance(ctx echo.Context) error
	// Delete the specified Monitoring instance
	// (DELETE /monitoring-instances/{name})
	DeleteMonitoringInstance(ctx echo.Context, name string) error
	// Get the specified monitoring instance
	// (GET /monitoring-instances/{name})
	GetMonitoringInstance(ctx echo.Context, name string) error
	// Update the specified Monitoring instance
	// (PATCH /monitoring-instances/{name})
	UpdateMonitoringInstance(ctx echo.Context, name string) error
	// Get all namespaces managed by Everest
	// (GET /namespaces)
	ListNamespaces(ctx echo.Context) error
	// List of the available database engines
	// (GET /namespaces/{namespace}/database-engines)
	ListDatabaseEngines(ctx echo.Context, namespace string) error
	// Get the specified database engine
	// (GET /namespaces/{namespace}/database-engines/{name})
	GetDatabaseEngine(ctx echo.Context, namespace string, name string) error
	// Update the specified database engine
	// (PUT /namespaces/{namespace}/database-engines/{name})
	UpdateDatabaseEngine(ctx echo.Context, namespace string, name string) error
	// Get the capacity and available resources of a kubernetes cluster
	// (GET /resources)
	GetKubernetesClusterResources(ctx echo.Context) error
	// Get Everest Backend version info
	// (GET /version)
	VersionInfo(ctx echo.Context) error
}

// ServerInterfaceWrapper converts echo contexts to parameters.
type ServerInterfaceWrapper struct {
	Handler ServerInterface
}

// ListBackupStorages converts echo context to params.
func (w *ServerInterfaceWrapper) ListBackupStorages(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListBackupStorages(ctx)
	return err
}

// CreateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) CreateBackupStorage(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.CreateBackupStorage(ctx)
	return err
}

// DeleteBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteBackupStorage(ctx, name)
	return err
}

// GetBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) GetBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetBackupStorage(ctx, name)
	return err
}

// UpdateBackupStorage converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateBackupStorage(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.UpdateBackupStorage(ctx, name)
	return err
}

// GetKubernetesClusterInfo converts echo context to params.
func (w *ServerInterfaceWrapper) GetKubernetesClusterInfo(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetKubernetesClusterInfo(ctx)
	return err
}

// SetKubernetesClusterMonitoring converts echo context to params.
func (w *ServerInterfaceWrapper) SetKubernetesClusterMonitoring(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.SetKubernetesClusterMonitoring(ctx)
	return err
}

// CreateDatabaseClusterBackup converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseClusterBackup(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.CreateDatabaseClusterBackup(ctx)
	return err
}

// DeleteDatabaseClusterBackup converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseClusterBackup(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteDatabaseClusterBackup(ctx, name)
	return err
}

// GetDatabaseClusterBackup converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterBackup(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseClusterBackup(ctx, name)
	return err
}

// CreateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseClusterRestore(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.CreateDatabaseClusterRestore(ctx)
	return err
}

// DeleteDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteDatabaseClusterRestore(ctx, name)
	return err
}

// GetDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseClusterRestore(ctx, name)
	return err
}

// UpdateDatabaseClusterRestore converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseClusterRestore(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.UpdateDatabaseClusterRestore(ctx, name)
	return err
}

// ListDatabaseClusters converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusters(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListDatabaseClusters(ctx)
	return err
}

// CreateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) CreateDatabaseCluster(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.CreateDatabaseCluster(ctx)
	return err
}

// DeleteDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteDatabaseCluster(ctx, name)
	return err
}

// GetDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseCluster(ctx, name)
	return err
}

// UpdateDatabaseCluster converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseCluster(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.UpdateDatabaseCluster(ctx, name)
	return err
}

// ListDatabaseClusterBackups converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusterBackups(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListDatabaseClusterBackups(ctx, name)
	return err
}

// GetDatabaseClusterCredentials converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterCredentials(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseClusterCredentials(ctx, name)
	return err
}

// GetDatabaseClusterPitr converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseClusterPitr(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseClusterPitr(ctx, name)
	return err
}

// ListDatabaseClusterRestores converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseClusterRestores(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListDatabaseClusterRestores(ctx, name)
	return err
}

// ListMonitoringInstances converts echo context to params.
func (w *ServerInterfaceWrapper) ListMonitoringInstances(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListMonitoringInstances(ctx)
	return err
}

// CreateMonitoringInstance converts echo context to params.
func (w *ServerInterfaceWrapper) CreateMonitoringInstance(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.CreateMonitoringInstance(ctx)
	return err
}

// DeleteMonitoringInstance converts echo context to params.
func (w *ServerInterfaceWrapper) DeleteMonitoringInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.DeleteMonitoringInstance(ctx, name)
	return err
}

// GetMonitoringInstance converts echo context to params.
func (w *ServerInterfaceWrapper) GetMonitoringInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetMonitoringInstance(ctx, name)
	return err
}

// UpdateMonitoringInstance converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateMonitoringInstance(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.UpdateMonitoringInstance(ctx, name)
	return err
}

// ListNamespaces converts echo context to params.
func (w *ServerInterfaceWrapper) ListNamespaces(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListNamespaces(ctx)
	return err
}

// ListDatabaseEngines converts echo context to params.
func (w *ServerInterfaceWrapper) ListDatabaseEngines(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "namespace" -------------
	var namespace string

	err = runtime.BindStyledParameterWithLocation("simple", false, "namespace", runtime.ParamLocationPath, ctx.Param("namespace"), &namespace)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter namespace: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.ListDatabaseEngines(ctx, namespace)
	return err
}

// GetDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) GetDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "namespace" -------------
	var namespace string

	err = runtime.BindStyledParameterWithLocation("simple", false, "namespace", runtime.ParamLocationPath, ctx.Param("namespace"), &namespace)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter namespace: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetDatabaseEngine(ctx, namespace, name)
	return err
}

// UpdateDatabaseEngine converts echo context to params.
func (w *ServerInterfaceWrapper) UpdateDatabaseEngine(ctx echo.Context) error {
	var err error
	// ------------- Path parameter "namespace" -------------
	var namespace string

	err = runtime.BindStyledParameterWithLocation("simple", false, "namespace", runtime.ParamLocationPath, ctx.Param("namespace"), &namespace)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter namespace: %s", err))
	}

	// ------------- Path parameter "name" -------------
	var name string

	err = runtime.BindStyledParameterWithLocation("simple", false, "name", runtime.ParamLocationPath, ctx.Param("name"), &name)
	if err != nil {
		return echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf("Invalid format for parameter name: %s", err))
	}

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.UpdateDatabaseEngine(ctx, namespace, name)
	return err
}

// GetKubernetesClusterResources converts echo context to params.
func (w *ServerInterfaceWrapper) GetKubernetesClusterResources(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.GetKubernetesClusterResources(ctx)
	return err
}

// VersionInfo converts echo context to params.
func (w *ServerInterfaceWrapper) VersionInfo(ctx echo.Context) error {
	var err error

	// Invoke the callback with all the unmarshaled arguments
	err = w.Handler.VersionInfo(ctx)
	return err
}

// This is a simple interface which specifies echo.Route addition functions which
// are present on both echo.Echo and echo.Group, since we want to allow using
// either of them for path registration
type EchoRouter interface {
	CONNECT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	DELETE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	GET(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	HEAD(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	OPTIONS(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PATCH(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	POST(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	PUT(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
	TRACE(path string, h echo.HandlerFunc, m ...echo.MiddlewareFunc) *echo.Route
}

// RegisterHandlers adds each server route to the EchoRouter.
func RegisterHandlers(router EchoRouter, si ServerInterface) {
	RegisterHandlersWithBaseURL(router, si, "")
}

// Registers handlers, and prepends BaseURL to the paths, so that the paths
// can be served under a prefix.
func RegisterHandlersWithBaseURL(router EchoRouter, si ServerInterface, baseURL string) {
	wrapper := ServerInterfaceWrapper{
		Handler: si,
	}

	router.GET(baseURL+"/backup-storages", wrapper.ListBackupStorages)
	router.POST(baseURL+"/backup-storages", wrapper.CreateBackupStorage)
	router.DELETE(baseURL+"/backup-storages/:name", wrapper.DeleteBackupStorage)
	router.GET(baseURL+"/backup-storages/:name", wrapper.GetBackupStorage)
	router.PATCH(baseURL+"/backup-storages/:name", wrapper.UpdateBackupStorage)
	router.GET(baseURL+"/cluster-info", wrapper.GetKubernetesClusterInfo)
	router.POST(baseURL+"/cluster-monitoring", wrapper.SetKubernetesClusterMonitoring)
	router.POST(baseURL+"/database-cluster-backups", wrapper.CreateDatabaseClusterBackup)
	router.DELETE(baseURL+"/database-cluster-backups/:name", wrapper.DeleteDatabaseClusterBackup)
	router.GET(baseURL+"/database-cluster-backups/:name", wrapper.GetDatabaseClusterBackup)
	router.POST(baseURL+"/database-cluster-restores", wrapper.CreateDatabaseClusterRestore)
	router.DELETE(baseURL+"/database-cluster-restores/:name", wrapper.DeleteDatabaseClusterRestore)
	router.GET(baseURL+"/database-cluster-restores/:name", wrapper.GetDatabaseClusterRestore)
	router.PUT(baseURL+"/database-cluster-restores/:name", wrapper.UpdateDatabaseClusterRestore)
	router.GET(baseURL+"/database-clusters", wrapper.ListDatabaseClusters)
	router.POST(baseURL+"/database-clusters", wrapper.CreateDatabaseCluster)
	router.DELETE(baseURL+"/database-clusters/:name", wrapper.DeleteDatabaseCluster)
	router.GET(baseURL+"/database-clusters/:name", wrapper.GetDatabaseCluster)
	router.PUT(baseURL+"/database-clusters/:name", wrapper.UpdateDatabaseCluster)
	router.GET(baseURL+"/database-clusters/:name/backups", wrapper.ListDatabaseClusterBackups)
	router.GET(baseURL+"/database-clusters/:name/credentials", wrapper.GetDatabaseClusterCredentials)
	router.GET(baseURL+"/database-clusters/:name/pitr", wrapper.GetDatabaseClusterPitr)
	router.GET(baseURL+"/database-clusters/:name/restores", wrapper.ListDatabaseClusterRestores)
	router.GET(baseURL+"/monitoring-instances", wrapper.ListMonitoringInstances)
	router.POST(baseURL+"/monitoring-instances", wrapper.CreateMonitoringInstance)
	router.DELETE(baseURL+"/monitoring-instances/:name", wrapper.DeleteMonitoringInstance)
	router.GET(baseURL+"/monitoring-instances/:name", wrapper.GetMonitoringInstance)
	router.PATCH(baseURL+"/monitoring-instances/:name", wrapper.UpdateMonitoringInstance)
	router.GET(baseURL+"/namespaces", wrapper.ListNamespaces)
	router.GET(baseURL+"/namespaces/:namespace/database-engines", wrapper.ListDatabaseEngines)
	router.GET(baseURL+"/namespaces/:namespace/database-engines/:name", wrapper.GetDatabaseEngine)
	router.PUT(baseURL+"/namespaces/:namespace/database-engines/:name", wrapper.UpdateDatabaseEngine)
	router.GET(baseURL+"/resources", wrapper.GetKubernetesClusterResources)
	router.GET(baseURL+"/version", wrapper.VersionInfo)
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{
	"H4sIAAAAAAAC/+x9a3PbNtroX8Gw70yTrkTbSbuz6y87juNtfVq3HtvZM2fjnAYiIQlrEmABULaS5r+/",
	"gwcAr6BESbbjbPglsUgQt+d+wYOPQcTTjDPClAwOPwYympMUw5+vcHSTZ5eKCzwj+gGOY6ooZzg5Fzwj",
	"QlEig8MpTiQZBTGRkaCZfh8c2m+RNB8jyqZcpBhejoKs8vXHYJJHN0T9ilMYQy0zEhwGUgnKZsGnRr+e",
	"96zrQ0Fm3m9Gwd14xsf64Vje0GzMM7OoccYpU0QEh0rk5NMoUFjMzMxkhiMzW6pIKr3j2QdYCLwsf38M",
	"CMvT4PBtIF8GowB/yAUJ3o3an+ci8XQL6/gjp4LEug9Y7Ki6ZbYnz2TLQfjkPyRSepAaSOUvVKramv5H",
	"kGlwGHyzV+LEnkWIvTo2eNZ7LAhWpNbsHAtset4edTLdB1FEyBbm4CgiUv5Mll541PGqPsbVnKAo4Xlc",
	"DGNa70WcKUwZEYhVdncbfKwPeIRySQSKyZQyokfVzWEMxKdIzUmFVODn618vzWtDOGiuVCYP9/Zu8gkR",
	"jCgiQ8r3Yh5JPeeIZEru8QURC0pu9265uKFsNr6laj420Jd7uje5903M5DjBE5KM4UEwCsgdTrMEYHkr",
	"xzFZ+Ja9OzVJEgmiuqD1ZdBaiXHV9WxGg6+xwhMsyXGSS9ifJq40GiAqASMugRA1PsDP2LaKTCuJjs5P",
	"wzaJZPRfREgLugZOnp/adxYvzTgL80xjqRkREJRKJEgmiCRMAR/XjzFDZl0huiRCf4jknOdJjCLOFkQo",
	"JEjEZ4x+KHqTSHEYJsGKSIUARxhO0AInORkhzGKU4iUSRPeLclbpAZrIEJ1xYUTKYUEWM6rCm78BTUQ8",
	"TXNG1RKIWdBJrriQezFZkGRP0tkYi2hOFYlULsgezugYJsv0omSYxt8IInkuIqCNFurcUBa3t/JnymIN",
	"J+woG6Za7ph+pBd9cXJ5hVz/ZlfNBpZNZbmXeh8omxJhWk4FT6EXwmIgLvgRJZQwhWQ+SanSQPojJ1Lp",
	"bQ7RMWaMKzQhKM9irEgcolOGjnFKkmMsyYPvpN49OdZb5t3LlCis0bhCiyWZyIxEa2njMiNRDXljIjX9",
	"IqmwAtba+MBDIUnCb98wiafkmLMpneUCKz+9dLREU0qSWDP4WCM3YTIXGrjYAAgYf4QZikBAatIov5Uo",
	"Z1OqgKozweM8gh5zScJyxyacJwQzEGogHNtzs0LTsoqJFaEZieiURn69izA8SYgHmU/MC4PP0wTPzKr0",
	"Q9uz9M4to8rDzc5Pry7cvGpLd4LPoLIWezQlwDAWRCzbamJVsfBL9VfNJm7cqpytNUK3cwKwIsjN022L",
	"B1+32jHdr3e78izhOD7V/G+Bk0sftr9pNkEsTydE6LVIEnEWSzQh6pYQozRMKEv4TCLTdQVKmsvOiGjJ",
	"OLcin5zS/DrOE7P79XlduldmxQmVSk/JoV3x4agU4V5I2YZNtHWPa+gSPhJGHF8Y0q1yFaebJbygpftB",
	"DujcLteLJH5tsmsl7a6qCpwynPmYZ9QH1It6g6L/AuMseCLzWnEkiNaVg1FgdFSDZy9feNCuxKZuZCqY",
	"hOBsxUoaGNxGghIUI6fDFb358LyuS25AIFp0XYIk98sp865AJAwqG7KyXzP8CedKKoEzrR5gxMgtstpc",
	"F653jPaq8rZJTFbV0NDSaExAjXgkWgKRCCs1YiP0IWaG1dwjNrCauwF0C6c22mVNaUL2YipIpLhYhluh",
	"CQzsBezEagtmNf7teP2q1ci3Ia9fOZi6qbdB0d6StZIUhOaYsnFNaNY5ZgvIWgX0omox8zdXxxpLLb5A",
	"p6BIantZ2z6ZMgBNsTpE18GL/f2/jvcPxvsvrg5+ONz//nD/h39fB14oOwstJlOcJ5pXwGyaxv/VMism",
	"oz/R2+hWFwJpGwPPfmyMCI+N96kF1k8eQBM2o4z4WLZ+7ubhLC1kmq9RqwwI2n0aldH1abtqwsvDtbOE",
	"RtjLrs2bNp+2fRefevhzShlN9U4e+Hh1aQB5RrWvELZ6U2HNJBQMEE3uBEfzxjRCdDpF2hiRRI1aH+nO",
	"9EuaZlwC525sapaDrs6Wv02Dw7cf25NuWfPvmqh1fP7G7ZX+s5iCZRMpeECBK2iLNDgM/v+z6+u//Dl+",
	"/o9nz97uj//+7i/Prq9D+Ou75/94/mfx6y/Pnz979vbnsx+vzk/e0ed/vmV5emN+/fnsLTl517+f58//",
	"8T/gUindPGNN6FyM7bqcNyUlKRfLnTflDLpx+2I6/bK3xkfnsvRhN3QP53SrUaVT91Zz0yjB0kMhx/qx",
	"67DoCR4qriVi4cHJiJBUaqULLXiSp9CMegWCpB/IzrC+pB+KleoOCwOscx5fCsCrkh62qlvP+7hC4Fjw",
	"W2eeEzXZXaS3gks1E0T+kegfMo0nfs+iJOISHIPSrza8qTfwavHwGllXtHMdgRvBvPI6UxZdbj7n46sv",
	"0jVfpzg50rHtfBubckYVNxBpDn5WvCt4TPlkNX2VDY3o9O/nmadVc1MxavaFji9Cv7jtIfmcQl8XYtad",
	"44i7HDH0cQ6a+lkHTSWY0+UCpFGB7OCjIoRAGSgioXtlPh4Z41XLU1C+J0vjOyziGiG6ZuhKP9L2KEM4",
	"yebYerAwix3Lt34Qh3yvlwynNHJ7cJQ4SxhNCVa5IGiGFSn7Nv3pQdI0V9qECtGpAi8YZ8kSTTSWG69X",
	"MTOwDjr8BRfVRSJBpkQQpmHBmcZopUUYQ+c8vtRbUmst2/u/wqhOc6lQilU0r2FQbZiMx6Fn6x35nvO4",
	"cCtVt0LDA3YhxTfgV8CqRCG8wDQBlwBlksYE4QrI1hIpLGitbdvgpRrNxinOxjdkKau9tFvZblKc6U6N",
	"ztYd1dtYTH0hKlcdXX4xmqt5OLGOohTfab0a4ZTnDHxiEU+zXJVqskTgcNao4HG+r4ru1bjlXooZnpFx",
	"0e24pKO9wIMJLi7wtYPtwsVHGoAzBtFKwDmKA1Om6IdKxFOqrGFcpdsRouBG1PYuKH8WZejUED+ViNxp",
	"44iqZOmsShKPEFdzIm6pBDMcM20VJaCEA+jHTgJAjCksZxKZaA+5iwiJ7WCPimX9jO4Ma07o8/iAxKq5",
	"SaXimY1yOb+YJ+4g+N3S059+XPhL4EfNcq9bpFoUZlpMCIqVtz26pUmiJRfOsoRacOu+Z3RBmNWrQnSk",
	"MSc1MRwUYavvS6JsELAqEhQHbBE8MarZnY2FmjCzc3kV/oeoK4bVz+dg1rTW5UDutA3ucYrA83pnpu0a",
	"RY5az+QFZjOfZnV6Xn3vBnBBhdNz58MU5v2z49PXFxpwMNpzoBHNUt2uTQVP67BVII2pRIxXdbVudaM2",
	"o0poVk8Gx7EgUuqJMlSbCuIC3VI157kCb65KsbxZ4Qxrpy+UzjEXFl/pILO7r78egW41IWU8nYsCnyrG",
	"TKXf4m0f79l2niiDJJ/bEVWbxeCHGvxQn80Ptd4FYXC14YFIOZtxvfA5NrLOyjzrjJhNeM4iIvq6wevx",
	"LfCAe+O/Cqtcrk/BgGa1cCmfSCIWm2VhRIouyGWXn+6o+rrpXDNqAyviLM/APQOG5nMf951zqfwm4E/2",
	"jRvBtaykCbhBLLsVmsP4swVSIqV3MWfmhdH/lMDV7FiEJ1p8eFWeSnyIC+VReLhQZXxIqD6z7hG5FQTH",
	"Sx8DxvGyzfKhtTaRZc+4sPVsdrsqFVc4qQqV/n13YLBF2QKN4Je13jt3vZ9y20D0Vx3pOt5m/RL9bCh1",
	"SPcb0v2+unQ/m12wadKf+Sx8SkkPRYrBmuSC6pBc0BnVtNM0CGEy2+VA1Oexgxrg9mBzZaALOhFPs4Qo",
	"n6vg2L0qZAQ1Qtqkwf2HT9AtlqjoIazKC00ZkDbhg4vJ0fQNaV5UB5QKp5nDgTyTShCcWqh/K026p01c",
	"6zd4TKSirCP79HX50k1imieJJznGi3AznHmA+CPOJKKxpuEp5HxNrbGMwaWfaVBqgjcKVpEmmfCZPwUU",
	"YOwXuAUaO/AX5zyw6oG8MP9328tgd9alBxLrpjY6Yrk1uOus66vunTBmOJXA8lt0WeEAg5x+UDldOHJ6",
	"nWXya2kex8wg/h9F/Peg4mNBgE3hpA2P0hK3+9uitwxLecsFwLI87iQ4V0FHEN8ZiOta95h6L9Zzb0xn",
	"4DZPnNsMfOYp85lzb+ptR7qtIAkohTBc63wNFgklUr22KlHJSV7sv3g5Pngxfnlw9eLl4Q9/P/zh7//u",
	"rST6FTnKYhppYqqrcBlVArS1hjKHp8rB32Yla31Z4RvCvHqdodN6OnRrZqbRvS63B8AuTC71WgZr2/Vz",
	"stgE7cHLMnhZvj4vi6WUjd0s9rvQd+5gt4MyhhxXHwMbjsYMR2OGozH3djRmIwdllUtUfZIVgK7HwwqX",
	"uEe/pGNmWzgmO/lZzTPZT2urBAPbyf1+p1ll5rUclGK6Da54H/EqO2Yvi7XS9n68ZU7pGhSup23AOo17",
	"sGOfoh170nGmsf5+jRlk0kIG82cwf74i88dQBpg9Ztv1Xyanu3EEuKOKDIkt7m9Zvcp3CBm0Pqkwi8uz",
	"RTLPMi6c46kyLxmiCzqbK8T4LaLqW2lO22R3EdAA5EWF6Cd+SxY2Pd0mBGVyhLIZNMJsaRLQrX20XnHr",
	"PBi2TkWzG76JanbStf/u/EwVAt5zcFqBEnmNOiqnbxauEZ+2zn2XkrHLCF11uKIdwYa+SkWpmgVmdaXO",
	"GYTFhqCTxisH0sa3o/KByTHUuMR5IhFNTZk9NfdouoIqGuFqtbSKVxC+/AnLuRfL4e25tWC9Sm8u/VXY",
	"uo4x+Q7uD9v9CNtdnLDoPDk0QOHhodB+oJcygOVpgcXXRC8DKy4qavOKSfjUgG4vgAUHZQijm7/J6iGh",
	"nTwCZtzVnoCyzW4eAKe9DKbG0zT8rU05GPxPyeA/EYJ7XOHwWG9qxpkk7aoKnY5I3xg/F5k11vdzyqZ8",
	"ZQKOc+bpXfQUPoCXV9be8fBACEJACRWoolsLJL8NZtmLYBTMspfa3OhrXzWsleocfCO+67MNZytKXvzc",
	"3ozeNS9MuTm/hCs7OWXaIIw6glG/VkIslYGp/ahahabyWrduz7yFpn3LPXvL6PXb24vuQ38ePKtyuw6T",
	"EBLAmsf4zmiS0Cr6mAMm1QUGh0FOmfrr9xAPofLm0p5V6feFOcT2aqlI72FaJFjdbpORVh58PCrW92kU",
	"RDjDEVXL/9K1HrvltajZvRhV4O1Ds7MW9Vi3jT2zuEoMtr99hSX5v1TNgQI9pxk9ZFe/AqHlPzFFyW3F",
	"ynfeCetBV1fY8Y9Vx4dmqfQsTdtBwv5V3W0p9ZSyXwibaQX7YAee0QNsta3fEYRwNLVPbZinXL7/YbZ+",
	"C5zuATxziqJyLcS90N9o08/Pz856rtDW7N6dePWQLd6saa/1EGfUXpJwH5Ad1XKft6ZyaS4quCfs8rD6",
	"87Oz9qZdZiQKevKFN6DS3w9qPShKGdujhlLeBW12PYtHvnnMteJqilbfa4MUZn+/+utduu5BeeALTjpv",
	"LGlRRqe/5GRBBJHKOUj8Fto0T5JjnqZU7cIuMsH1dPyZwv27WXS5y7a0QqrTKnsfVRftUx0pBw8AzmiK",
	"o7nGnmWY3cz0Axlqoz1cHISaoM6IMd6bhcLMm0rFKWfpG0eZXDI1J4pGlVpTUIdujhdkhCiLkjzWLMQU",
	"BsQsRgssKM9lcXbd6AghOiq9KSleQgcmBMgZaCoff4OWejoj5Cb2yVtQSFGWe0jLvYH+bRk/Oq1WqFRw",
	"I0BKFeKsURwA8B0JonLBSGy8ZWXmenFjBgT/BJpjiVIujPu4jNGZlDvjUaIS8Qz/kZPC8TYhxUUcVEp4",
	"YaKZ1hPk/HcVp5EGgQk3gl8JXJWmur2gZGEKKDByByVjwG1YRAuLfT82u2LquEecuXqq0JeelvU7ZVxK",
	"ClX+ptWV1u/F0OuO5pjNSIzASDe3iTCE0ZTcopSyXG8XAFcLdxKbLXGgd15RU2bK7bY5HpvLogpVAUmz",
	"la66lTkNGuHE7ZTdaQPLKRVSFd6lEcpZQqRES56b+QgSEVpspeI3hBlHHWaIgGfKOqA6ym+mpuLpqSLp",
	"Mc+Zx/fcbtMuQiHzidTg1u8A5ezsARy3cxrNy0o/QF3ufKsDv1sgVAsqvnQo5KRIjEAT10Ayey1JAlm3",
	"UIaTsFZpDDtzNymJcnbD+C0D7DXbq7txoEjIVKGcAUmxuCgzF+egUEgiKE7oh7KYWTFRWp59Rs8IBfyf",
	"kAjnkiCqTCUshaJ5zrSdoefv3ipbGdS4uKVt9Lxcjz1YwrjBy+aazEKKGmdbrcT5e3kSg68XM7Q4CA9+",
	"QDF3lZsqYxjc11yfaTDqRViTzI8p3xGpqNa72Oy7WilkTbiJhh9M4hj8yEVAQI8rCDDSrr4Vd/wQwln6",
	"B7nDkQobxUr++n2wqtZVp/y+VNZRh1X1yHbJRr6VlXCE5QEu+FELzJignKsPG9mVKg7ng0RKmT1Lb9mb",
	"oWzLkUL0L+AHIKAmBCl7Lh4XnLjSJSSdAIdCOUt5DPUNIdnbMRcz8xCd8yw3Z6mgYi1BcikVSUN0QXA8",
	"1iLswb3z2g7PhSAsWo5tVb4xZvG4YOfR0luamyTTXyi7aQPMvTGRkDcXvzQDIAVceq3/ml2z1yfnFyfH",
	"R1cnr6vOWqAyKJWopTie4VapQYYOwhf7GoMJlqTBbqhEWYIZM1ITygOlfEHcZwfus7Df+axe6pJJ+jnW",
	"PKerPg+81Cta0JhYTaBdKQnqNlLbH5pimuSipjRFWOot0vic5omiWUKMJDLV3giLNPUSYapENLRhvT9+",
	"88JsXcFpihAWVkZ+m2KWAAMYbaQpRBsdAGGqJPo/l7/92mR9ZxDiAomEYm6YZcalmtK7sszglAvEiASq",
	"UwbTidb9tK1gFvWBCD6mLCZ3mmDRP/VcTfwMZxnBVZ2CGz8O7KPuAEqf6slLFOcQLJiar+d4obezsYch",
	"+s2q3oCfJyZWIw+vGULX4A+5DtC4gmzFQ8tIDcmVlZDNhyBM3u6/C3v0YFQSM/miRrPt4jrYqDLXEZrn",
	"KWZjQXAMCl7ldVEgCldEDGxCiKpFr60SagkdOOPYlPrEUBzLG5qHKlvSG+VGloo2ntSpZf2FpkzSTC1r",
	"xTBr5FTo1/dO5q+JwjSRvy9edNG6bWFjxlbNLnwKqKRKQ2FnR//PyVrHLo0irbhjGNXPPVyjouFpar6A",
	"3S+JGqPLqmVVJBjcQnH1gugK/UYSVaoMIBrpjMExJkM85kYxo76U1cWdO9md5oFqlUXvxjyy+geWMk8t",
	"f8FsWbZy+AbA1XxvgRMaj7QOkrO49Fl7bDygcj93OzYcwBCVZUjOGLOgwlLyiILIuqXKLMhsmttMw4tD",
	"9KtmZElSe2u4kYOV6ZPElvPUCsGvcnptLGo8npWZ4L4KbXoX4FVlq5vc3rcF1iKvrjXsn/OtR9Vv7mFQ",
	"9BtDkqcEmeQj6vY8ptMpEWX2hDVqSFwO8TNl8edOhmCdjj0Iq+y8P+jZbWnRGLZD2Syx3Rsb0WWvWb9N",
	"/LyDcyuxPJoquNeD6+W06wlPq+W9i4JVlFVucZxyW6uxgJejfdDIlKBall9qiFr1xeTDGO9JNfcF+I/C",
	"N8Tc7wAWgSIIm6tFxzaNnMuiI1WXXkWfc36LEs6gEvctpqqYJb5xKQPN7sN+lRlz6kH+N6evm9AMO8FU",
	"wLsLVE389QffcknEeJbTmOwVNpWQ3+TUh5U7isEV8s8szbhqrMCGuzFwkhTCg32rXAvj0XLepyFr7qGz",
	"5iIe+8yUfDYznPOnq6tzBxvd1pIYdQ7aEdpHtCg73ZNGrKC9RxlY0cOG1L17Tt3bwaKoFqAFhzbpPNRb",
	"TxLcGS2KoMVOBsjtfNmYOdz8Y6yz6+CfRg+8DuxCd7BM0JHT1KMEC+P/wsyQn91FIL9JrhkmMW5OviBC",
	"aC2TKu+OrqkSbIFUQgX9BrGUQ3QdXOYQotS2qKiu9MHRUWsT4Jyyk++T662FlTd78xt0lKu58frrR9fs",
	"KEmq5Idc6PDo/NTVYkfv9UdcWNfFIXpFsCACXef7+y8jcPzDn+Q9moPVa7QxjMA+sZEBylCWYMrGitwp",
	"cCBcQcFn/c5KdD6xrvbJ0gYv3hMzm0gltqlmN+q91QTgh6scrd+CD0VQbZnRIvwjI0EIC68hb4UqqFN0",
	"TkTEGS5Wa0ipEik8DA7C/XDfZvQznNHgMHgZ7ocvbMkMwKI9cxZsbEPP8GxGlD8wWBjw1o06qUXHNWAL",
	"xDuN7Te1GLyEfBRjy8JQL/b3XQSPmPgJ3FdiQLv3H0vjdm1rmEh9JMgZADxqykGggmmelFSi9+j7e5yJ",
	"SXb2DP6GyY7hf3iM4U+dJmMdEMQ2HAUyT1Mslr3hrPBMtsqxQDJRxn1nMEwqlb02ut6d0880QX33nfPJ",
	"ffcdeOXev3+v//uo/yl9dJqbyZcOZ6+DkXutuYh7XXlcZl+Yl+b3QaVFkb1hGpifv9/o30WbImPCjgA/",
	"G21MwoVpQPJxRJgSOBkfXAe6xadiSavXhj/kgqxcHrRYscIidWTFIm3/v+MInMq/m/E7l9toXa67XFWL",
	"ARiw1wgzKG73esVNpf57wXnPSDbhx0MHV5WySjUktCEFV1e5mpBhszweh3sNjGtzxrWexazgW59GLUm4",
	"91ETxCfDyxLirbgEz42Idh6TxtAtkjDfNEmiklh2+HbVGYlW7xQqPmI1dxmdh4HNFqvj7qgCg6b69a6F",
	"19/7DMgB/1bhXz9k6BacXq3rR6I2Q68fiXrquDXwzCeDsz3Qa4Wmh1XkLfgnFMWJyxx2boOOEUJkUnVt",
	"8Y96UxOPCltI7snufRp4fv96TXcicz+9BjZFhui3rt0tooLOVTVoPV8SBW9GbWs0IHtMcew8LytFkjvT",
	"CPFgCP5alIsSDDdOQmT6xndKsyWy/Cd3HxDv/AMO+Le1BNkBGxxG3vxNNvCwfle/37NwBpf+os3OMdcR",
	"8NKDgJUz0w/D2FeN2MHaWzUodzFaBzTfBM23wrI2YjsIjh2G23rK3ehdWLUd1/V0uFz8d8Y8DCZ33E/T",
	"E4etgPrs/pfeq+gilRf7B48/GXfRlyUgM48Xjz+PI1tTeuAZHodUN+k6DhF793k1z9jWP7WGf5hvuvhH",
	"bxurY80QG9ckPuU5i23S35mNEr91PvB3RdF1782jNmDwBTgoNsy3GfTP+/G6bUxnHd63C0iSkZsR0I9E",
	"DdTzNETyQCSGSHri8VbSyNXB30aFtd/202EvisaPoMQWVeN7arHuIpCnpsauWMdn0GNXzOZxFdkVExk0",
	"2U002ZKCO5iH2+k13GNXZbaLk3i12ZKTbC+Q3UUxO0nkixrXGBTagdZ6o/lacttKpe0io7ZOO9DQZxTR",
	"A6300Ws3IpYs9xJLluBoU5ljQrZfIb18GVq5jXMPWvnmWvk0Twb2U2U//djDVqrxZpn4rXvVvbn4DcA/",
	"aDa+71r5QcTdSzq+D9gdONYnJb/ZXT93zOP4YR4lFP5YE/8MvL0fU0+WD+xvGRwtOzpaVlK4V3xs61FZ",
	"yw28LpVd9Nrd9NnBeTLQz2rnyUa01DsPfy2dtH0mA5E8rBwdqKArq39DEtjAGbKWDLzekP8uSniiWvAT",
	"cHQM1HtfXoV7Uwj3KimnW7sXkOukh5fhVdF0EH5bZbwMrpOHc51UEHmb7JeCqCJBoCAXTuTagzPdRI2q",
	"3azXJ49rrQfq2pC6yu0bqOshlMwGNm8prjKqxFqSOueUqTFl4yuaEiRIUhB7eQ39LpbbuZ7EQGIbkxjs",
	"20BcWxPXrni9Jc1Vczq31xGLXnooiRdl24HItovfDmriA6qJFVzuFc0tTwWO3VVqm1GT5y5cPyF5rmJ7",
	"yLBu181vA+LdC+J1gN3hXOoBdneE98h7o3JR+BRYmUTvNet6X14IE16zV1iS2N1Y4N6bQscZiRRdEHRD",
	"lqZGYv02KEZILGt9XebRHGE5QnRqujpEWZq+t3f0vNd/Q2fVL22l9dhVYayNEXbWGfPcKvgw7rk1V4V2",
	"eOvOuoHx+cLWvpsYB1LeqfZYN9GtpeQu0bFtMNeDch3xXC/t9FbFUu84X3tpsu/NXB92eB9XYVwZJfjp",
	"B2f9GLpO3vX0r6U90P9HonbD/bNHxP2B7w+E1ccVl25FVR0F3UwEdwvJYj580pLlMXTD2l3fHbphuk43",
	"/CzV2QYm8d/DJDag4vU6KqtdDN4pjXGSoLIpSqGIEhTHt1XrvR6Nyq3jD4jb9cvle6N1i/GuX2Njx4wu",
	"D39/Kl2whM0o6+EjKq9zLnxU7tNVbtaTok1vzlvMspvfutdPyy1q1jp4pXb3Sq1EtqYf1Gx7i0GsRPeK",
	"XbtpyNz0sCp2d+JafF6UH/WKYRTL+VKCD3Z3Bwq7z8h5gQWdxNWRnOmV7utopZ6a+ZWTy8MlcXZTytPO",
	"4Rwo/F517Q2IXEvQ8oq/tYWYcYYjqpZQdrcU2UUHOxVivqjcNPh41ZjLUQfs274k8/Z40a5cuyiv6OxE",
	"RncV2Ssc3RAWu2s64Wa5FrLZez0futC3u1p0ewNv5aqgWwMLIy1zkQSHwd7iINBixe5jc7N0l0s112a3",
	"y+mxN71VCgxXDmlbwaah0ZaP3Z05Ru7pqpkQtFW3pVHZ6NVJjh3miioZQf45F2ULdhmlTE73D+JqDm4w",
	"xqtmxX3bc73g/qd3n/43AAD///X6o33N9gAA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
